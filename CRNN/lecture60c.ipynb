{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 60: Activity recognition using CNN-LSTM\n",
    "## 60c: Train LSTM using features extracted from CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset: [UCF101](http://crcv.ucf.edu/data/UCF101.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories containing extracted features\n",
    "trainPath = 'ucf101_resnet18Feat/train/'\n",
    "testPath = 'ucf101_resnet18Feat/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train list for loading feature tensors\n",
    "classes = os.listdir(trainPath)\n",
    "classes.sort()\n",
    "labels = np.arange(5)\n",
    "trainShuffList = []\n",
    "labelShuffList = []\n",
    "for c in range(5):\n",
    "    files = os.listdir(trainPath+classes[c])\n",
    "    for f in files:\n",
    "        trainShuffList.append(classes[c]+'/'+f)  \n",
    "        labelShuffList.append(float(labels[c]))\n",
    "# Shuffling data list and label list\n",
    "trainList = list(zip(trainShuffList, labelShuffList))\n",
    "shuffle(trainList)\n",
    "trainShuffList, labelShuffList = zip(*trainList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating test list for loading feature tensors\n",
    "testList = []\n",
    "testLabelList = []\n",
    "for c in range(5):\n",
    "    files = os.listdir(testPath+classes[c])\n",
    "    for f in files:\n",
    "        testList.append(classes[c]+'/'+f)  \n",
    "        testLabelList.append(float(labels[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net_LSTM(nn.Module):\n",
    "    def __init__(self, input_sz, hidden_sz, nLayers, nClasses):\n",
    "        super(net_LSTM, self).__init__()       \n",
    "        self.lstm = nn.LSTM(input_sz, hidden_sz, nLayers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_sz, nClasses)        \n",
    "    \n",
    "    def forward(self, x):      \n",
    "        out, _ = self.lstm(x)       \n",
    "        # Output from hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])  \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, inputs, labels, optimizer, criterion):\n",
    "    net.train(True)\n",
    "    if use_gpu:\n",
    "        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "    else:\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "    # Feed-forward\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)     \n",
    "    # Initialize gradients to zero\n",
    "    optimizer.zero_grad() \n",
    "    # Compute loss/error\n",
    "    loss = criterion(F.log_softmax(outputs), labels)\n",
    "    # Backpropagate loss and compute gradients\n",
    "    loss.backward()\n",
    "    # Update the network parameters\n",
    "    optimizer.step()\n",
    "    if use_gpu:\n",
    "        correct = (predicted.cpu() == labels.data.cpu()).sum()\n",
    "    else:\n",
    "        correct = (predicted == labels.data).sum()\n",
    "    return net, loss.data.item(), correct    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define test routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, inputs, labels, criterion):\n",
    "    net.train(False)\n",
    "    if use_gpu:\n",
    "        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "    else:\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)  \n",
    "    # Compute loss/error\n",
    "    loss = criterion(F.log_softmax(outputs), labels)   \n",
    "    if use_gpu:\n",
    "        correct = (predicted.cpu() == labels.data.cpu()).sum()\n",
    "    else:\n",
    "        correct = (predicted == labels.data).sum()\n",
    "    return loss.data.item(), correct    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net_LSTM(512, 8, 2, 5) # Input feature length->512, hidden layer size->8, number of layers->2\n",
    "if use_gpu:\n",
    "    net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss() # Negative Log-likelihood\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4) # Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amrit/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n",
      "/home/amrit/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 /1000;  Training Loss: 0.051008 ; Training Acc: 17.417\n",
      "Iteration: 1 /1000;  Testing Loss: 0.062561 ; Testing Acc: 23.308\n",
      "Time consumed: 0m 22s\n",
      "Iteration: 2 /1000;  Training Loss: 0.050976 ; Training Acc: 17.417\n",
      "Iteration: 2 /1000;  Testing Loss: 0.062523 ; Testing Acc: 24.060\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 3 /1000;  Training Loss: 0.050945 ; Training Acc: 17.417\n",
      "Iteration: 3 /1000;  Testing Loss: 0.062494 ; Testing Acc: 24.060\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 4 /1000;  Training Loss: 0.050916 ; Training Acc: 17.417\n",
      "Iteration: 4 /1000;  Testing Loss: 0.062465 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 5 /1000;  Training Loss: 0.050895 ; Training Acc: 17.417\n",
      "Iteration: 5 /1000;  Testing Loss: 0.062450 ; Testing Acc: 22.556\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 6 /1000;  Training Loss: 0.050868 ; Training Acc: 19.569\n",
      "Iteration: 6 /1000;  Testing Loss: 0.062434 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 7 /1000;  Training Loss: 0.050840 ; Training Acc: 22.505\n",
      "Iteration: 7 /1000;  Testing Loss: 0.062407 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 8 /1000;  Training Loss: 0.050816 ; Training Acc: 22.505\n",
      "Iteration: 8 /1000;  Testing Loss: 0.062387 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 9 /1000;  Training Loss: 0.050797 ; Training Acc: 22.505\n",
      "Iteration: 9 /1000;  Testing Loss: 0.062370 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 10 /1000;  Training Loss: 0.050778 ; Training Acc: 22.505\n",
      "Iteration: 10 /1000;  Testing Loss: 0.062337 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 11 /1000;  Training Loss: 0.050755 ; Training Acc: 22.505\n",
      "Iteration: 11 /1000;  Testing Loss: 0.062331 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 12 /1000;  Training Loss: 0.050735 ; Training Acc: 22.505\n",
      "Iteration: 12 /1000;  Testing Loss: 0.062309 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 13 /1000;  Training Loss: 0.050722 ; Training Acc: 22.505\n",
      "Iteration: 13 /1000;  Testing Loss: 0.062303 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 14 /1000;  Training Loss: 0.050700 ; Training Acc: 22.505\n",
      "Iteration: 14 /1000;  Testing Loss: 0.062273 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 15 /1000;  Training Loss: 0.050684 ; Training Acc: 22.505\n",
      "Iteration: 15 /1000;  Testing Loss: 0.062277 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 16 /1000;  Training Loss: 0.050664 ; Training Acc: 22.505\n",
      "Iteration: 16 /1000;  Testing Loss: 0.062225 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 17 /1000;  Training Loss: 0.050643 ; Training Acc: 22.505\n",
      "Iteration: 17 /1000;  Testing Loss: 0.062216 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 18 /1000;  Training Loss: 0.050632 ; Training Acc: 22.505\n",
      "Iteration: 18 /1000;  Testing Loss: 0.062208 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 19 /1000;  Training Loss: 0.050612 ; Training Acc: 22.505\n",
      "Iteration: 19 /1000;  Testing Loss: 0.062184 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 20 /1000;  Training Loss: 0.050597 ; Training Acc: 22.505\n",
      "Iteration: 20 /1000;  Testing Loss: 0.062152 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 21 /1000;  Training Loss: 0.050582 ; Training Acc: 22.505\n",
      "Iteration: 21 /1000;  Testing Loss: 0.062105 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 22 /1000;  Training Loss: 0.050563 ; Training Acc: 22.505\n",
      "Iteration: 22 /1000;  Testing Loss: 0.062097 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 23 /1000;  Training Loss: 0.050548 ; Training Acc: 22.505\n",
      "Iteration: 23 /1000;  Testing Loss: 0.062076 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 24 /1000;  Training Loss: 0.050531 ; Training Acc: 22.505\n",
      "Iteration: 24 /1000;  Testing Loss: 0.062056 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 25 /1000;  Training Loss: 0.050520 ; Training Acc: 22.505\n",
      "Iteration: 25 /1000;  Testing Loss: 0.062033 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 26 /1000;  Training Loss: 0.050511 ; Training Acc: 22.505\n",
      "Iteration: 26 /1000;  Testing Loss: 0.062032 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 27 /1000;  Training Loss: 0.050494 ; Training Acc: 22.505\n",
      "Iteration: 27 /1000;  Testing Loss: 0.061988 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 28 /1000;  Training Loss: 0.050477 ; Training Acc: 22.505\n",
      "Iteration: 28 /1000;  Testing Loss: 0.061971 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 29 /1000;  Training Loss: 0.050467 ; Training Acc: 22.505\n",
      "Iteration: 29 /1000;  Testing Loss: 0.061949 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 30 /1000;  Training Loss: 0.050453 ; Training Acc: 22.505\n",
      "Iteration: 30 /1000;  Testing Loss: 0.061925 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 31 /1000;  Training Loss: 0.050439 ; Training Acc: 22.505\n",
      "Iteration: 31 /1000;  Testing Loss: 0.061911 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 32 /1000;  Training Loss: 0.050427 ; Training Acc: 22.505\n",
      "Iteration: 32 /1000;  Testing Loss: 0.061882 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 33 /1000;  Training Loss: 0.050414 ; Training Acc: 22.505\n",
      "Iteration: 33 /1000;  Testing Loss: 0.061861 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 34 /1000;  Training Loss: 0.050405 ; Training Acc: 22.505\n",
      "Iteration: 34 /1000;  Testing Loss: 0.061837 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 35 /1000;  Training Loss: 0.050393 ; Training Acc: 22.505\n",
      "Iteration: 35 /1000;  Testing Loss: 0.061816 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 36 /1000;  Training Loss: 0.050382 ; Training Acc: 22.505\n",
      "Iteration: 36 /1000;  Testing Loss: 0.061782 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 37 /1000;  Training Loss: 0.050371 ; Training Acc: 22.505\n",
      "Iteration: 37 /1000;  Testing Loss: 0.061734 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 38 /1000;  Training Loss: 0.050361 ; Training Acc: 22.505\n",
      "Iteration: 38 /1000;  Testing Loss: 0.061742 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 39 /1000;  Training Loss: 0.050348 ; Training Acc: 22.505\n",
      "Iteration: 39 /1000;  Testing Loss: 0.061707 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 40 /1000;  Training Loss: 0.050339 ; Training Acc: 22.505\n",
      "Iteration: 40 /1000;  Testing Loss: 0.061602 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 41 /1000;  Training Loss: 0.050320 ; Training Acc: 22.505\n",
      "Iteration: 41 /1000;  Testing Loss: 0.061576 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 42 /1000;  Training Loss: 0.050307 ; Training Acc: 22.505\n",
      "Iteration: 42 /1000;  Testing Loss: 0.061538 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 43 /1000;  Training Loss: 0.050296 ; Training Acc: 22.505\n",
      "Iteration: 43 /1000;  Testing Loss: 0.061456 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 44 /1000;  Training Loss: 0.050286 ; Training Acc: 22.505\n",
      "Iteration: 44 /1000;  Testing Loss: 0.061399 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 45 /1000;  Training Loss: 0.050274 ; Training Acc: 22.505\n",
      "Iteration: 45 /1000;  Testing Loss: 0.061429 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 46 /1000;  Training Loss: 0.050260 ; Training Acc: 22.505\n",
      "Iteration: 46 /1000;  Testing Loss: 0.061385 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 47 /1000;  Training Loss: 0.050251 ; Training Acc: 22.505\n",
      "Iteration: 47 /1000;  Testing Loss: 0.061352 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 48 /1000;  Training Loss: 0.050241 ; Training Acc: 22.505\n",
      "Iteration: 48 /1000;  Testing Loss: 0.061360 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 49 /1000;  Training Loss: 0.050237 ; Training Acc: 22.505\n",
      "Iteration: 49 /1000;  Testing Loss: 0.061335 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 50 /1000;  Training Loss: 0.050234 ; Training Acc: 22.505\n",
      "Iteration: 50 /1000;  Testing Loss: 0.061390 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 51 /1000;  Training Loss: 0.050228 ; Training Acc: 22.505\n",
      "Iteration: 51 /1000;  Testing Loss: 0.061347 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 52 /1000;  Training Loss: 0.050213 ; Training Acc: 22.505\n",
      "Iteration: 52 /1000;  Testing Loss: 0.061346 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 53 /1000;  Training Loss: 0.050208 ; Training Acc: 22.505\n",
      "Iteration: 53 /1000;  Testing Loss: 0.061352 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 54 /1000;  Training Loss: 0.050206 ; Training Acc: 22.505\n",
      "Iteration: 54 /1000;  Testing Loss: 0.061368 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 55 /1000;  Training Loss: 0.050202 ; Training Acc: 22.505\n",
      "Iteration: 55 /1000;  Testing Loss: 0.061381 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 56 /1000;  Training Loss: 0.050196 ; Training Acc: 22.505\n",
      "Iteration: 56 /1000;  Testing Loss: 0.061379 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 57 /1000;  Training Loss: 0.050193 ; Training Acc: 22.505\n",
      "Iteration: 57 /1000;  Testing Loss: 0.061372 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 58 /1000;  Training Loss: 0.050189 ; Training Acc: 22.505\n",
      "Iteration: 58 /1000;  Testing Loss: 0.061374 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 59 /1000;  Training Loss: 0.050185 ; Training Acc: 22.505\n",
      "Iteration: 59 /1000;  Testing Loss: 0.061372 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 60 /1000;  Training Loss: 0.050184 ; Training Acc: 22.505\n",
      "Iteration: 60 /1000;  Testing Loss: 0.061373 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 61 /1000;  Training Loss: 0.050181 ; Training Acc: 22.505\n",
      "Iteration: 61 /1000;  Testing Loss: 0.061398 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 62 /1000;  Training Loss: 0.050177 ; Training Acc: 22.505\n",
      "Iteration: 62 /1000;  Testing Loss: 0.061408 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 63 /1000;  Training Loss: 0.050174 ; Training Acc: 22.505\n",
      "Iteration: 63 /1000;  Testing Loss: 0.061396 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 64 /1000;  Training Loss: 0.050176 ; Training Acc: 22.505\n",
      "Iteration: 64 /1000;  Testing Loss: 0.061408 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 65 /1000;  Training Loss: 0.050171 ; Training Acc: 22.505\n",
      "Iteration: 65 /1000;  Testing Loss: 0.061399 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 66 /1000;  Training Loss: 0.050170 ; Training Acc: 22.505\n",
      "Iteration: 66 /1000;  Testing Loss: 0.061422 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 67 /1000;  Training Loss: 0.050167 ; Training Acc: 22.505\n",
      "Iteration: 67 /1000;  Testing Loss: 0.061417 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 68 /1000;  Training Loss: 0.050166 ; Training Acc: 22.505\n",
      "Iteration: 68 /1000;  Testing Loss: 0.061414 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 69 /1000;  Training Loss: 0.050165 ; Training Acc: 22.505\n",
      "Iteration: 69 /1000;  Testing Loss: 0.061404 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 70 /1000;  Training Loss: 0.050170 ; Training Acc: 22.505\n",
      "Iteration: 70 /1000;  Testing Loss: 0.061441 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 71 /1000;  Training Loss: 0.050167 ; Training Acc: 22.505\n",
      "Iteration: 71 /1000;  Testing Loss: 0.061432 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 72 /1000;  Training Loss: 0.050161 ; Training Acc: 22.505\n",
      "Iteration: 72 /1000;  Testing Loss: 0.061432 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 73 /1000;  Training Loss: 0.050160 ; Training Acc: 22.505\n",
      "Iteration: 73 /1000;  Testing Loss: 0.061436 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 74 /1000;  Training Loss: 0.050159 ; Training Acc: 22.505\n",
      "Iteration: 74 /1000;  Testing Loss: 0.061432 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 75 /1000;  Training Loss: 0.050160 ; Training Acc: 22.505\n",
      "Iteration: 75 /1000;  Testing Loss: 0.061440 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 76 /1000;  Training Loss: 0.050157 ; Training Acc: 22.505\n",
      "Iteration: 76 /1000;  Testing Loss: 0.061438 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 77 /1000;  Training Loss: 0.050156 ; Training Acc: 22.505\n",
      "Iteration: 77 /1000;  Testing Loss: 0.061448 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 78 /1000;  Training Loss: 0.050157 ; Training Acc: 22.505\n",
      "Iteration: 78 /1000;  Testing Loss: 0.061454 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 79 /1000;  Training Loss: 0.050153 ; Training Acc: 22.505\n",
      "Iteration: 79 /1000;  Testing Loss: 0.061441 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 80 /1000;  Training Loss: 0.050157 ; Training Acc: 22.505\n",
      "Iteration: 80 /1000;  Testing Loss: 0.061434 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 81 /1000;  Training Loss: 0.050152 ; Training Acc: 22.505\n",
      "Iteration: 81 /1000;  Testing Loss: 0.061439 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 82 /1000;  Training Loss: 0.050156 ; Training Acc: 22.505\n",
      "Iteration: 82 /1000;  Testing Loss: 0.061466 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 83 /1000;  Training Loss: 0.050153 ; Training Acc: 22.505\n",
      "Iteration: 83 /1000;  Testing Loss: 0.061456 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 84 /1000;  Training Loss: 0.050153 ; Training Acc: 22.505\n",
      "Iteration: 84 /1000;  Testing Loss: 0.061455 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 85 /1000;  Training Loss: 0.050151 ; Training Acc: 22.505\n",
      "Iteration: 85 /1000;  Testing Loss: 0.061447 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 86 /1000;  Training Loss: 0.050151 ; Training Acc: 22.505\n",
      "Iteration: 86 /1000;  Testing Loss: 0.061454 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 87 /1000;  Training Loss: 0.050150 ; Training Acc: 22.505\n",
      "Iteration: 87 /1000;  Testing Loss: 0.061458 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 88 /1000;  Training Loss: 0.050151 ; Training Acc: 22.505\n",
      "Iteration: 88 /1000;  Testing Loss: 0.061453 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 89 /1000;  Training Loss: 0.050153 ; Training Acc: 22.505\n",
      "Iteration: 89 /1000;  Testing Loss: 0.061460 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 90 /1000;  Training Loss: 0.050145 ; Training Acc: 22.505\n",
      "Iteration: 90 /1000;  Testing Loss: 0.061445 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 91 /1000;  Training Loss: 0.050149 ; Training Acc: 22.505\n",
      "Iteration: 91 /1000;  Testing Loss: 0.061442 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 92 /1000;  Training Loss: 0.050145 ; Training Acc: 22.505\n",
      "Iteration: 92 /1000;  Testing Loss: 0.061433 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 93 /1000;  Training Loss: 0.050148 ; Training Acc: 22.505\n",
      "Iteration: 93 /1000;  Testing Loss: 0.061429 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 94 /1000;  Training Loss: 0.050142 ; Training Acc: 22.505\n",
      "Iteration: 94 /1000;  Testing Loss: 0.061426 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 95 /1000;  Training Loss: 0.050146 ; Training Acc: 22.505\n",
      "Iteration: 95 /1000;  Testing Loss: 0.061449 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 96 /1000;  Training Loss: 0.050145 ; Training Acc: 22.309\n",
      "Iteration: 96 /1000;  Testing Loss: 0.061410 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 97 /1000;  Training Loss: 0.050143 ; Training Acc: 24.070\n",
      "Iteration: 97 /1000;  Testing Loss: 0.061431 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 98 /1000;  Training Loss: 0.050138 ; Training Acc: 24.658\n",
      "Iteration: 98 /1000;  Testing Loss: 0.061422 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 99 /1000;  Training Loss: 0.050134 ; Training Acc: 23.679\n",
      "Iteration: 99 /1000;  Testing Loss: 0.061419 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 100 /1000;  Training Loss: 0.050133 ; Training Acc: 23.483\n",
      "Iteration: 100 /1000;  Testing Loss: 0.061396 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 101 /1000;  Training Loss: 0.050137 ; Training Acc: 22.309\n",
      "Iteration: 101 /1000;  Testing Loss: 0.061396 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 102 /1000;  Training Loss: 0.050134 ; Training Acc: 23.483\n",
      "Iteration: 102 /1000;  Testing Loss: 0.061374 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 103 /1000;  Training Loss: 0.050133 ; Training Acc: 22.701\n",
      "Iteration: 103 /1000;  Testing Loss: 0.061371 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 104 /1000;  Training Loss: 0.050130 ; Training Acc: 23.092\n",
      "Iteration: 104 /1000;  Testing Loss: 0.061429 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 105 /1000;  Training Loss: 0.050129 ; Training Acc: 23.679\n",
      "Iteration: 105 /1000;  Testing Loss: 0.061417 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 106 /1000;  Training Loss: 0.050125 ; Training Acc: 24.070\n",
      "Iteration: 106 /1000;  Testing Loss: 0.061409 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 107 /1000;  Training Loss: 0.050134 ; Training Acc: 24.070\n",
      "Iteration: 107 /1000;  Testing Loss: 0.061381 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 108 /1000;  Training Loss: 0.050125 ; Training Acc: 26.419\n",
      "Iteration: 108 /1000;  Testing Loss: 0.061388 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 109 /1000;  Training Loss: 0.050122 ; Training Acc: 23.483\n",
      "Iteration: 109 /1000;  Testing Loss: 0.061386 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 110 /1000;  Training Loss: 0.050127 ; Training Acc: 27.006\n",
      "Iteration: 110 /1000;  Testing Loss: 0.061406 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 111 /1000;  Training Loss: 0.050131 ; Training Acc: 25.049\n",
      "Iteration: 111 /1000;  Testing Loss: 0.061304 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 112 /1000;  Training Loss: 0.050131 ; Training Acc: 23.092\n",
      "Iteration: 112 /1000;  Testing Loss: 0.061453 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 113 /1000;  Training Loss: 0.050135 ; Training Acc: 22.896\n",
      "Iteration: 113 /1000;  Testing Loss: 0.061427 ; Testing Acc: 24.060\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 114 /1000;  Training Loss: 0.050132 ; Training Acc: 23.092\n",
      "Iteration: 114 /1000;  Testing Loss: 0.061470 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 115 /1000;  Training Loss: 0.050126 ; Training Acc: 22.114\n",
      "Iteration: 115 /1000;  Testing Loss: 0.061373 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 116 /1000;  Training Loss: 0.050125 ; Training Acc: 24.658\n",
      "Iteration: 116 /1000;  Testing Loss: 0.061350 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 117 /1000;  Training Loss: 0.050116 ; Training Acc: 27.006\n",
      "Iteration: 117 /1000;  Testing Loss: 0.061412 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 118 /1000;  Training Loss: 0.050119 ; Training Acc: 25.440\n",
      "Iteration: 118 /1000;  Testing Loss: 0.061395 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 119 /1000;  Training Loss: 0.050115 ; Training Acc: 28.180\n",
      "Iteration: 119 /1000;  Testing Loss: 0.061363 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 120 /1000;  Training Loss: 0.050133 ; Training Acc: 27.397\n",
      "Iteration: 120 /1000;  Testing Loss: 0.061472 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 121 /1000;  Training Loss: 0.050111 ; Training Acc: 28.571\n",
      "Iteration: 121 /1000;  Testing Loss: 0.061384 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 122 /1000;  Training Loss: 0.050121 ; Training Acc: 25.636\n",
      "Iteration: 122 /1000;  Testing Loss: 0.061339 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 123 /1000;  Training Loss: 0.050115 ; Training Acc: 23.483\n",
      "Iteration: 123 /1000;  Testing Loss: 0.061392 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 124 /1000;  Training Loss: 0.050114 ; Training Acc: 27.397\n",
      "Iteration: 124 /1000;  Testing Loss: 0.061336 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 125 /1000;  Training Loss: 0.050112 ; Training Acc: 27.397\n",
      "Iteration: 125 /1000;  Testing Loss: 0.061404 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 126 /1000;  Training Loss: 0.050121 ; Training Acc: 27.397\n",
      "Iteration: 126 /1000;  Testing Loss: 0.061379 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 127 /1000;  Training Loss: 0.050114 ; Training Acc: 25.245\n",
      "Iteration: 127 /1000;  Testing Loss: 0.061319 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 128 /1000;  Training Loss: 0.050109 ; Training Acc: 24.462\n",
      "Iteration: 128 /1000;  Testing Loss: 0.061437 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 129 /1000;  Training Loss: 0.050104 ; Training Acc: 27.006\n",
      "Iteration: 129 /1000;  Testing Loss: 0.061372 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 130 /1000;  Training Loss: 0.050107 ; Training Acc: 29.746\n",
      "Iteration: 130 /1000;  Testing Loss: 0.061377 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 131 /1000;  Training Loss: 0.050110 ; Training Acc: 25.245\n",
      "Iteration: 131 /1000;  Testing Loss: 0.061352 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 132 /1000;  Training Loss: 0.050107 ; Training Acc: 24.462\n",
      "Iteration: 132 /1000;  Testing Loss: 0.061359 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 133 /1000;  Training Loss: 0.050098 ; Training Acc: 27.202\n",
      "Iteration: 133 /1000;  Testing Loss: 0.061405 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 134 /1000;  Training Loss: 0.050105 ; Training Acc: 27.397\n",
      "Iteration: 134 /1000;  Testing Loss: 0.061339 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 135 /1000;  Training Loss: 0.050099 ; Training Acc: 25.245\n",
      "Iteration: 135 /1000;  Testing Loss: 0.061295 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 136 /1000;  Training Loss: 0.050095 ; Training Acc: 24.853\n",
      "Iteration: 136 /1000;  Testing Loss: 0.061423 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 137 /1000;  Training Loss: 0.050104 ; Training Acc: 28.180\n",
      "Iteration: 137 /1000;  Testing Loss: 0.061277 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 138 /1000;  Training Loss: 0.050090 ; Training Acc: 27.202\n",
      "Iteration: 138 /1000;  Testing Loss: 0.061372 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 139 /1000;  Training Loss: 0.050090 ; Training Acc: 27.397\n",
      "Iteration: 139 /1000;  Testing Loss: 0.061378 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 140 /1000;  Training Loss: 0.050095 ; Training Acc: 24.070\n",
      "Iteration: 140 /1000;  Testing Loss: 0.061280 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 141 /1000;  Training Loss: 0.050100 ; Training Acc: 24.070\n",
      "Iteration: 141 /1000;  Testing Loss: 0.061463 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 142 /1000;  Training Loss: 0.050088 ; Training Acc: 24.658\n",
      "Iteration: 142 /1000;  Testing Loss: 0.061290 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 143 /1000;  Training Loss: 0.050095 ; Training Acc: 24.853\n",
      "Iteration: 143 /1000;  Testing Loss: 0.061345 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 144 /1000;  Training Loss: 0.050096 ; Training Acc: 26.419\n",
      "Iteration: 144 /1000;  Testing Loss: 0.061243 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 145 /1000;  Training Loss: 0.050075 ; Training Acc: 27.789\n",
      "Iteration: 145 /1000;  Testing Loss: 0.061377 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 146 /1000;  Training Loss: 0.050078 ; Training Acc: 24.070\n",
      "Iteration: 146 /1000;  Testing Loss: 0.061511 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 147 /1000;  Training Loss: 0.050083 ; Training Acc: 24.266\n",
      "Iteration: 147 /1000;  Testing Loss: 0.061299 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 148 /1000;  Training Loss: 0.050088 ; Training Acc: 28.571\n",
      "Iteration: 148 /1000;  Testing Loss: 0.061332 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 149 /1000;  Training Loss: 0.050092 ; Training Acc: 23.483\n",
      "Iteration: 149 /1000;  Testing Loss: 0.061372 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 150 /1000;  Training Loss: 0.050087 ; Training Acc: 26.223\n",
      "Iteration: 150 /1000;  Testing Loss: 0.061279 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 151 /1000;  Training Loss: 0.050108 ; Training Acc: 22.505\n",
      "Iteration: 151 /1000;  Testing Loss: 0.061348 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 152 /1000;  Training Loss: 0.050082 ; Training Acc: 26.223\n",
      "Iteration: 152 /1000;  Testing Loss: 0.061332 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 153 /1000;  Training Loss: 0.050080 ; Training Acc: 26.027\n",
      "Iteration: 153 /1000;  Testing Loss: 0.061301 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 154 /1000;  Training Loss: 0.050073 ; Training Acc: 29.550\n",
      "Iteration: 154 /1000;  Testing Loss: 0.061317 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 155 /1000;  Training Loss: 0.050072 ; Training Acc: 26.810\n",
      "Iteration: 155 /1000;  Testing Loss: 0.061319 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 156 /1000;  Training Loss: 0.050067 ; Training Acc: 28.180\n",
      "Iteration: 156 /1000;  Testing Loss: 0.061333 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 157 /1000;  Training Loss: 0.050080 ; Training Acc: 26.810\n",
      "Iteration: 157 /1000;  Testing Loss: 0.061448 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 158 /1000;  Training Loss: 0.050067 ; Training Acc: 27.397\n",
      "Iteration: 158 /1000;  Testing Loss: 0.061205 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 159 /1000;  Training Loss: 0.050063 ; Training Acc: 26.419\n",
      "Iteration: 159 /1000;  Testing Loss: 0.061395 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 160 /1000;  Training Loss: 0.050066 ; Training Acc: 26.810\n",
      "Iteration: 160 /1000;  Testing Loss: 0.061312 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 161 /1000;  Training Loss: 0.050067 ; Training Acc: 26.810\n",
      "Iteration: 161 /1000;  Testing Loss: 0.061305 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 162 /1000;  Training Loss: 0.050061 ; Training Acc: 27.984\n",
      "Iteration: 162 /1000;  Testing Loss: 0.061289 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 163 /1000;  Training Loss: 0.050072 ; Training Acc: 22.896\n",
      "Iteration: 163 /1000;  Testing Loss: 0.061321 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 164 /1000;  Training Loss: 0.050075 ; Training Acc: 23.288\n",
      "Iteration: 164 /1000;  Testing Loss: 0.061263 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 165 /1000;  Training Loss: 0.050062 ; Training Acc: 29.354\n",
      "Iteration: 165 /1000;  Testing Loss: 0.061355 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 166 /1000;  Training Loss: 0.050070 ; Training Acc: 22.505\n",
      "Iteration: 166 /1000;  Testing Loss: 0.061368 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 167 /1000;  Training Loss: 0.050061 ; Training Acc: 25.440\n",
      "Iteration: 167 /1000;  Testing Loss: 0.061272 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 168 /1000;  Training Loss: 0.050049 ; Training Acc: 29.159\n",
      "Iteration: 168 /1000;  Testing Loss: 0.061316 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 169 /1000;  Training Loss: 0.050055 ; Training Acc: 26.027\n",
      "Iteration: 169 /1000;  Testing Loss: 0.061347 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 170 /1000;  Training Loss: 0.050049 ; Training Acc: 26.027\n",
      "Iteration: 170 /1000;  Testing Loss: 0.061242 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 171 /1000;  Training Loss: 0.050052 ; Training Acc: 26.223\n",
      "Iteration: 171 /1000;  Testing Loss: 0.061213 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 172 /1000;  Training Loss: 0.050058 ; Training Acc: 26.223\n",
      "Iteration: 172 /1000;  Testing Loss: 0.061422 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 173 /1000;  Training Loss: 0.050043 ; Training Acc: 27.006\n",
      "Iteration: 173 /1000;  Testing Loss: 0.061193 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 174 /1000;  Training Loss: 0.050055 ; Training Acc: 25.245\n",
      "Iteration: 174 /1000;  Testing Loss: 0.061264 ; Testing Acc: 24.812\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 175 /1000;  Training Loss: 0.050070 ; Training Acc: 25.636\n",
      "Iteration: 175 /1000;  Testing Loss: 0.061341 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 176 /1000;  Training Loss: 0.050042 ; Training Acc: 25.440\n",
      "Iteration: 176 /1000;  Testing Loss: 0.061301 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 177 /1000;  Training Loss: 0.050041 ; Training Acc: 29.746\n",
      "Iteration: 177 /1000;  Testing Loss: 0.061210 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 178 /1000;  Training Loss: 0.050040 ; Training Acc: 25.832\n",
      "Iteration: 178 /1000;  Testing Loss: 0.061317 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 179 /1000;  Training Loss: 0.050090 ; Training Acc: 23.288\n",
      "Iteration: 179 /1000;  Testing Loss: 0.061230 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 180 /1000;  Training Loss: 0.050027 ; Training Acc: 25.636\n",
      "Iteration: 180 /1000;  Testing Loss: 0.061233 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 181 /1000;  Training Loss: 0.050032 ; Training Acc: 24.070\n",
      "Iteration: 181 /1000;  Testing Loss: 0.061233 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 182 /1000;  Training Loss: 0.050034 ; Training Acc: 25.049\n",
      "Iteration: 182 /1000;  Testing Loss: 0.061154 ; Testing Acc: 27.820\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 183 /1000;  Training Loss: 0.050051 ; Training Acc: 28.180\n",
      "Iteration: 183 /1000;  Testing Loss: 0.061374 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 184 /1000;  Training Loss: 0.050040 ; Training Acc: 25.245\n",
      "Iteration: 184 /1000;  Testing Loss: 0.061212 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 185 /1000;  Training Loss: 0.050024 ; Training Acc: 25.636\n",
      "Iteration: 185 /1000;  Testing Loss: 0.061208 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 186 /1000;  Training Loss: 0.050029 ; Training Acc: 29.550\n",
      "Iteration: 186 /1000;  Testing Loss: 0.061181 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 187 /1000;  Training Loss: 0.050026 ; Training Acc: 24.658\n",
      "Iteration: 187 /1000;  Testing Loss: 0.061281 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 188 /1000;  Training Loss: 0.050028 ; Training Acc: 27.593\n",
      "Iteration: 188 /1000;  Testing Loss: 0.061192 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 189 /1000;  Training Loss: 0.050018 ; Training Acc: 26.027\n",
      "Iteration: 189 /1000;  Testing Loss: 0.061262 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 190 /1000;  Training Loss: 0.050057 ; Training Acc: 23.679\n",
      "Iteration: 190 /1000;  Testing Loss: 0.061243 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 191 /1000;  Training Loss: 0.050040 ; Training Acc: 24.266\n",
      "Iteration: 191 /1000;  Testing Loss: 0.061336 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 192 /1000;  Training Loss: 0.050038 ; Training Acc: 24.266\n",
      "Iteration: 192 /1000;  Testing Loss: 0.061299 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 193 /1000;  Training Loss: 0.050004 ; Training Acc: 27.789\n",
      "Iteration: 193 /1000;  Testing Loss: 0.061104 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 194 /1000;  Training Loss: 0.050035 ; Training Acc: 22.701\n",
      "Iteration: 194 /1000;  Testing Loss: 0.061130 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 195 /1000;  Training Loss: 0.050010 ; Training Acc: 27.397\n",
      "Iteration: 195 /1000;  Testing Loss: 0.061155 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 196 /1000;  Training Loss: 0.049995 ; Training Acc: 27.984\n",
      "Iteration: 196 /1000;  Testing Loss: 0.061124 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 197 /1000;  Training Loss: 0.050005 ; Training Acc: 26.614\n",
      "Iteration: 197 /1000;  Testing Loss: 0.061159 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 198 /1000;  Training Loss: 0.049998 ; Training Acc: 27.202\n",
      "Iteration: 198 /1000;  Testing Loss: 0.061083 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 199 /1000;  Training Loss: 0.049995 ; Training Acc: 26.614\n",
      "Iteration: 199 /1000;  Testing Loss: 0.061293 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 200 /1000;  Training Loss: 0.050005 ; Training Acc: 24.853\n",
      "Iteration: 200 /1000;  Testing Loss: 0.061254 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 201 /1000;  Training Loss: 0.049973 ; Training Acc: 26.027\n",
      "Iteration: 201 /1000;  Testing Loss: 0.061139 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 202 /1000;  Training Loss: 0.049981 ; Training Acc: 26.614\n",
      "Iteration: 202 /1000;  Testing Loss: 0.061192 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 203 /1000;  Training Loss: 0.050008 ; Training Acc: 27.202\n",
      "Iteration: 203 /1000;  Testing Loss: 0.061087 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 204 /1000;  Training Loss: 0.049984 ; Training Acc: 26.614\n",
      "Iteration: 204 /1000;  Testing Loss: 0.061216 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 205 /1000;  Training Loss: 0.049989 ; Training Acc: 27.202\n",
      "Iteration: 205 /1000;  Testing Loss: 0.061217 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 206 /1000;  Training Loss: 0.049977 ; Training Acc: 27.202\n",
      "Iteration: 206 /1000;  Testing Loss: 0.061132 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 207 /1000;  Training Loss: 0.049977 ; Training Acc: 25.440\n",
      "Iteration: 207 /1000;  Testing Loss: 0.061100 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 208 /1000;  Training Loss: 0.049966 ; Training Acc: 26.614\n",
      "Iteration: 208 /1000;  Testing Loss: 0.061076 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 209 /1000;  Training Loss: 0.049965 ; Training Acc: 29.746\n",
      "Iteration: 209 /1000;  Testing Loss: 0.061231 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 210 /1000;  Training Loss: 0.049990 ; Training Acc: 27.789\n",
      "Iteration: 210 /1000;  Testing Loss: 0.061135 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 211 /1000;  Training Loss: 0.050000 ; Training Acc: 27.397\n",
      "Iteration: 211 /1000;  Testing Loss: 0.061124 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 212 /1000;  Training Loss: 0.049984 ; Training Acc: 26.223\n",
      "Iteration: 212 /1000;  Testing Loss: 0.061073 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 213 /1000;  Training Loss: 0.049978 ; Training Acc: 24.266\n",
      "Iteration: 213 /1000;  Testing Loss: 0.061147 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 214 /1000;  Training Loss: 0.049954 ; Training Acc: 29.746\n",
      "Iteration: 214 /1000;  Testing Loss: 0.061173 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 215 /1000;  Training Loss: 0.049995 ; Training Acc: 25.245\n",
      "Iteration: 215 /1000;  Testing Loss: 0.061183 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 216 /1000;  Training Loss: 0.050000 ; Training Acc: 31.115\n",
      "Iteration: 216 /1000;  Testing Loss: 0.061088 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 217 /1000;  Training Loss: 0.049980 ; Training Acc: 26.419\n",
      "Iteration: 217 /1000;  Testing Loss: 0.061382 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 218 /1000;  Training Loss: 0.049947 ; Training Acc: 28.767\n",
      "Iteration: 218 /1000;  Testing Loss: 0.061164 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 219 /1000;  Training Loss: 0.049944 ; Training Acc: 29.354\n",
      "Iteration: 219 /1000;  Testing Loss: 0.061094 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 220 /1000;  Training Loss: 0.049959 ; Training Acc: 32.094\n",
      "Iteration: 220 /1000;  Testing Loss: 0.061211 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 221 /1000;  Training Loss: 0.049974 ; Training Acc: 24.658\n",
      "Iteration: 221 /1000;  Testing Loss: 0.061120 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 222 /1000;  Training Loss: 0.049944 ; Training Acc: 30.333\n",
      "Iteration: 222 /1000;  Testing Loss: 0.061095 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 223 /1000;  Training Loss: 0.049932 ; Training Acc: 26.223\n",
      "Iteration: 223 /1000;  Testing Loss: 0.061104 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 224 /1000;  Training Loss: 0.049936 ; Training Acc: 28.767\n",
      "Iteration: 224 /1000;  Testing Loss: 0.061077 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 225 /1000;  Training Loss: 0.049942 ; Training Acc: 27.397\n",
      "Iteration: 225 /1000;  Testing Loss: 0.061132 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 226 /1000;  Training Loss: 0.049962 ; Training Acc: 29.354\n",
      "Iteration: 226 /1000;  Testing Loss: 0.061256 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 227 /1000;  Training Loss: 0.049965 ; Training Acc: 26.810\n",
      "Iteration: 227 /1000;  Testing Loss: 0.061209 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 228 /1000;  Training Loss: 0.049922 ; Training Acc: 31.115\n",
      "Iteration: 228 /1000;  Testing Loss: 0.061079 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 229 /1000;  Training Loss: 0.049912 ; Training Acc: 28.180\n",
      "Iteration: 229 /1000;  Testing Loss: 0.061131 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 230 /1000;  Training Loss: 0.049915 ; Training Acc: 25.049\n",
      "Iteration: 230 /1000;  Testing Loss: 0.061169 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 231 /1000;  Training Loss: 0.049888 ; Training Acc: 28.571\n",
      "Iteration: 231 /1000;  Testing Loss: 0.061122 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 232 /1000;  Training Loss: 0.049928 ; Training Acc: 29.746\n",
      "Iteration: 232 /1000;  Testing Loss: 0.061172 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 233 /1000;  Training Loss: 0.049863 ; Training Acc: 24.853\n",
      "Iteration: 233 /1000;  Testing Loss: 0.061206 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 234 /1000;  Training Loss: 0.049872 ; Training Acc: 28.180\n",
      "Iteration: 234 /1000;  Testing Loss: 0.061089 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 235 /1000;  Training Loss: 0.049871 ; Training Acc: 27.006\n",
      "Iteration: 235 /1000;  Testing Loss: 0.061148 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 236 /1000;  Training Loss: 0.049880 ; Training Acc: 28.180\n",
      "Iteration: 236 /1000;  Testing Loss: 0.061094 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 237 /1000;  Training Loss: 0.049870 ; Training Acc: 30.528\n",
      "Iteration: 237 /1000;  Testing Loss: 0.060955 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 238 /1000;  Training Loss: 0.049885 ; Training Acc: 25.049\n",
      "Iteration: 238 /1000;  Testing Loss: 0.061333 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 239 /1000;  Training Loss: 0.049870 ; Training Acc: 25.245\n",
      "Iteration: 239 /1000;  Testing Loss: 0.060948 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 240 /1000;  Training Loss: 0.049861 ; Training Acc: 27.397\n",
      "Iteration: 240 /1000;  Testing Loss: 0.061267 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 241 /1000;  Training Loss: 0.049820 ; Training Acc: 29.550\n",
      "Iteration: 241 /1000;  Testing Loss: 0.061188 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 242 /1000;  Training Loss: 0.049829 ; Training Acc: 24.266\n",
      "Iteration: 242 /1000;  Testing Loss: 0.061125 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 243 /1000;  Training Loss: 0.049826 ; Training Acc: 31.311\n",
      "Iteration: 243 /1000;  Testing Loss: 0.061104 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 244 /1000;  Training Loss: 0.049940 ; Training Acc: 32.094\n",
      "Iteration: 244 /1000;  Testing Loss: 0.061355 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 245 /1000;  Training Loss: 0.049938 ; Training Acc: 32.094\n",
      "Iteration: 245 /1000;  Testing Loss: 0.061095 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 246 /1000;  Training Loss: 0.049856 ; Training Acc: 28.376\n",
      "Iteration: 246 /1000;  Testing Loss: 0.061482 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 247 /1000;  Training Loss: 0.049757 ; Training Acc: 25.832\n",
      "Iteration: 247 /1000;  Testing Loss: 0.061087 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 248 /1000;  Training Loss: 0.049767 ; Training Acc: 28.376\n",
      "Iteration: 248 /1000;  Testing Loss: 0.061287 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 249 /1000;  Training Loss: 0.049842 ; Training Acc: 26.419\n",
      "Iteration: 249 /1000;  Testing Loss: 0.061377 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 250 /1000;  Training Loss: 0.049743 ; Training Acc: 26.027\n",
      "Iteration: 250 /1000;  Testing Loss: 0.061195 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 251 /1000;  Training Loss: 0.049702 ; Training Acc: 26.614\n",
      "Iteration: 251 /1000;  Testing Loss: 0.061780 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 252 /1000;  Training Loss: 0.049681 ; Training Acc: 27.006\n",
      "Iteration: 252 /1000;  Testing Loss: 0.061064 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 253 /1000;  Training Loss: 0.049639 ; Training Acc: 27.593\n",
      "Iteration: 253 /1000;  Testing Loss: 0.061463 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 254 /1000;  Training Loss: 0.049791 ; Training Acc: 26.027\n",
      "Iteration: 254 /1000;  Testing Loss: 0.061288 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 255 /1000;  Training Loss: 0.049767 ; Training Acc: 25.245\n",
      "Iteration: 255 /1000;  Testing Loss: 0.061219 ; Testing Acc: 25.564\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 256 /1000;  Training Loss: 0.049673 ; Training Acc: 24.853\n",
      "Iteration: 256 /1000;  Testing Loss: 0.061231 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 257 /1000;  Training Loss: 0.049693 ; Training Acc: 22.896\n",
      "Iteration: 257 /1000;  Testing Loss: 0.061134 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 258 /1000;  Training Loss: 0.049705 ; Training Acc: 27.789\n",
      "Iteration: 258 /1000;  Testing Loss: 0.060911 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 259 /1000;  Training Loss: 0.049605 ; Training Acc: 26.223\n",
      "Iteration: 259 /1000;  Testing Loss: 0.061387 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 260 /1000;  Training Loss: 0.049714 ; Training Acc: 28.571\n",
      "Iteration: 260 /1000;  Testing Loss: 0.061074 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 261 /1000;  Training Loss: 0.049592 ; Training Acc: 27.984\n",
      "Iteration: 261 /1000;  Testing Loss: 0.061011 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 262 /1000;  Training Loss: 0.049753 ; Training Acc: 27.789\n",
      "Iteration: 262 /1000;  Testing Loss: 0.061222 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 263 /1000;  Training Loss: 0.049603 ; Training Acc: 24.853\n",
      "Iteration: 263 /1000;  Testing Loss: 0.061023 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 264 /1000;  Training Loss: 0.049647 ; Training Acc: 28.571\n",
      "Iteration: 264 /1000;  Testing Loss: 0.061174 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 265 /1000;  Training Loss: 0.049694 ; Training Acc: 25.440\n",
      "Iteration: 265 /1000;  Testing Loss: 0.060883 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 266 /1000;  Training Loss: 0.049551 ; Training Acc: 29.550\n",
      "Iteration: 266 /1000;  Testing Loss: 0.061456 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 267 /1000;  Training Loss: 0.049653 ; Training Acc: 26.419\n",
      "Iteration: 267 /1000;  Testing Loss: 0.060654 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 268 /1000;  Training Loss: 0.049755 ; Training Acc: 26.614\n",
      "Iteration: 268 /1000;  Testing Loss: 0.061104 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 269 /1000;  Training Loss: 0.049548 ; Training Acc: 29.550\n",
      "Iteration: 269 /1000;  Testing Loss: 0.061020 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 270 /1000;  Training Loss: 0.049462 ; Training Acc: 26.810\n",
      "Iteration: 270 /1000;  Testing Loss: 0.061047 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 271 /1000;  Training Loss: 0.049523 ; Training Acc: 25.440\n",
      "Iteration: 271 /1000;  Testing Loss: 0.061351 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 272 /1000;  Training Loss: 0.049529 ; Training Acc: 26.614\n",
      "Iteration: 272 /1000;  Testing Loss: 0.061543 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 273 /1000;  Training Loss: 0.049371 ; Training Acc: 28.376\n",
      "Iteration: 273 /1000;  Testing Loss: 0.060798 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 274 /1000;  Training Loss: 0.049415 ; Training Acc: 27.202\n",
      "Iteration: 274 /1000;  Testing Loss: 0.060939 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 275 /1000;  Training Loss: 0.049423 ; Training Acc: 28.571\n",
      "Iteration: 275 /1000;  Testing Loss: 0.060850 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 276 /1000;  Training Loss: 0.049804 ; Training Acc: 22.896\n",
      "Iteration: 276 /1000;  Testing Loss: 0.060481 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 277 /1000;  Training Loss: 0.049534 ; Training Acc: 25.049\n",
      "Iteration: 277 /1000;  Testing Loss: 0.061113 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 278 /1000;  Training Loss: 0.049381 ; Training Acc: 24.853\n",
      "Iteration: 278 /1000;  Testing Loss: 0.060425 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 279 /1000;  Training Loss: 0.049474 ; Training Acc: 24.658\n",
      "Iteration: 279 /1000;  Testing Loss: 0.061482 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 280 /1000;  Training Loss: 0.049326 ; Training Acc: 29.354\n",
      "Iteration: 280 /1000;  Testing Loss: 0.060810 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 281 /1000;  Training Loss: 0.049344 ; Training Acc: 26.419\n",
      "Iteration: 281 /1000;  Testing Loss: 0.060282 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 282 /1000;  Training Loss: 0.049404 ; Training Acc: 25.049\n",
      "Iteration: 282 /1000;  Testing Loss: 0.061163 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 283 /1000;  Training Loss: 0.049408 ; Training Acc: 28.376\n",
      "Iteration: 283 /1000;  Testing Loss: 0.060709 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 284 /1000;  Training Loss: 0.049336 ; Training Acc: 28.767\n",
      "Iteration: 284 /1000;  Testing Loss: 0.060961 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 285 /1000;  Training Loss: 0.049217 ; Training Acc: 30.333\n",
      "Iteration: 285 /1000;  Testing Loss: 0.060390 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 286 /1000;  Training Loss: 0.049206 ; Training Acc: 27.789\n",
      "Iteration: 286 /1000;  Testing Loss: 0.060529 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 287 /1000;  Training Loss: 0.049163 ; Training Acc: 28.963\n",
      "Iteration: 287 /1000;  Testing Loss: 0.060667 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 288 /1000;  Training Loss: 0.049211 ; Training Acc: 27.397\n",
      "Iteration: 288 /1000;  Testing Loss: 0.060398 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 289 /1000;  Training Loss: 0.049546 ; Training Acc: 24.658\n",
      "Iteration: 289 /1000;  Testing Loss: 0.060702 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 290 /1000;  Training Loss: 0.049366 ; Training Acc: 24.853\n",
      "Iteration: 290 /1000;  Testing Loss: 0.061169 ; Testing Acc: 26.316\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 291 /1000;  Training Loss: 0.049280 ; Training Acc: 27.006\n",
      "Iteration: 291 /1000;  Testing Loss: 0.061026 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 292 /1000;  Training Loss: 0.049167 ; Training Acc: 27.593\n",
      "Iteration: 292 /1000;  Testing Loss: 0.060167 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 293 /1000;  Training Loss: 0.049141 ; Training Acc: 28.767\n",
      "Iteration: 293 /1000;  Testing Loss: 0.060058 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 294 /1000;  Training Loss: 0.049066 ; Training Acc: 28.180\n",
      "Iteration: 294 /1000;  Testing Loss: 0.060571 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 295 /1000;  Training Loss: 0.049074 ; Training Acc: 28.571\n",
      "Iteration: 295 /1000;  Testing Loss: 0.060285 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 296 /1000;  Training Loss: 0.049184 ; Training Acc: 28.767\n",
      "Iteration: 296 /1000;  Testing Loss: 0.059992 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 297 /1000;  Training Loss: 0.048982 ; Training Acc: 29.941\n",
      "Iteration: 297 /1000;  Testing Loss: 0.060176 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 298 /1000;  Training Loss: 0.049348 ; Training Acc: 25.636\n",
      "Iteration: 298 /1000;  Testing Loss: 0.060087 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 299 /1000;  Training Loss: 0.048854 ; Training Acc: 31.115\n",
      "Iteration: 299 /1000;  Testing Loss: 0.061542 ; Testing Acc: 34.586\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 300 /1000;  Training Loss: 0.049173 ; Training Acc: 27.984\n",
      "Iteration: 300 /1000;  Testing Loss: 0.060602 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 301 /1000;  Training Loss: 0.048875 ; Training Acc: 31.703\n",
      "Iteration: 301 /1000;  Testing Loss: 0.059850 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 302 /1000;  Training Loss: 0.048896 ; Training Acc: 28.376\n",
      "Iteration: 302 /1000;  Testing Loss: 0.060272 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 303 /1000;  Training Loss: 0.048742 ; Training Acc: 27.006\n",
      "Iteration: 303 /1000;  Testing Loss: 0.061390 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 304 /1000;  Training Loss: 0.048818 ; Training Acc: 31.507\n",
      "Iteration: 304 /1000;  Testing Loss: 0.060470 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 305 /1000;  Training Loss: 0.048939 ; Training Acc: 31.115\n",
      "Iteration: 305 /1000;  Testing Loss: 0.059522 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 306 /1000;  Training Loss: 0.048917 ; Training Acc: 27.397\n",
      "Iteration: 306 /1000;  Testing Loss: 0.059315 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 309 /1000;  Training Loss: 0.048547 ; Training Acc: 28.963\n",
      "Iteration: 309 /1000;  Testing Loss: 0.059725 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 310 /1000;  Training Loss: 0.048471 ; Training Acc: 28.376\n",
      "Iteration: 310 /1000;  Testing Loss: 0.060638 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 311 /1000;  Training Loss: 0.048603 ; Training Acc: 30.724\n",
      "Iteration: 311 /1000;  Testing Loss: 0.058938 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 312 /1000;  Training Loss: 0.048534 ; Training Acc: 27.397\n",
      "Iteration: 312 /1000;  Testing Loss: 0.061837 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 313 /1000;  Training Loss: 0.048380 ; Training Acc: 28.571\n",
      "Iteration: 313 /1000;  Testing Loss: 0.059955 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 314 /1000;  Training Loss: 0.048181 ; Training Acc: 28.767\n",
      "Iteration: 314 /1000;  Testing Loss: 0.058703 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 315 /1000;  Training Loss: 0.048599 ; Training Acc: 26.614\n",
      "Iteration: 315 /1000;  Testing Loss: 0.060798 ; Testing Acc: 31.579\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 316 /1000;  Training Loss: 0.049698 ; Training Acc: 22.896\n",
      "Iteration: 316 /1000;  Testing Loss: 0.062037 ; Testing Acc: 27.068\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 317 /1000;  Training Loss: 0.048616 ; Training Acc: 28.376\n",
      "Iteration: 317 /1000;  Testing Loss: 0.061313 ; Testing Acc: 28.571\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 318 /1000;  Training Loss: 0.048546 ; Training Acc: 29.159\n",
      "Iteration: 318 /1000;  Testing Loss: 0.059267 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 319 /1000;  Training Loss: 0.047984 ; Training Acc: 32.290\n",
      "Iteration: 319 /1000;  Testing Loss: 0.059272 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 320 /1000;  Training Loss: 0.048916 ; Training Acc: 27.006\n",
      "Iteration: 320 /1000;  Testing Loss: 0.058429 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 321 /1000;  Training Loss: 0.048242 ; Training Acc: 29.941\n",
      "Iteration: 321 /1000;  Testing Loss: 0.058586 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 322 /1000;  Training Loss: 0.048047 ; Training Acc: 30.724\n",
      "Iteration: 322 /1000;  Testing Loss: 0.058791 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 323 /1000;  Training Loss: 0.048295 ; Training Acc: 29.550\n",
      "Iteration: 323 /1000;  Testing Loss: 0.058895 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 324 /1000;  Training Loss: 0.047823 ; Training Acc: 30.724\n",
      "Iteration: 324 /1000;  Testing Loss: 0.058751 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 325 /1000;  Training Loss: 0.047651 ; Training Acc: 34.442\n",
      "Iteration: 325 /1000;  Testing Loss: 0.059002 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 326 /1000;  Training Loss: 0.047571 ; Training Acc: 31.898\n",
      "Iteration: 326 /1000;  Testing Loss: 0.058447 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 327 /1000;  Training Loss: 0.047453 ; Training Acc: 34.638\n",
      "Iteration: 327 /1000;  Testing Loss: 0.057986 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 328 /1000;  Training Loss: 0.047585 ; Training Acc: 30.333\n",
      "Iteration: 328 /1000;  Testing Loss: 0.057723 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 329 /1000;  Training Loss: 0.047025 ; Training Acc: 32.877\n",
      "Iteration: 329 /1000;  Testing Loss: 0.057269 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 330 /1000;  Training Loss: 0.047634 ; Training Acc: 29.550\n",
      "Iteration: 330 /1000;  Testing Loss: 0.058234 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 331 /1000;  Training Loss: 0.047931 ; Training Acc: 32.290\n",
      "Iteration: 331 /1000;  Testing Loss: 0.057648 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 332 /1000;  Training Loss: 0.046924 ; Training Acc: 32.877\n",
      "Iteration: 332 /1000;  Testing Loss: 0.056886 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 333 /1000;  Training Loss: 0.046677 ; Training Acc: 35.421\n",
      "Iteration: 333 /1000;  Testing Loss: 0.057532 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 334 /1000;  Training Loss: 0.046837 ; Training Acc: 31.507\n",
      "Iteration: 334 /1000;  Testing Loss: 0.056397 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 335 /1000;  Training Loss: 0.047217 ; Training Acc: 30.333\n",
      "Iteration: 335 /1000;  Testing Loss: 0.056759 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 336 /1000;  Training Loss: 0.048412 ; Training Acc: 29.941\n",
      "Iteration: 336 /1000;  Testing Loss: 0.059886 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 337 /1000;  Training Loss: 0.047794 ; Training Acc: 28.767\n",
      "Iteration: 337 /1000;  Testing Loss: 0.060885 ; Testing Acc: 30.075\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 338 /1000;  Training Loss: 0.048432 ; Training Acc: 27.593\n",
      "Iteration: 338 /1000;  Testing Loss: 0.055408 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 339 /1000;  Training Loss: 0.046592 ; Training Acc: 34.442\n",
      "Iteration: 339 /1000;  Testing Loss: 0.055616 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 340 /1000;  Training Loss: 0.046023 ; Training Acc: 32.877\n",
      "Iteration: 340 /1000;  Testing Loss: 0.056734 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 341 /1000;  Training Loss: 0.046290 ; Training Acc: 31.507\n",
      "Iteration: 341 /1000;  Testing Loss: 0.055449 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 342 /1000;  Training Loss: 0.045983 ; Training Acc: 33.659\n",
      "Iteration: 342 /1000;  Testing Loss: 0.055384 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 343 /1000;  Training Loss: 0.045836 ; Training Acc: 32.290\n",
      "Iteration: 343 /1000;  Testing Loss: 0.056204 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 344 /1000;  Training Loss: 0.045675 ; Training Acc: 33.268\n",
      "Iteration: 344 /1000;  Testing Loss: 0.053618 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 345 /1000;  Training Loss: 0.045400 ; Training Acc: 33.659\n",
      "Iteration: 345 /1000;  Testing Loss: 0.055660 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 346 /1000;  Training Loss: 0.045887 ; Training Acc: 30.137\n",
      "Iteration: 346 /1000;  Testing Loss: 0.056635 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 347 /1000;  Training Loss: 0.047596 ; Training Acc: 31.115\n",
      "Iteration: 347 /1000;  Testing Loss: 0.057098 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 348 /1000;  Training Loss: 0.046783 ; Training Acc: 30.920\n",
      "Iteration: 348 /1000;  Testing Loss: 0.053420 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 349 /1000;  Training Loss: 0.046621 ; Training Acc: 31.311\n",
      "Iteration: 349 /1000;  Testing Loss: 0.056196 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 350 /1000;  Training Loss: 0.046749 ; Training Acc: 33.072\n",
      "Iteration: 350 /1000;  Testing Loss: 0.057779 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 351 /1000;  Training Loss: 0.045677 ; Training Acc: 36.204\n",
      "Iteration: 351 /1000;  Testing Loss: 0.054205 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 352 /1000;  Training Loss: 0.044994 ; Training Acc: 34.638\n",
      "Iteration: 352 /1000;  Testing Loss: 0.053702 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 353 /1000;  Training Loss: 0.044265 ; Training Acc: 38.748\n",
      "Iteration: 353 /1000;  Testing Loss: 0.052958 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 354 /1000;  Training Loss: 0.044855 ; Training Acc: 35.812\n",
      "Iteration: 354 /1000;  Testing Loss: 0.053400 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 355 /1000;  Training Loss: 0.044958 ; Training Acc: 36.791\n",
      "Iteration: 355 /1000;  Testing Loss: 0.054589 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 356 /1000;  Training Loss: 0.044856 ; Training Acc: 36.986\n",
      "Iteration: 356 /1000;  Testing Loss: 0.053133 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 357 /1000;  Training Loss: 0.044213 ; Training Acc: 38.943\n",
      "Iteration: 357 /1000;  Testing Loss: 0.051651 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 358 /1000;  Training Loss: 0.044172 ; Training Acc: 36.204\n",
      "Iteration: 358 /1000;  Testing Loss: 0.053838 ; Testing Acc: 30.827\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 359 /1000;  Training Loss: 0.044567 ; Training Acc: 38.356\n",
      "Iteration: 359 /1000;  Testing Loss: 0.051433 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 360 /1000;  Training Loss: 0.043524 ; Training Acc: 40.117\n",
      "Iteration: 360 /1000;  Testing Loss: 0.053355 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 361 /1000;  Training Loss: 0.045226 ; Training Acc: 33.464\n",
      "Iteration: 361 /1000;  Testing Loss: 0.056604 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 362 /1000;  Training Loss: 0.044706 ; Training Acc: 33.855\n",
      "Iteration: 362 /1000;  Testing Loss: 0.052084 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 363 /1000;  Training Loss: 0.043256 ; Training Acc: 41.487\n",
      "Iteration: 363 /1000;  Testing Loss: 0.050684 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 364 /1000;  Training Loss: 0.043095 ; Training Acc: 40.509\n",
      "Iteration: 364 /1000;  Testing Loss: 0.051133 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 365 /1000;  Training Loss: 0.043278 ; Training Acc: 38.160\n",
      "Iteration: 365 /1000;  Testing Loss: 0.050660 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 366 /1000;  Training Loss: 0.043546 ; Training Acc: 40.313\n",
      "Iteration: 366 /1000;  Testing Loss: 0.053577 ; Testing Acc: 35.338\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 367 /1000;  Training Loss: 0.045801 ; Training Acc: 35.029\n",
      "Iteration: 367 /1000;  Testing Loss: 0.051186 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 368 /1000;  Training Loss: 0.043863 ; Training Acc: 38.943\n",
      "Iteration: 368 /1000;  Testing Loss: 0.050509 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 369 /1000;  Training Loss: 0.043166 ; Training Acc: 37.965\n",
      "Iteration: 369 /1000;  Testing Loss: 0.055681 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 370 /1000;  Training Loss: 0.043117 ; Training Acc: 39.139\n",
      "Iteration: 370 /1000;  Testing Loss: 0.052524 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 371 /1000;  Training Loss: 0.043447 ; Training Acc: 36.008\n",
      "Iteration: 371 /1000;  Testing Loss: 0.051225 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 372 /1000;  Training Loss: 0.042995 ; Training Acc: 36.986\n",
      "Iteration: 372 /1000;  Testing Loss: 0.051486 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 373 /1000;  Training Loss: 0.042481 ; Training Acc: 36.204\n",
      "Iteration: 373 /1000;  Testing Loss: 0.051241 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 374 /1000;  Training Loss: 0.043756 ; Training Acc: 36.204\n",
      "Iteration: 374 /1000;  Testing Loss: 0.049979 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 375 /1000;  Training Loss: 0.043146 ; Training Acc: 36.008\n",
      "Iteration: 375 /1000;  Testing Loss: 0.050653 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 376 /1000;  Training Loss: 0.042401 ; Training Acc: 37.965\n",
      "Iteration: 376 /1000;  Testing Loss: 0.049979 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 377 /1000;  Training Loss: 0.043331 ; Training Acc: 36.595\n",
      "Iteration: 377 /1000;  Testing Loss: 0.049821 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 378 /1000;  Training Loss: 0.042705 ; Training Acc: 37.965\n",
      "Iteration: 378 /1000;  Testing Loss: 0.050307 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 379 /1000;  Training Loss: 0.042011 ; Training Acc: 37.182\n",
      "Iteration: 379 /1000;  Testing Loss: 0.049460 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 380 /1000;  Training Loss: 0.043162 ; Training Acc: 36.399\n",
      "Iteration: 380 /1000;  Testing Loss: 0.052246 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 381 /1000;  Training Loss: 0.042262 ; Training Acc: 34.834\n",
      "Iteration: 381 /1000;  Testing Loss: 0.050245 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 382 /1000;  Training Loss: 0.042160 ; Training Acc: 36.595\n",
      "Iteration: 382 /1000;  Testing Loss: 0.050218 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 383 /1000;  Training Loss: 0.042237 ; Training Acc: 37.573\n",
      "Iteration: 383 /1000;  Testing Loss: 0.049488 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 384 /1000;  Training Loss: 0.041743 ; Training Acc: 38.160\n",
      "Iteration: 384 /1000;  Testing Loss: 0.050254 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 385 /1000;  Training Loss: 0.042085 ; Training Acc: 36.595\n",
      "Iteration: 385 /1000;  Testing Loss: 0.049202 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 386 /1000;  Training Loss: 0.041933 ; Training Acc: 36.399\n",
      "Iteration: 386 /1000;  Testing Loss: 0.049275 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 387 /1000;  Training Loss: 0.046309 ; Training Acc: 30.724\n",
      "Iteration: 387 /1000;  Testing Loss: 0.049716 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 388 /1000;  Training Loss: 0.042108 ; Training Acc: 36.204\n",
      "Iteration: 388 /1000;  Testing Loss: 0.056545 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 389 /1000;  Training Loss: 0.042091 ; Training Acc: 36.399\n",
      "Iteration: 389 /1000;  Testing Loss: 0.051378 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 390 /1000;  Training Loss: 0.042445 ; Training Acc: 36.204\n",
      "Iteration: 390 /1000;  Testing Loss: 0.049068 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 391 /1000;  Training Loss: 0.041818 ; Training Acc: 36.399\n",
      "Iteration: 391 /1000;  Testing Loss: 0.049066 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 392 /1000;  Training Loss: 0.041768 ; Training Acc: 37.573\n",
      "Iteration: 392 /1000;  Testing Loss: 0.050450 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 393 /1000;  Training Loss: 0.042865 ; Training Acc: 35.421\n",
      "Iteration: 393 /1000;  Testing Loss: 0.051103 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 394 /1000;  Training Loss: 0.042764 ; Training Acc: 35.421\n",
      "Iteration: 394 /1000;  Testing Loss: 0.049202 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 395 /1000;  Training Loss: 0.041503 ; Training Acc: 34.638\n",
      "Iteration: 395 /1000;  Testing Loss: 0.048946 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 396 /1000;  Training Loss: 0.041596 ; Training Acc: 35.616\n",
      "Iteration: 396 /1000;  Testing Loss: 0.048903 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 397 /1000;  Training Loss: 0.041649 ; Training Acc: 37.182\n",
      "Iteration: 397 /1000;  Testing Loss: 0.049745 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 398 /1000;  Training Loss: 0.041384 ; Training Acc: 37.378\n",
      "Iteration: 398 /1000;  Testing Loss: 0.050279 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 399 /1000;  Training Loss: 0.041638 ; Training Acc: 37.378\n",
      "Iteration: 399 /1000;  Testing Loss: 0.053527 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 400 /1000;  Training Loss: 0.043421 ; Training Acc: 35.812\n",
      "Iteration: 400 /1000;  Testing Loss: 0.049798 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 401 /1000;  Training Loss: 0.041546 ; Training Acc: 36.008\n",
      "Iteration: 401 /1000;  Testing Loss: 0.049884 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 402 /1000;  Training Loss: 0.041454 ; Training Acc: 39.922\n",
      "Iteration: 402 /1000;  Testing Loss: 0.049089 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 403 /1000;  Training Loss: 0.043140 ; Training Acc: 36.399\n",
      "Iteration: 403 /1000;  Testing Loss: 0.050583 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 404 /1000;  Training Loss: 0.040897 ; Training Acc: 37.182\n",
      "Iteration: 404 /1000;  Testing Loss: 0.048407 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 405 /1000;  Training Loss: 0.040523 ; Training Acc: 37.182\n",
      "Iteration: 405 /1000;  Testing Loss: 0.048639 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 406 /1000;  Training Loss: 0.040805 ; Training Acc: 36.204\n",
      "Iteration: 406 /1000;  Testing Loss: 0.048144 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 407 /1000;  Training Loss: 0.040565 ; Training Acc: 37.573\n",
      "Iteration: 407 /1000;  Testing Loss: 0.049082 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 408 /1000;  Training Loss: 0.040994 ; Training Acc: 39.139\n",
      "Iteration: 408 /1000;  Testing Loss: 0.049117 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 409 /1000;  Training Loss: 0.040623 ; Training Acc: 37.182\n",
      "Iteration: 409 /1000;  Testing Loss: 0.048744 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 410 /1000;  Training Loss: 0.040905 ; Training Acc: 37.182\n",
      "Iteration: 410 /1000;  Testing Loss: 0.048463 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 411 /1000;  Training Loss: 0.040899 ; Training Acc: 36.986\n",
      "Iteration: 411 /1000;  Testing Loss: 0.048151 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 412 /1000;  Training Loss: 0.040581 ; Training Acc: 36.595\n",
      "Iteration: 412 /1000;  Testing Loss: 0.049709 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 413 /1000;  Training Loss: 0.040754 ; Training Acc: 36.791\n",
      "Iteration: 413 /1000;  Testing Loss: 0.047886 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 414 /1000;  Training Loss: 0.040562 ; Training Acc: 40.313\n",
      "Iteration: 414 /1000;  Testing Loss: 0.048870 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 415 /1000;  Training Loss: 0.040222 ; Training Acc: 36.986\n",
      "Iteration: 415 /1000;  Testing Loss: 0.048101 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 416 /1000;  Training Loss: 0.040012 ; Training Acc: 37.965\n",
      "Iteration: 416 /1000;  Testing Loss: 0.048934 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 417 /1000;  Training Loss: 0.040569 ; Training Acc: 38.356\n",
      "Iteration: 417 /1000;  Testing Loss: 0.050198 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 418 /1000;  Training Loss: 0.041179 ; Training Acc: 35.029\n",
      "Iteration: 418 /1000;  Testing Loss: 0.047705 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 419 /1000;  Training Loss: 0.041989 ; Training Acc: 36.399\n",
      "Iteration: 419 /1000;  Testing Loss: 0.048817 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 420 /1000;  Training Loss: 0.040801 ; Training Acc: 36.986\n",
      "Iteration: 420 /1000;  Testing Loss: 0.048328 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 421 /1000;  Training Loss: 0.040011 ; Training Acc: 36.791\n",
      "Iteration: 421 /1000;  Testing Loss: 0.048481 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 422 /1000;  Training Loss: 0.042370 ; Training Acc: 36.204\n",
      "Iteration: 422 /1000;  Testing Loss: 0.052220 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 423 /1000;  Training Loss: 0.042262 ; Training Acc: 35.616\n",
      "Iteration: 423 /1000;  Testing Loss: 0.049346 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 424 /1000;  Training Loss: 0.039699 ; Training Acc: 36.204\n",
      "Iteration: 424 /1000;  Testing Loss: 0.049095 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 425 /1000;  Training Loss: 0.040444 ; Training Acc: 37.769\n",
      "Iteration: 425 /1000;  Testing Loss: 0.048510 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 426 /1000;  Training Loss: 0.039789 ; Training Acc: 38.748\n",
      "Iteration: 426 /1000;  Testing Loss: 0.047309 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 427 /1000;  Training Loss: 0.039886 ; Training Acc: 37.965\n",
      "Iteration: 427 /1000;  Testing Loss: 0.048231 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 428 /1000;  Training Loss: 0.040513 ; Training Acc: 36.204\n",
      "Iteration: 428 /1000;  Testing Loss: 0.050272 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 429 /1000;  Training Loss: 0.043534 ; Training Acc: 34.638\n",
      "Iteration: 429 /1000;  Testing Loss: 0.057221 ; Testing Acc: 33.083\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 430 /1000;  Training Loss: 0.042338 ; Training Acc: 34.247\n",
      "Iteration: 430 /1000;  Testing Loss: 0.048896 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 431 /1000;  Training Loss: 0.039670 ; Training Acc: 37.965\n",
      "Iteration: 431 /1000;  Testing Loss: 0.047170 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 432 /1000;  Training Loss: 0.041218 ; Training Acc: 38.356\n",
      "Iteration: 432 /1000;  Testing Loss: 0.049863 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 433 /1000;  Training Loss: 0.040326 ; Training Acc: 35.421\n",
      "Iteration: 433 /1000;  Testing Loss: 0.047068 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 434 /1000;  Training Loss: 0.042161 ; Training Acc: 34.834\n",
      "Iteration: 434 /1000;  Testing Loss: 0.048504 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 435 /1000;  Training Loss: 0.040378 ; Training Acc: 36.204\n",
      "Iteration: 435 /1000;  Testing Loss: 0.047274 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 436 /1000;  Training Loss: 0.040196 ; Training Acc: 36.595\n",
      "Iteration: 436 /1000;  Testing Loss: 0.047055 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 437 /1000;  Training Loss: 0.039761 ; Training Acc: 36.008\n",
      "Iteration: 437 /1000;  Testing Loss: 0.047794 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 438 /1000;  Training Loss: 0.039396 ; Training Acc: 38.748\n",
      "Iteration: 438 /1000;  Testing Loss: 0.047661 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 439 /1000;  Training Loss: 0.039853 ; Training Acc: 37.965\n",
      "Iteration: 439 /1000;  Testing Loss: 0.047315 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 440 /1000;  Training Loss: 0.040654 ; Training Acc: 37.573\n",
      "Iteration: 440 /1000;  Testing Loss: 0.051714 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 441 /1000;  Training Loss: 0.040718 ; Training Acc: 37.965\n",
      "Iteration: 441 /1000;  Testing Loss: 0.047082 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 442 /1000;  Training Loss: 0.039703 ; Training Acc: 40.509\n",
      "Iteration: 442 /1000;  Testing Loss: 0.046709 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 443 /1000;  Training Loss: 0.039342 ; Training Acc: 40.313\n",
      "Iteration: 443 /1000;  Testing Loss: 0.046844 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 444 /1000;  Training Loss: 0.038945 ; Training Acc: 39.335\n",
      "Iteration: 444 /1000;  Testing Loss: 0.048160 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 445 /1000;  Training Loss: 0.038956 ; Training Acc: 39.139\n",
      "Iteration: 445 /1000;  Testing Loss: 0.048275 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 446 /1000;  Training Loss: 0.039137 ; Training Acc: 37.573\n",
      "Iteration: 446 /1000;  Testing Loss: 0.048210 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 447 /1000;  Training Loss: 0.039915 ; Training Acc: 37.573\n",
      "Iteration: 447 /1000;  Testing Loss: 0.052378 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 448 /1000;  Training Loss: 0.040840 ; Training Acc: 36.204\n",
      "Iteration: 448 /1000;  Testing Loss: 0.048679 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 449 /1000;  Training Loss: 0.039499 ; Training Acc: 36.595\n",
      "Iteration: 449 /1000;  Testing Loss: 0.047593 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 450 /1000;  Training Loss: 0.038644 ; Training Acc: 40.509\n",
      "Iteration: 450 /1000;  Testing Loss: 0.048390 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 451 /1000;  Training Loss: 0.041047 ; Training Acc: 39.335\n",
      "Iteration: 451 /1000;  Testing Loss: 0.047594 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 452 /1000;  Training Loss: 0.040114 ; Training Acc: 39.530\n",
      "Iteration: 452 /1000;  Testing Loss: 0.046593 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 453 /1000;  Training Loss: 0.039572 ; Training Acc: 38.552\n",
      "Iteration: 453 /1000;  Testing Loss: 0.046901 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 454 /1000;  Training Loss: 0.040368 ; Training Acc: 37.378\n",
      "Iteration: 454 /1000;  Testing Loss: 0.048995 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 455 /1000;  Training Loss: 0.040904 ; Training Acc: 37.769\n",
      "Iteration: 455 /1000;  Testing Loss: 0.046559 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 456 /1000;  Training Loss: 0.039767 ; Training Acc: 36.204\n",
      "Iteration: 456 /1000;  Testing Loss: 0.049322 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 457 /1000;  Training Loss: 0.038838 ; Training Acc: 41.096\n",
      "Iteration: 457 /1000;  Testing Loss: 0.047112 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 458 /1000;  Training Loss: 0.039066 ; Training Acc: 42.857\n",
      "Iteration: 458 /1000;  Testing Loss: 0.047016 ; Testing Acc: 54.887\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 459 /1000;  Training Loss: 0.038350 ; Training Acc: 43.053\n",
      "Iteration: 459 /1000;  Testing Loss: 0.046895 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 460 /1000;  Training Loss: 0.039512 ; Training Acc: 41.292\n",
      "Iteration: 460 /1000;  Testing Loss: 0.046554 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 461 /1000;  Training Loss: 0.038307 ; Training Acc: 40.313\n",
      "Iteration: 461 /1000;  Testing Loss: 0.047320 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 462 /1000;  Training Loss: 0.040751 ; Training Acc: 38.160\n",
      "Iteration: 462 /1000;  Testing Loss: 0.050499 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 463 /1000;  Training Loss: 0.040312 ; Training Acc: 36.595\n",
      "Iteration: 463 /1000;  Testing Loss: 0.046060 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 464 /1000;  Training Loss: 0.039867 ; Training Acc: 36.399\n",
      "Iteration: 464 /1000;  Testing Loss: 0.047091 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 465 /1000;  Training Loss: 0.038747 ; Training Acc: 37.573\n",
      "Iteration: 465 /1000;  Testing Loss: 0.046263 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 466 /1000;  Training Loss: 0.038213 ; Training Acc: 43.053\n",
      "Iteration: 466 /1000;  Testing Loss: 0.046816 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 467 /1000;  Training Loss: 0.038545 ; Training Acc: 44.423\n",
      "Iteration: 467 /1000;  Testing Loss: 0.046692 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 468 /1000;  Training Loss: 0.038343 ; Training Acc: 39.530\n",
      "Iteration: 468 /1000;  Testing Loss: 0.048063 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 469 /1000;  Training Loss: 0.038447 ; Training Acc: 41.487\n",
      "Iteration: 469 /1000;  Testing Loss: 0.047708 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 470 /1000;  Training Loss: 0.041023 ; Training Acc: 37.378\n",
      "Iteration: 470 /1000;  Testing Loss: 0.046377 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 471 /1000;  Training Loss: 0.041215 ; Training Acc: 38.748\n",
      "Iteration: 471 /1000;  Testing Loss: 0.046230 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 472 /1000;  Training Loss: 0.038857 ; Training Acc: 37.573\n",
      "Iteration: 472 /1000;  Testing Loss: 0.046021 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 473 /1000;  Training Loss: 0.038129 ; Training Acc: 41.683\n",
      "Iteration: 473 /1000;  Testing Loss: 0.046227 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 474 /1000;  Training Loss: 0.038541 ; Training Acc: 40.313\n",
      "Iteration: 474 /1000;  Testing Loss: 0.046267 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 475 /1000;  Training Loss: 0.038074 ; Training Acc: 41.096\n",
      "Iteration: 475 /1000;  Testing Loss: 0.046883 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 476 /1000;  Training Loss: 0.038915 ; Training Acc: 41.487\n",
      "Iteration: 476 /1000;  Testing Loss: 0.047365 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 477 /1000;  Training Loss: 0.038037 ; Training Acc: 40.900\n",
      "Iteration: 477 /1000;  Testing Loss: 0.049061 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 478 /1000;  Training Loss: 0.038729 ; Training Acc: 39.139\n",
      "Iteration: 478 /1000;  Testing Loss: 0.046765 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 479 /1000;  Training Loss: 0.038663 ; Training Acc: 38.943\n",
      "Iteration: 479 /1000;  Testing Loss: 0.048800 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 480 /1000;  Training Loss: 0.038534 ; Training Acc: 39.726\n",
      "Iteration: 480 /1000;  Testing Loss: 0.046252 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 481 /1000;  Training Loss: 0.038021 ; Training Acc: 41.487\n",
      "Iteration: 481 /1000;  Testing Loss: 0.046434 ; Testing Acc: 54.887\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 482 /1000;  Training Loss: 0.038396 ; Training Acc: 39.139\n",
      "Iteration: 482 /1000;  Testing Loss: 0.048260 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 483 /1000;  Training Loss: 0.038710 ; Training Acc: 38.356\n",
      "Iteration: 483 /1000;  Testing Loss: 0.048422 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 484 /1000;  Training Loss: 0.038629 ; Training Acc: 39.530\n",
      "Iteration: 484 /1000;  Testing Loss: 0.046602 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 485 /1000;  Training Loss: 0.038434 ; Training Acc: 39.139\n",
      "Iteration: 485 /1000;  Testing Loss: 0.046013 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 486 /1000;  Training Loss: 0.038885 ; Training Acc: 38.943\n",
      "Iteration: 486 /1000;  Testing Loss: 0.046037 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 487 /1000;  Training Loss: 0.038515 ; Training Acc: 38.748\n",
      "Iteration: 487 /1000;  Testing Loss: 0.047600 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 488 /1000;  Training Loss: 0.039832 ; Training Acc: 39.726\n",
      "Iteration: 488 /1000;  Testing Loss: 0.045825 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 489 /1000;  Training Loss: 0.038159 ; Training Acc: 39.726\n",
      "Iteration: 489 /1000;  Testing Loss: 0.045871 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 490 /1000;  Training Loss: 0.038036 ; Training Acc: 39.726\n",
      "Iteration: 490 /1000;  Testing Loss: 0.047079 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 491 /1000;  Training Loss: 0.038200 ; Training Acc: 41.096\n",
      "Iteration: 491 /1000;  Testing Loss: 0.046047 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 492 /1000;  Training Loss: 0.038564 ; Training Acc: 38.160\n",
      "Iteration: 492 /1000;  Testing Loss: 0.047508 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 493 /1000;  Training Loss: 0.038642 ; Training Acc: 40.900\n",
      "Iteration: 493 /1000;  Testing Loss: 0.049219 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 494 /1000;  Training Loss: 0.038870 ; Training Acc: 39.530\n",
      "Iteration: 494 /1000;  Testing Loss: 0.045994 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 495 /1000;  Training Loss: 0.038217 ; Training Acc: 42.270\n",
      "Iteration: 495 /1000;  Testing Loss: 0.048643 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 496 /1000;  Training Loss: 0.038743 ; Training Acc: 38.943\n",
      "Iteration: 496 /1000;  Testing Loss: 0.046962 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 497 /1000;  Training Loss: 0.037581 ; Training Acc: 41.096\n",
      "Iteration: 497 /1000;  Testing Loss: 0.046038 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 498 /1000;  Training Loss: 0.037772 ; Training Acc: 43.053\n",
      "Iteration: 498 /1000;  Testing Loss: 0.046493 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 499 /1000;  Training Loss: 0.037862 ; Training Acc: 44.227\n",
      "Iteration: 499 /1000;  Testing Loss: 0.048142 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 500 /1000;  Training Loss: 0.038899 ; Training Acc: 39.530\n",
      "Iteration: 500 /1000;  Testing Loss: 0.045874 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 501 /1000;  Training Loss: 0.037731 ; Training Acc: 42.661\n",
      "Iteration: 501 /1000;  Testing Loss: 0.046110 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 502 /1000;  Training Loss: 0.037703 ; Training Acc: 42.857\n",
      "Iteration: 502 /1000;  Testing Loss: 0.049145 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 503 /1000;  Training Loss: 0.038233 ; Training Acc: 42.466\n",
      "Iteration: 503 /1000;  Testing Loss: 0.046243 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 504 /1000;  Training Loss: 0.038269 ; Training Acc: 41.096\n",
      "Iteration: 504 /1000;  Testing Loss: 0.046046 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 505 /1000;  Training Loss: 0.037481 ; Training Acc: 42.466\n",
      "Iteration: 505 /1000;  Testing Loss: 0.046649 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 506 /1000;  Training Loss: 0.037349 ; Training Acc: 43.053\n",
      "Iteration: 506 /1000;  Testing Loss: 0.045996 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 507 /1000;  Training Loss: 0.037409 ; Training Acc: 43.836\n",
      "Iteration: 507 /1000;  Testing Loss: 0.046305 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 508 /1000;  Training Loss: 0.037220 ; Training Acc: 42.270\n",
      "Iteration: 508 /1000;  Testing Loss: 0.047411 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 509 /1000;  Training Loss: 0.037312 ; Training Acc: 43.836\n",
      "Iteration: 509 /1000;  Testing Loss: 0.048731 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 510 /1000;  Training Loss: 0.037598 ; Training Acc: 43.444\n",
      "Iteration: 510 /1000;  Testing Loss: 0.046123 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 511 /1000;  Training Loss: 0.037596 ; Training Acc: 44.618\n",
      "Iteration: 511 /1000;  Testing Loss: 0.045938 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 512 /1000;  Training Loss: 0.038003 ; Training Acc: 43.053\n",
      "Iteration: 512 /1000;  Testing Loss: 0.049053 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 513 /1000;  Training Loss: 0.037807 ; Training Acc: 39.726\n",
      "Iteration: 513 /1000;  Testing Loss: 0.046025 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 514 /1000;  Training Loss: 0.038031 ; Training Acc: 41.683\n",
      "Iteration: 514 /1000;  Testing Loss: 0.047456 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 515 /1000;  Training Loss: 0.039013 ; Training Acc: 36.399\n",
      "Iteration: 515 /1000;  Testing Loss: 0.049200 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 516 /1000;  Training Loss: 0.038283 ; Training Acc: 39.726\n",
      "Iteration: 516 /1000;  Testing Loss: 0.045740 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 517 /1000;  Training Loss: 0.037517 ; Training Acc: 45.205\n",
      "Iteration: 517 /1000;  Testing Loss: 0.046081 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 518 /1000;  Training Loss: 0.037918 ; Training Acc: 44.031\n",
      "Iteration: 518 /1000;  Testing Loss: 0.050742 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 519 /1000;  Training Loss: 0.040516 ; Training Acc: 37.378\n",
      "Iteration: 519 /1000;  Testing Loss: 0.045685 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 520 /1000;  Training Loss: 0.041497 ; Training Acc: 38.748\n",
      "Iteration: 520 /1000;  Testing Loss: 0.049990 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 521 /1000;  Training Loss: 0.037304 ; Training Acc: 41.096\n",
      "Iteration: 521 /1000;  Testing Loss: 0.045457 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 522 /1000;  Training Loss: 0.037602 ; Training Acc: 44.227\n",
      "Iteration: 522 /1000;  Testing Loss: 0.046120 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 523 /1000;  Training Loss: 0.038291 ; Training Acc: 40.313\n",
      "Iteration: 523 /1000;  Testing Loss: 0.047338 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 524 /1000;  Training Loss: 0.039067 ; Training Acc: 38.943\n",
      "Iteration: 524 /1000;  Testing Loss: 0.045640 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 525 /1000;  Training Loss: 0.037134 ; Training Acc: 40.900\n",
      "Iteration: 525 /1000;  Testing Loss: 0.049860 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 526 /1000;  Training Loss: 0.038494 ; Training Acc: 43.249\n",
      "Iteration: 526 /1000;  Testing Loss: 0.045519 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 527 /1000;  Training Loss: 0.036910 ; Training Acc: 46.380\n",
      "Iteration: 527 /1000;  Testing Loss: 0.045687 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 528 /1000;  Training Loss: 0.036645 ; Training Acc: 47.554\n",
      "Iteration: 528 /1000;  Testing Loss: 0.047456 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 529 /1000;  Training Loss: 0.037611 ; Training Acc: 45.205\n",
      "Iteration: 529 /1000;  Testing Loss: 0.046970 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 530 /1000;  Training Loss: 0.036879 ; Training Acc: 43.836\n",
      "Iteration: 530 /1000;  Testing Loss: 0.046053 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 531 /1000;  Training Loss: 0.037932 ; Training Acc: 42.074\n",
      "Iteration: 531 /1000;  Testing Loss: 0.046778 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 532 /1000;  Training Loss: 0.037244 ; Training Acc: 44.814\n",
      "Iteration: 532 /1000;  Testing Loss: 0.047365 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 533 /1000;  Training Loss: 0.037200 ; Training Acc: 42.661\n",
      "Iteration: 533 /1000;  Testing Loss: 0.045331 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 534 /1000;  Training Loss: 0.036438 ; Training Acc: 47.162\n",
      "Iteration: 534 /1000;  Testing Loss: 0.046628 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 535 /1000;  Training Loss: 0.037140 ; Training Acc: 46.575\n",
      "Iteration: 535 /1000;  Testing Loss: 0.045585 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 536 /1000;  Training Loss: 0.036547 ; Training Acc: 46.575\n",
      "Iteration: 536 /1000;  Testing Loss: 0.045589 ; Testing Acc: 56.391\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 537 /1000;  Training Loss: 0.037279 ; Training Acc: 44.423\n",
      "Iteration: 537 /1000;  Testing Loss: 0.045441 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 538 /1000;  Training Loss: 0.036488 ; Training Acc: 46.771\n",
      "Iteration: 538 /1000;  Testing Loss: 0.046806 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 539 /1000;  Training Loss: 0.037139 ; Training Acc: 45.010\n",
      "Iteration: 539 /1000;  Testing Loss: 0.048719 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 540 /1000;  Training Loss: 0.036631 ; Training Acc: 42.270\n",
      "Iteration: 540 /1000;  Testing Loss: 0.045771 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 541 /1000;  Training Loss: 0.036957 ; Training Acc: 42.661\n",
      "Iteration: 541 /1000;  Testing Loss: 0.046331 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 542 /1000;  Training Loss: 0.036627 ; Training Acc: 46.184\n",
      "Iteration: 542 /1000;  Testing Loss: 0.045855 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 543 /1000;  Training Loss: 0.036644 ; Training Acc: 45.597\n",
      "Iteration: 543 /1000;  Testing Loss: 0.045733 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 544 /1000;  Training Loss: 0.037667 ; Training Acc: 45.793\n",
      "Iteration: 544 /1000;  Testing Loss: 0.045674 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 545 /1000;  Training Loss: 0.036401 ; Training Acc: 45.205\n",
      "Iteration: 545 /1000;  Testing Loss: 0.046943 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 546 /1000;  Training Loss: 0.036702 ; Training Acc: 43.053\n",
      "Iteration: 546 /1000;  Testing Loss: 0.045592 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 547 /1000;  Training Loss: 0.036756 ; Training Acc: 44.814\n",
      "Iteration: 547 /1000;  Testing Loss: 0.045406 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 548 /1000;  Training Loss: 0.036416 ; Training Acc: 45.401\n",
      "Iteration: 548 /1000;  Testing Loss: 0.046029 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 549 /1000;  Training Loss: 0.036906 ; Training Acc: 45.988\n",
      "Iteration: 549 /1000;  Testing Loss: 0.047471 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 550 /1000;  Training Loss: 0.035977 ; Training Acc: 47.162\n",
      "Iteration: 550 /1000;  Testing Loss: 0.045837 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 551 /1000;  Training Loss: 0.036534 ; Training Acc: 46.967\n",
      "Iteration: 551 /1000;  Testing Loss: 0.045565 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 552 /1000;  Training Loss: 0.038847 ; Training Acc: 39.922\n",
      "Iteration: 552 /1000;  Testing Loss: 0.049630 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 553 /1000;  Training Loss: 0.036848 ; Training Acc: 41.487\n",
      "Iteration: 553 /1000;  Testing Loss: 0.045078 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 554 /1000;  Training Loss: 0.037163 ; Training Acc: 44.423\n",
      "Iteration: 554 /1000;  Testing Loss: 0.045627 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 555 /1000;  Training Loss: 0.036489 ; Training Acc: 45.793\n",
      "Iteration: 555 /1000;  Testing Loss: 0.045461 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 556 /1000;  Training Loss: 0.036231 ; Training Acc: 44.227\n",
      "Iteration: 556 /1000;  Testing Loss: 0.045406 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 557 /1000;  Training Loss: 0.036748 ; Training Acc: 45.205\n",
      "Iteration: 557 /1000;  Testing Loss: 0.045905 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 558 /1000;  Training Loss: 0.037496 ; Training Acc: 42.661\n",
      "Iteration: 558 /1000;  Testing Loss: 0.046882 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 559 /1000;  Training Loss: 0.037097 ; Training Acc: 42.661\n",
      "Iteration: 559 /1000;  Testing Loss: 0.045550 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 560 /1000;  Training Loss: 0.036223 ; Training Acc: 45.793\n",
      "Iteration: 560 /1000;  Testing Loss: 0.046412 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 561 /1000;  Training Loss: 0.036506 ; Training Acc: 45.401\n",
      "Iteration: 561 /1000;  Testing Loss: 0.046863 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 562 /1000;  Training Loss: 0.037205 ; Training Acc: 42.466\n",
      "Iteration: 562 /1000;  Testing Loss: 0.048539 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 563 /1000;  Training Loss: 0.037442 ; Training Acc: 44.031\n",
      "Iteration: 563 /1000;  Testing Loss: 0.044688 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 564 /1000;  Training Loss: 0.036882 ; Training Acc: 43.444\n",
      "Iteration: 564 /1000;  Testing Loss: 0.045687 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 565 /1000;  Training Loss: 0.036942 ; Training Acc: 44.031\n",
      "Iteration: 565 /1000;  Testing Loss: 0.049811 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 566 /1000;  Training Loss: 0.037760 ; Training Acc: 43.249\n",
      "Iteration: 566 /1000;  Testing Loss: 0.044879 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 567 /1000;  Training Loss: 0.037183 ; Training Acc: 44.814\n",
      "Iteration: 567 /1000;  Testing Loss: 0.046400 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 568 /1000;  Training Loss: 0.037064 ; Training Acc: 43.053\n",
      "Iteration: 568 /1000;  Testing Loss: 0.045218 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 569 /1000;  Training Loss: 0.036353 ; Training Acc: 46.575\n",
      "Iteration: 569 /1000;  Testing Loss: 0.045150 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 570 /1000;  Training Loss: 0.036588 ; Training Acc: 48.728\n",
      "Iteration: 570 /1000;  Testing Loss: 0.045675 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 571 /1000;  Training Loss: 0.037188 ; Training Acc: 44.618\n",
      "Iteration: 571 /1000;  Testing Loss: 0.046910 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 572 /1000;  Training Loss: 0.036302 ; Training Acc: 46.575\n",
      "Iteration: 572 /1000;  Testing Loss: 0.046552 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 573 /1000;  Training Loss: 0.036221 ; Training Acc: 45.988\n",
      "Iteration: 573 /1000;  Testing Loss: 0.045033 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 574 /1000;  Training Loss: 0.036671 ; Training Acc: 43.836\n",
      "Iteration: 574 /1000;  Testing Loss: 0.044979 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 575 /1000;  Training Loss: 0.036048 ; Training Acc: 46.967\n",
      "Iteration: 575 /1000;  Testing Loss: 0.047680 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 576 /1000;  Training Loss: 0.037536 ; Training Acc: 44.618\n",
      "Iteration: 576 /1000;  Testing Loss: 0.044975 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 577 /1000;  Training Loss: 0.036166 ; Training Acc: 45.010\n",
      "Iteration: 577 /1000;  Testing Loss: 0.044753 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 578 /1000;  Training Loss: 0.036289 ; Training Acc: 45.793\n",
      "Iteration: 578 /1000;  Testing Loss: 0.044964 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 579 /1000;  Training Loss: 0.036427 ; Training Acc: 45.988\n",
      "Iteration: 579 /1000;  Testing Loss: 0.045578 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 580 /1000;  Training Loss: 0.038061 ; Training Acc: 40.117\n",
      "Iteration: 580 /1000;  Testing Loss: 0.044775 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 581 /1000;  Training Loss: 0.036197 ; Training Acc: 44.814\n",
      "Iteration: 581 /1000;  Testing Loss: 0.045092 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 582 /1000;  Training Loss: 0.035800 ; Training Acc: 46.380\n",
      "Iteration: 582 /1000;  Testing Loss: 0.045014 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 583 /1000;  Training Loss: 0.035844 ; Training Acc: 47.358\n",
      "Iteration: 583 /1000;  Testing Loss: 0.045326 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 584 /1000;  Training Loss: 0.035794 ; Training Acc: 46.771\n",
      "Iteration: 584 /1000;  Testing Loss: 0.045192 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 585 /1000;  Training Loss: 0.036164 ; Training Acc: 46.380\n",
      "Iteration: 585 /1000;  Testing Loss: 0.046869 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 586 /1000;  Training Loss: 0.038018 ; Training Acc: 41.096\n",
      "Iteration: 586 /1000;  Testing Loss: 0.049294 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 587 /1000;  Training Loss: 0.036392 ; Training Acc: 46.771\n",
      "Iteration: 587 /1000;  Testing Loss: 0.045429 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 588 /1000;  Training Loss: 0.036027 ; Training Acc: 43.444\n",
      "Iteration: 588 /1000;  Testing Loss: 0.049732 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 589 /1000;  Training Loss: 0.035662 ; Training Acc: 48.337\n",
      "Iteration: 589 /1000;  Testing Loss: 0.045278 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 590 /1000;  Training Loss: 0.035717 ; Training Acc: 46.967\n",
      "Iteration: 590 /1000;  Testing Loss: 0.045210 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 591 /1000;  Training Loss: 0.036799 ; Training Acc: 44.423\n",
      "Iteration: 591 /1000;  Testing Loss: 0.046900 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 592 /1000;  Training Loss: 0.036003 ; Training Acc: 45.988\n",
      "Iteration: 592 /1000;  Testing Loss: 0.044971 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 593 /1000;  Training Loss: 0.035394 ; Training Acc: 45.988\n",
      "Iteration: 593 /1000;  Testing Loss: 0.045699 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 594 /1000;  Training Loss: 0.036841 ; Training Acc: 43.053\n",
      "Iteration: 594 /1000;  Testing Loss: 0.044975 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 595 /1000;  Training Loss: 0.037156 ; Training Acc: 43.249\n",
      "Iteration: 595 /1000;  Testing Loss: 0.045128 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 596 /1000;  Training Loss: 0.037095 ; Training Acc: 42.857\n",
      "Iteration: 596 /1000;  Testing Loss: 0.047328 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 597 /1000;  Training Loss: 0.036655 ; Training Acc: 43.836\n",
      "Iteration: 597 /1000;  Testing Loss: 0.044482 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 598 /1000;  Training Loss: 0.035865 ; Training Acc: 47.162\n",
      "Iteration: 598 /1000;  Testing Loss: 0.044836 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 599 /1000;  Training Loss: 0.037268 ; Training Acc: 42.661\n",
      "Iteration: 599 /1000;  Testing Loss: 0.044799 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 600 /1000;  Training Loss: 0.036266 ; Training Acc: 44.227\n",
      "Iteration: 600 /1000;  Testing Loss: 0.044951 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 601 /1000;  Training Loss: 0.035965 ; Training Acc: 45.401\n",
      "Iteration: 601 /1000;  Testing Loss: 0.045382 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 602 /1000;  Training Loss: 0.037586 ; Training Acc: 44.618\n",
      "Iteration: 602 /1000;  Testing Loss: 0.044249 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 603 /1000;  Training Loss: 0.036101 ; Training Acc: 45.401\n",
      "Iteration: 603 /1000;  Testing Loss: 0.050007 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 604 /1000;  Training Loss: 0.038852 ; Training Acc: 41.292\n",
      "Iteration: 604 /1000;  Testing Loss: 0.044562 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 605 /1000;  Training Loss: 0.036966 ; Training Acc: 43.836\n",
      "Iteration: 605 /1000;  Testing Loss: 0.044510 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 606 /1000;  Training Loss: 0.035594 ; Training Acc: 45.401\n",
      "Iteration: 606 /1000;  Testing Loss: 0.045701 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 607 /1000;  Training Loss: 0.036422 ; Training Acc: 45.205\n",
      "Iteration: 607 /1000;  Testing Loss: 0.045625 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 608 /1000;  Training Loss: 0.036000 ; Training Acc: 45.401\n",
      "Iteration: 608 /1000;  Testing Loss: 0.045444 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 609 /1000;  Training Loss: 0.035270 ; Training Acc: 46.575\n",
      "Iteration: 609 /1000;  Testing Loss: 0.044579 ; Testing Acc: 54.887\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 610 /1000;  Training Loss: 0.035592 ; Training Acc: 47.162\n",
      "Iteration: 610 /1000;  Testing Loss: 0.045381 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 611 /1000;  Training Loss: 0.035580 ; Training Acc: 45.205\n",
      "Iteration: 611 /1000;  Testing Loss: 0.045193 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 612 /1000;  Training Loss: 0.035520 ; Training Acc: 46.575\n",
      "Iteration: 612 /1000;  Testing Loss: 0.044903 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 613 /1000;  Training Loss: 0.035973 ; Training Acc: 46.967\n",
      "Iteration: 613 /1000;  Testing Loss: 0.045392 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 614 /1000;  Training Loss: 0.035794 ; Training Acc: 46.380\n",
      "Iteration: 614 /1000;  Testing Loss: 0.044504 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 615 /1000;  Training Loss: 0.035533 ; Training Acc: 48.337\n",
      "Iteration: 615 /1000;  Testing Loss: 0.045077 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 616 /1000;  Training Loss: 0.035827 ; Training Acc: 45.793\n",
      "Iteration: 616 /1000;  Testing Loss: 0.044773 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 617 /1000;  Training Loss: 0.035353 ; Training Acc: 47.945\n",
      "Iteration: 617 /1000;  Testing Loss: 0.044842 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 618 /1000;  Training Loss: 0.035873 ; Training Acc: 46.771\n",
      "Iteration: 618 /1000;  Testing Loss: 0.050124 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 619 /1000;  Training Loss: 0.035862 ; Training Acc: 46.771\n",
      "Iteration: 619 /1000;  Testing Loss: 0.044621 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 620 /1000;  Training Loss: 0.035243 ; Training Acc: 49.119\n",
      "Iteration: 620 /1000;  Testing Loss: 0.044903 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 621 /1000;  Training Loss: 0.036184 ; Training Acc: 42.466\n",
      "Iteration: 621 /1000;  Testing Loss: 0.047905 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 622 /1000;  Training Loss: 0.035958 ; Training Acc: 46.575\n",
      "Iteration: 622 /1000;  Testing Loss: 0.044738 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 623 /1000;  Training Loss: 0.035872 ; Training Acc: 46.380\n",
      "Iteration: 623 /1000;  Testing Loss: 0.045388 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 624 /1000;  Training Loss: 0.036325 ; Training Acc: 43.444\n",
      "Iteration: 624 /1000;  Testing Loss: 0.047082 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 625 /1000;  Training Loss: 0.035710 ; Training Acc: 44.814\n",
      "Iteration: 625 /1000;  Testing Loss: 0.044950 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 626 /1000;  Training Loss: 0.035237 ; Training Acc: 48.532\n",
      "Iteration: 626 /1000;  Testing Loss: 0.045815 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 627 /1000;  Training Loss: 0.035197 ; Training Acc: 47.162\n",
      "Iteration: 627 /1000;  Testing Loss: 0.044896 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 628 /1000;  Training Loss: 0.035144 ; Training Acc: 48.141\n",
      "Iteration: 628 /1000;  Testing Loss: 0.044868 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 629 /1000;  Training Loss: 0.035781 ; Training Acc: 45.793\n",
      "Iteration: 629 /1000;  Testing Loss: 0.045279 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 630 /1000;  Training Loss: 0.034929 ; Training Acc: 47.945\n",
      "Iteration: 630 /1000;  Testing Loss: 0.044788 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 631 /1000;  Training Loss: 0.034936 ; Training Acc: 48.337\n",
      "Iteration: 631 /1000;  Testing Loss: 0.045440 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 632 /1000;  Training Loss: 0.036655 ; Training Acc: 42.270\n",
      "Iteration: 632 /1000;  Testing Loss: 0.045368 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 633 /1000;  Training Loss: 0.038270 ; Training Acc: 40.900\n",
      "Iteration: 633 /1000;  Testing Loss: 0.045891 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 634 /1000;  Training Loss: 0.036354 ; Training Acc: 44.227\n",
      "Iteration: 634 /1000;  Testing Loss: 0.044349 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 635 /1000;  Training Loss: 0.035523 ; Training Acc: 46.771\n",
      "Iteration: 635 /1000;  Testing Loss: 0.044951 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 636 /1000;  Training Loss: 0.035984 ; Training Acc: 47.162\n",
      "Iteration: 636 /1000;  Testing Loss: 0.045283 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 637 /1000;  Training Loss: 0.034878 ; Training Acc: 48.141\n",
      "Iteration: 637 /1000;  Testing Loss: 0.044649 ; Testing Acc: 55.639\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 638 /1000;  Training Loss: 0.035473 ; Training Acc: 47.750\n",
      "Iteration: 638 /1000;  Testing Loss: 0.046468 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 639 /1000;  Training Loss: 0.035849 ; Training Acc: 44.227\n",
      "Iteration: 639 /1000;  Testing Loss: 0.044114 ; Testing Acc: 54.887\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 640 /1000;  Training Loss: 0.035482 ; Training Acc: 46.575\n",
      "Iteration: 640 /1000;  Testing Loss: 0.047223 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 641 /1000;  Training Loss: 0.036881 ; Training Acc: 44.618\n",
      "Iteration: 641 /1000;  Testing Loss: 0.046444 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 642 /1000;  Training Loss: 0.037124 ; Training Acc: 44.618\n",
      "Iteration: 642 /1000;  Testing Loss: 0.047214 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 643 /1000;  Training Loss: 0.036356 ; Training Acc: 43.444\n",
      "Iteration: 643 /1000;  Testing Loss: 0.047332 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 644 /1000;  Training Loss: 0.036003 ; Training Acc: 45.597\n",
      "Iteration: 644 /1000;  Testing Loss: 0.044575 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 645 /1000;  Training Loss: 0.035243 ; Training Acc: 47.750\n",
      "Iteration: 645 /1000;  Testing Loss: 0.046423 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 646 /1000;  Training Loss: 0.035772 ; Training Acc: 45.205\n",
      "Iteration: 646 /1000;  Testing Loss: 0.048475 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 647 /1000;  Training Loss: 0.035951 ; Training Acc: 45.988\n",
      "Iteration: 647 /1000;  Testing Loss: 0.044947 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 648 /1000;  Training Loss: 0.034725 ; Training Acc: 48.924\n",
      "Iteration: 648 /1000;  Testing Loss: 0.044910 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 649 /1000;  Training Loss: 0.034870 ; Training Acc: 47.554\n",
      "Iteration: 649 /1000;  Testing Loss: 0.044957 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 650 /1000;  Training Loss: 0.035067 ; Training Acc: 45.988\n",
      "Iteration: 650 /1000;  Testing Loss: 0.044643 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 651 /1000;  Training Loss: 0.035867 ; Training Acc: 46.575\n",
      "Iteration: 651 /1000;  Testing Loss: 0.045309 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 652 /1000;  Training Loss: 0.036055 ; Training Acc: 44.227\n",
      "Iteration: 652 /1000;  Testing Loss: 0.046583 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 653 /1000;  Training Loss: 0.035710 ; Training Acc: 43.640\n",
      "Iteration: 653 /1000;  Testing Loss: 0.045413 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 654 /1000;  Training Loss: 0.035192 ; Training Acc: 45.793\n",
      "Iteration: 654 /1000;  Testing Loss: 0.045092 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 655 /1000;  Training Loss: 0.035283 ; Training Acc: 47.945\n",
      "Iteration: 655 /1000;  Testing Loss: 0.044751 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 656 /1000;  Training Loss: 0.034854 ; Training Acc: 46.967\n",
      "Iteration: 656 /1000;  Testing Loss: 0.045376 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 657 /1000;  Training Loss: 0.035949 ; Training Acc: 44.423\n",
      "Iteration: 657 /1000;  Testing Loss: 0.044606 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 658 /1000;  Training Loss: 0.035311 ; Training Acc: 47.358\n",
      "Iteration: 658 /1000;  Testing Loss: 0.044723 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 659 /1000;  Training Loss: 0.034887 ; Training Acc: 47.162\n",
      "Iteration: 659 /1000;  Testing Loss: 0.046364 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 660 /1000;  Training Loss: 0.035852 ; Training Acc: 45.401\n",
      "Iteration: 660 /1000;  Testing Loss: 0.044580 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 661 /1000;  Training Loss: 0.037183 ; Training Acc: 40.705\n",
      "Iteration: 661 /1000;  Testing Loss: 0.045270 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 662 /1000;  Training Loss: 0.035574 ; Training Acc: 42.661\n",
      "Iteration: 662 /1000;  Testing Loss: 0.046468 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 663 /1000;  Training Loss: 0.035168 ; Training Acc: 47.750\n",
      "Iteration: 663 /1000;  Testing Loss: 0.046993 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 664 /1000;  Training Loss: 0.035573 ; Training Acc: 44.031\n",
      "Iteration: 664 /1000;  Testing Loss: 0.044270 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 665 /1000;  Training Loss: 0.034456 ; Training Acc: 49.706\n",
      "Iteration: 665 /1000;  Testing Loss: 0.044444 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 666 /1000;  Training Loss: 0.034517 ; Training Acc: 47.554\n",
      "Iteration: 666 /1000;  Testing Loss: 0.045563 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 667 /1000;  Training Loss: 0.035436 ; Training Acc: 46.771\n",
      "Iteration: 667 /1000;  Testing Loss: 0.044758 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 668 /1000;  Training Loss: 0.035341 ; Training Acc: 44.814\n",
      "Iteration: 668 /1000;  Testing Loss: 0.050293 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 669 /1000;  Training Loss: 0.036109 ; Training Acc: 45.597\n",
      "Iteration: 669 /1000;  Testing Loss: 0.044123 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 670 /1000;  Training Loss: 0.036800 ; Training Acc: 46.575\n",
      "Iteration: 670 /1000;  Testing Loss: 0.047774 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 671 /1000;  Training Loss: 0.036724 ; Training Acc: 43.836\n",
      "Iteration: 671 /1000;  Testing Loss: 0.044720 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 672 /1000;  Training Loss: 0.035883 ; Training Acc: 42.661\n",
      "Iteration: 672 /1000;  Testing Loss: 0.044025 ; Testing Acc: 54.887\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 673 /1000;  Training Loss: 0.034693 ; Training Acc: 47.945\n",
      "Iteration: 673 /1000;  Testing Loss: 0.043822 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 674 /1000;  Training Loss: 0.034675 ; Training Acc: 48.532\n",
      "Iteration: 674 /1000;  Testing Loss: 0.044205 ; Testing Acc: 54.887\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 675 /1000;  Training Loss: 0.034462 ; Training Acc: 48.532\n",
      "Iteration: 675 /1000;  Testing Loss: 0.044133 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 676 /1000;  Training Loss: 0.035595 ; Training Acc: 46.380\n",
      "Iteration: 676 /1000;  Testing Loss: 0.048484 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 677 /1000;  Training Loss: 0.036893 ; Training Acc: 40.509\n",
      "Iteration: 677 /1000;  Testing Loss: 0.043857 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 678 /1000;  Training Loss: 0.034645 ; Training Acc: 47.554\n",
      "Iteration: 678 /1000;  Testing Loss: 0.044425 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 679 /1000;  Training Loss: 0.034841 ; Training Acc: 47.358\n",
      "Iteration: 679 /1000;  Testing Loss: 0.044304 ; Testing Acc: 54.887\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 680 /1000;  Training Loss: 0.036037 ; Training Acc: 44.814\n",
      "Iteration: 680 /1000;  Testing Loss: 0.045068 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 681 /1000;  Training Loss: 0.035344 ; Training Acc: 45.010\n",
      "Iteration: 681 /1000;  Testing Loss: 0.045218 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 682 /1000;  Training Loss: 0.037577 ; Training Acc: 40.117\n",
      "Iteration: 682 /1000;  Testing Loss: 0.047297 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 683 /1000;  Training Loss: 0.035845 ; Training Acc: 44.423\n",
      "Iteration: 683 /1000;  Testing Loss: 0.043505 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 684 /1000;  Training Loss: 0.034638 ; Training Acc: 47.162\n",
      "Iteration: 684 /1000;  Testing Loss: 0.046650 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 685 /1000;  Training Loss: 0.035703 ; Training Acc: 43.640\n",
      "Iteration: 685 /1000;  Testing Loss: 0.044148 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 686 /1000;  Training Loss: 0.035790 ; Training Acc: 44.227\n",
      "Iteration: 686 /1000;  Testing Loss: 0.045956 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 687 /1000;  Training Loss: 0.035405 ; Training Acc: 44.814\n",
      "Iteration: 687 /1000;  Testing Loss: 0.044898 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 688 /1000;  Training Loss: 0.035114 ; Training Acc: 47.162\n",
      "Iteration: 688 /1000;  Testing Loss: 0.044710 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 689 /1000;  Training Loss: 0.034800 ; Training Acc: 46.771\n",
      "Iteration: 689 /1000;  Testing Loss: 0.045698 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 690 /1000;  Training Loss: 0.034542 ; Training Acc: 47.554\n",
      "Iteration: 690 /1000;  Testing Loss: 0.045213 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 691 /1000;  Training Loss: 0.034422 ; Training Acc: 50.685\n",
      "Iteration: 691 /1000;  Testing Loss: 0.045126 ; Testing Acc: 55.639\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 692 /1000;  Training Loss: 0.036920 ; Training Acc: 43.053\n",
      "Iteration: 692 /1000;  Testing Loss: 0.045839 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 693 /1000;  Training Loss: 0.035858 ; Training Acc: 45.205\n",
      "Iteration: 693 /1000;  Testing Loss: 0.044680 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 694 /1000;  Training Loss: 0.034870 ; Training Acc: 46.771\n",
      "Iteration: 694 /1000;  Testing Loss: 0.045111 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 0s\n",
      "Iteration: 695 /1000;  Training Loss: 0.035032 ; Training Acc: 46.771\n",
      "Iteration: 695 /1000;  Testing Loss: 0.044405 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 696 /1000;  Training Loss: 0.035601 ; Training Acc: 45.988\n",
      "Iteration: 696 /1000;  Testing Loss: 0.045871 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 697 /1000;  Training Loss: 0.034313 ; Training Acc: 47.358\n",
      "Iteration: 697 /1000;  Testing Loss: 0.045109 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 698 /1000;  Training Loss: 0.034562 ; Training Acc: 47.945\n",
      "Iteration: 698 /1000;  Testing Loss: 0.043684 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 699 /1000;  Training Loss: 0.034321 ; Training Acc: 48.532\n",
      "Iteration: 699 /1000;  Testing Loss: 0.044388 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 700 /1000;  Training Loss: 0.034499 ; Training Acc: 49.706\n",
      "Iteration: 700 /1000;  Testing Loss: 0.045150 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 701 /1000;  Training Loss: 0.035010 ; Training Acc: 46.575\n",
      "Iteration: 701 /1000;  Testing Loss: 0.045086 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 702 /1000;  Training Loss: 0.035356 ; Training Acc: 45.597\n",
      "Iteration: 702 /1000;  Testing Loss: 0.043655 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 703 /1000;  Training Loss: 0.034557 ; Training Acc: 48.337\n",
      "Iteration: 703 /1000;  Testing Loss: 0.044293 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 704 /1000;  Training Loss: 0.034650 ; Training Acc: 46.967\n",
      "Iteration: 704 /1000;  Testing Loss: 0.043884 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 705 /1000;  Training Loss: 0.034287 ; Training Acc: 49.902\n",
      "Iteration: 705 /1000;  Testing Loss: 0.044047 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 706 /1000;  Training Loss: 0.034736 ; Training Acc: 48.141\n",
      "Iteration: 706 /1000;  Testing Loss: 0.045988 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 707 /1000;  Training Loss: 0.034760 ; Training Acc: 45.401\n",
      "Iteration: 707 /1000;  Testing Loss: 0.044291 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 708 /1000;  Training Loss: 0.034804 ; Training Acc: 47.554\n",
      "Iteration: 708 /1000;  Testing Loss: 0.043273 ; Testing Acc: 56.391\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 709 /1000;  Training Loss: 0.034302 ; Training Acc: 50.098\n",
      "Iteration: 709 /1000;  Testing Loss: 0.043851 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 710 /1000;  Training Loss: 0.035251 ; Training Acc: 45.793\n",
      "Iteration: 710 /1000;  Testing Loss: 0.044268 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 711 /1000;  Training Loss: 0.035001 ; Training Acc: 46.771\n",
      "Iteration: 711 /1000;  Testing Loss: 0.043513 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 712 /1000;  Training Loss: 0.034144 ; Training Acc: 48.728\n",
      "Iteration: 712 /1000;  Testing Loss: 0.044226 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 713 /1000;  Training Loss: 0.034957 ; Training Acc: 44.814\n",
      "Iteration: 713 /1000;  Testing Loss: 0.043397 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 714 /1000;  Training Loss: 0.034266 ; Training Acc: 47.554\n",
      "Iteration: 714 /1000;  Testing Loss: 0.043608 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 715 /1000;  Training Loss: 0.034016 ; Training Acc: 48.924\n",
      "Iteration: 715 /1000;  Testing Loss: 0.044483 ; Testing Acc: 54.887\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 716 /1000;  Training Loss: 0.034934 ; Training Acc: 46.575\n",
      "Iteration: 716 /1000;  Testing Loss: 0.043558 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 717 /1000;  Training Loss: 0.034229 ; Training Acc: 47.358\n",
      "Iteration: 717 /1000;  Testing Loss: 0.044695 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 718 /1000;  Training Loss: 0.034116 ; Training Acc: 49.315\n",
      "Iteration: 718 /1000;  Testing Loss: 0.045099 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 719 /1000;  Training Loss: 0.034226 ; Training Acc: 46.967\n",
      "Iteration: 719 /1000;  Testing Loss: 0.044062 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 720 /1000;  Training Loss: 0.034895 ; Training Acc: 44.814\n",
      "Iteration: 720 /1000;  Testing Loss: 0.047383 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 721 /1000;  Training Loss: 0.036295 ; Training Acc: 43.444\n",
      "Iteration: 721 /1000;  Testing Loss: 0.046307 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 722 /1000;  Training Loss: 0.035191 ; Training Acc: 46.380\n",
      "Iteration: 722 /1000;  Testing Loss: 0.043707 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 723 /1000;  Training Loss: 0.034155 ; Training Acc: 48.532\n",
      "Iteration: 723 /1000;  Testing Loss: 0.043471 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 724 /1000;  Training Loss: 0.035380 ; Training Acc: 46.771\n",
      "Iteration: 724 /1000;  Testing Loss: 0.045363 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 725 /1000;  Training Loss: 0.036849 ; Training Acc: 40.900\n",
      "Iteration: 725 /1000;  Testing Loss: 0.048160 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 726 /1000;  Training Loss: 0.034543 ; Training Acc: 44.227\n",
      "Iteration: 726 /1000;  Testing Loss: 0.043390 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 727 /1000;  Training Loss: 0.034681 ; Training Acc: 46.575\n",
      "Iteration: 727 /1000;  Testing Loss: 0.043514 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 728 /1000;  Training Loss: 0.033918 ; Training Acc: 46.380\n",
      "Iteration: 728 /1000;  Testing Loss: 0.045284 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 729 /1000;  Training Loss: 0.034343 ; Training Acc: 48.141\n",
      "Iteration: 729 /1000;  Testing Loss: 0.043398 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 730 /1000;  Training Loss: 0.033768 ; Training Acc: 50.294\n",
      "Iteration: 730 /1000;  Testing Loss: 0.044971 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 731 /1000;  Training Loss: 0.035695 ; Training Acc: 45.010\n",
      "Iteration: 731 /1000;  Testing Loss: 0.047212 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 732 /1000;  Training Loss: 0.034394 ; Training Acc: 46.184\n",
      "Iteration: 732 /1000;  Testing Loss: 0.043756 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 733 /1000;  Training Loss: 0.033922 ; Training Acc: 49.706\n",
      "Iteration: 733 /1000;  Testing Loss: 0.043780 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 734 /1000;  Training Loss: 0.034700 ; Training Acc: 50.489\n",
      "Iteration: 734 /1000;  Testing Loss: 0.044839 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 735 /1000;  Training Loss: 0.034473 ; Training Acc: 44.814\n",
      "Iteration: 735 /1000;  Testing Loss: 0.046039 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 736 /1000;  Training Loss: 0.034580 ; Training Acc: 45.597\n",
      "Iteration: 736 /1000;  Testing Loss: 0.043589 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 737 /1000;  Training Loss: 0.034016 ; Training Acc: 49.511\n",
      "Iteration: 737 /1000;  Testing Loss: 0.043203 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 738 /1000;  Training Loss: 0.033871 ; Training Acc: 47.750\n",
      "Iteration: 738 /1000;  Testing Loss: 0.043294 ; Testing Acc: 56.391\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 739 /1000;  Training Loss: 0.033804 ; Training Acc: 47.945\n",
      "Iteration: 739 /1000;  Testing Loss: 0.043786 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 740 /1000;  Training Loss: 0.034296 ; Training Acc: 47.750\n",
      "Iteration: 740 /1000;  Testing Loss: 0.044186 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 741 /1000;  Training Loss: 0.034333 ; Training Acc: 48.728\n",
      "Iteration: 741 /1000;  Testing Loss: 0.043487 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 742 /1000;  Training Loss: 0.034323 ; Training Acc: 49.119\n",
      "Iteration: 742 /1000;  Testing Loss: 0.044176 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 743 /1000;  Training Loss: 0.033847 ; Training Acc: 47.750\n",
      "Iteration: 743 /1000;  Testing Loss: 0.044658 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 744 /1000;  Training Loss: 0.034211 ; Training Acc: 46.575\n",
      "Iteration: 744 /1000;  Testing Loss: 0.044712 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 745 /1000;  Training Loss: 0.034420 ; Training Acc: 49.119\n",
      "Iteration: 745 /1000;  Testing Loss: 0.043358 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 746 /1000;  Training Loss: 0.034158 ; Training Acc: 49.315\n",
      "Iteration: 746 /1000;  Testing Loss: 0.042825 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 747 /1000;  Training Loss: 0.034328 ; Training Acc: 47.358\n",
      "Iteration: 747 /1000;  Testing Loss: 0.043968 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 748 /1000;  Training Loss: 0.034891 ; Training Acc: 45.401\n",
      "Iteration: 748 /1000;  Testing Loss: 0.043400 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 749 /1000;  Training Loss: 0.035984 ; Training Acc: 44.227\n",
      "Iteration: 749 /1000;  Testing Loss: 0.045267 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 750 /1000;  Training Loss: 0.033623 ; Training Acc: 46.575\n",
      "Iteration: 750 /1000;  Testing Loss: 0.042930 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 751 /1000;  Training Loss: 0.035664 ; Training Acc: 45.597\n",
      "Iteration: 751 /1000;  Testing Loss: 0.045155 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 752 /1000;  Training Loss: 0.034381 ; Training Acc: 45.793\n",
      "Iteration: 752 /1000;  Testing Loss: 0.043926 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 753 /1000;  Training Loss: 0.033834 ; Training Acc: 49.119\n",
      "Iteration: 753 /1000;  Testing Loss: 0.043423 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 754 /1000;  Training Loss: 0.034219 ; Training Acc: 46.967\n",
      "Iteration: 754 /1000;  Testing Loss: 0.043628 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 755 /1000;  Training Loss: 0.033812 ; Training Acc: 47.750\n",
      "Iteration: 755 /1000;  Testing Loss: 0.044493 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 756 /1000;  Training Loss: 0.033737 ; Training Acc: 48.532\n",
      "Iteration: 756 /1000;  Testing Loss: 0.043548 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 757 /1000;  Training Loss: 0.033824 ; Training Acc: 47.358\n",
      "Iteration: 757 /1000;  Testing Loss: 0.042879 ; Testing Acc: 55.639\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 758 /1000;  Training Loss: 0.033771 ; Training Acc: 49.511\n",
      "Iteration: 758 /1000;  Testing Loss: 0.044049 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 759 /1000;  Training Loss: 0.035492 ; Training Acc: 44.814\n",
      "Iteration: 759 /1000;  Testing Loss: 0.053192 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 760 /1000;  Training Loss: 0.039023 ; Training Acc: 38.552\n",
      "Iteration: 760 /1000;  Testing Loss: 0.054990 ; Testing Acc: 32.331\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 761 /1000;  Training Loss: 0.036057 ; Training Acc: 43.640\n",
      "Iteration: 761 /1000;  Testing Loss: 0.043343 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 762 /1000;  Training Loss: 0.034054 ; Training Acc: 50.489\n",
      "Iteration: 762 /1000;  Testing Loss: 0.043780 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 763 /1000;  Training Loss: 0.034351 ; Training Acc: 46.380\n",
      "Iteration: 763 /1000;  Testing Loss: 0.045207 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 764 /1000;  Training Loss: 0.035780 ; Training Acc: 42.466\n",
      "Iteration: 764 /1000;  Testing Loss: 0.042907 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 765 /1000;  Training Loss: 0.034927 ; Training Acc: 45.205\n",
      "Iteration: 765 /1000;  Testing Loss: 0.043467 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 766 /1000;  Training Loss: 0.035028 ; Training Acc: 46.967\n",
      "Iteration: 766 /1000;  Testing Loss: 0.042654 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 767 /1000;  Training Loss: 0.033725 ; Training Acc: 47.945\n",
      "Iteration: 767 /1000;  Testing Loss: 0.044262 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 768 /1000;  Training Loss: 0.033366 ; Training Acc: 49.119\n",
      "Iteration: 768 /1000;  Testing Loss: 0.043231 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 769 /1000;  Training Loss: 0.033291 ; Training Acc: 50.489\n",
      "Iteration: 769 /1000;  Testing Loss: 0.043793 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 770 /1000;  Training Loss: 0.034288 ; Training Acc: 47.945\n",
      "Iteration: 770 /1000;  Testing Loss: 0.043362 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 771 /1000;  Training Loss: 0.033637 ; Training Acc: 47.750\n",
      "Iteration: 771 /1000;  Testing Loss: 0.044283 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 772 /1000;  Training Loss: 0.034104 ; Training Acc: 49.706\n",
      "Iteration: 772 /1000;  Testing Loss: 0.046010 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 773 /1000;  Training Loss: 0.034955 ; Training Acc: 43.640\n",
      "Iteration: 773 /1000;  Testing Loss: 0.043433 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 774 /1000;  Training Loss: 0.033566 ; Training Acc: 46.967\n",
      "Iteration: 774 /1000;  Testing Loss: 0.043531 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 775 /1000;  Training Loss: 0.033675 ; Training Acc: 49.706\n",
      "Iteration: 775 /1000;  Testing Loss: 0.043001 ; Testing Acc: 54.887\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 776 /1000;  Training Loss: 0.033719 ; Training Acc: 47.358\n",
      "Iteration: 776 /1000;  Testing Loss: 0.043566 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 777 /1000;  Training Loss: 0.035659 ; Training Acc: 47.358\n",
      "Iteration: 777 /1000;  Testing Loss: 0.045479 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 778 /1000;  Training Loss: 0.036924 ; Training Acc: 41.096\n",
      "Iteration: 778 /1000;  Testing Loss: 0.044044 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 779 /1000;  Training Loss: 0.035660 ; Training Acc: 42.074\n",
      "Iteration: 779 /1000;  Testing Loss: 0.045478 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 780 /1000;  Training Loss: 0.035800 ; Training Acc: 42.074\n",
      "Iteration: 780 /1000;  Testing Loss: 0.043697 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 781 /1000;  Training Loss: 0.033468 ; Training Acc: 49.315\n",
      "Iteration: 781 /1000;  Testing Loss: 0.042280 ; Testing Acc: 59.398\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 782 /1000;  Training Loss: 0.033464 ; Training Acc: 49.511\n",
      "Iteration: 782 /1000;  Testing Loss: 0.042677 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 783 /1000;  Training Loss: 0.034554 ; Training Acc: 45.401\n",
      "Iteration: 783 /1000;  Testing Loss: 0.044509 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 784 /1000;  Training Loss: 0.036288 ; Training Acc: 41.879\n",
      "Iteration: 784 /1000;  Testing Loss: 0.046861 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 785 /1000;  Training Loss: 0.033844 ; Training Acc: 48.532\n",
      "Iteration: 785 /1000;  Testing Loss: 0.044122 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 786 /1000;  Training Loss: 0.033682 ; Training Acc: 49.119\n",
      "Iteration: 786 /1000;  Testing Loss: 0.043816 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 787 /1000;  Training Loss: 0.034048 ; Training Acc: 45.401\n",
      "Iteration: 787 /1000;  Testing Loss: 0.043059 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 788 /1000;  Training Loss: 0.034059 ; Training Acc: 46.967\n",
      "Iteration: 788 /1000;  Testing Loss: 0.043044 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 789 /1000;  Training Loss: 0.034097 ; Training Acc: 46.967\n",
      "Iteration: 789 /1000;  Testing Loss: 0.048022 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 790 /1000;  Training Loss: 0.034468 ; Training Acc: 47.162\n",
      "Iteration: 790 /1000;  Testing Loss: 0.043573 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 791 /1000;  Training Loss: 0.034031 ; Training Acc: 45.401\n",
      "Iteration: 791 /1000;  Testing Loss: 0.043815 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 792 /1000;  Training Loss: 0.034199 ; Training Acc: 48.924\n",
      "Iteration: 792 /1000;  Testing Loss: 0.043345 ; Testing Acc: 57.895\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 793 /1000;  Training Loss: 0.033913 ; Training Acc: 47.162\n",
      "Iteration: 793 /1000;  Testing Loss: 0.045539 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 794 /1000;  Training Loss: 0.036257 ; Training Acc: 44.814\n",
      "Iteration: 794 /1000;  Testing Loss: 0.053363 ; Testing Acc: 29.323\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 795 /1000;  Training Loss: 0.035054 ; Training Acc: 43.444\n",
      "Iteration: 795 /1000;  Testing Loss: 0.042415 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 796 /1000;  Training Loss: 0.033536 ; Training Acc: 49.706\n",
      "Iteration: 796 /1000;  Testing Loss: 0.042521 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 797 /1000;  Training Loss: 0.034637 ; Training Acc: 46.967\n",
      "Iteration: 797 /1000;  Testing Loss: 0.042627 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 798 /1000;  Training Loss: 0.034266 ; Training Acc: 45.793\n",
      "Iteration: 798 /1000;  Testing Loss: 0.045431 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 799 /1000;  Training Loss: 0.034595 ; Training Acc: 46.771\n",
      "Iteration: 799 /1000;  Testing Loss: 0.043433 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 800 /1000;  Training Loss: 0.034097 ; Training Acc: 46.184\n",
      "Iteration: 800 /1000;  Testing Loss: 0.042635 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 801 /1000;  Training Loss: 0.034995 ; Training Acc: 45.205\n",
      "Iteration: 801 /1000;  Testing Loss: 0.046591 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 802 /1000;  Training Loss: 0.033794 ; Training Acc: 47.162\n",
      "Iteration: 802 /1000;  Testing Loss: 0.042273 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 803 /1000;  Training Loss: 0.033671 ; Training Acc: 46.380\n",
      "Iteration: 803 /1000;  Testing Loss: 0.042319 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 804 /1000;  Training Loss: 0.033435 ; Training Acc: 47.750\n",
      "Iteration: 804 /1000;  Testing Loss: 0.042361 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 805 /1000;  Training Loss: 0.033244 ; Training Acc: 50.098\n",
      "Iteration: 805 /1000;  Testing Loss: 0.043065 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 806 /1000;  Training Loss: 0.033673 ; Training Acc: 50.098\n",
      "Iteration: 806 /1000;  Testing Loss: 0.048892 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 807 /1000;  Training Loss: 0.035547 ; Training Acc: 45.205\n",
      "Iteration: 807 /1000;  Testing Loss: 0.044231 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 808 /1000;  Training Loss: 0.033893 ; Training Acc: 49.119\n",
      "Iteration: 808 /1000;  Testing Loss: 0.043040 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 809 /1000;  Training Loss: 0.033332 ; Training Acc: 47.945\n",
      "Iteration: 809 /1000;  Testing Loss: 0.043053 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 810 /1000;  Training Loss: 0.033764 ; Training Acc: 49.119\n",
      "Iteration: 810 /1000;  Testing Loss: 0.043723 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 811 /1000;  Training Loss: 0.033930 ; Training Acc: 47.945\n",
      "Iteration: 811 /1000;  Testing Loss: 0.047853 ; Testing Acc: 39.850\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 812 /1000;  Training Loss: 0.037673 ; Training Acc: 40.117\n",
      "Iteration: 812 /1000;  Testing Loss: 0.053232 ; Testing Acc: 36.842\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 813 /1000;  Training Loss: 0.035801 ; Training Acc: 44.814\n",
      "Iteration: 813 /1000;  Testing Loss: 0.043042 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 814 /1000;  Training Loss: 0.033151 ; Training Acc: 49.119\n",
      "Iteration: 814 /1000;  Testing Loss: 0.042675 ; Testing Acc: 57.895\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 815 /1000;  Training Loss: 0.034970 ; Training Acc: 44.423\n",
      "Iteration: 815 /1000;  Testing Loss: 0.042620 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 816 /1000;  Training Loss: 0.033008 ; Training Acc: 52.055\n",
      "Iteration: 816 /1000;  Testing Loss: 0.042579 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 817 /1000;  Training Loss: 0.033507 ; Training Acc: 47.162\n",
      "Iteration: 817 /1000;  Testing Loss: 0.043443 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 818 /1000;  Training Loss: 0.033091 ; Training Acc: 48.337\n",
      "Iteration: 818 /1000;  Testing Loss: 0.042766 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 819 /1000;  Training Loss: 0.033531 ; Training Acc: 49.902\n",
      "Iteration: 819 /1000;  Testing Loss: 0.042628 ; Testing Acc: 55.639\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 820 /1000;  Training Loss: 0.033670 ; Training Acc: 47.554\n",
      "Iteration: 820 /1000;  Testing Loss: 0.042870 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 821 /1000;  Training Loss: 0.033338 ; Training Acc: 47.162\n",
      "Iteration: 821 /1000;  Testing Loss: 0.042576 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 822 /1000;  Training Loss: 0.032857 ; Training Acc: 49.902\n",
      "Iteration: 822 /1000;  Testing Loss: 0.042441 ; Testing Acc: 55.639\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 823 /1000;  Training Loss: 0.033129 ; Training Acc: 50.489\n",
      "Iteration: 823 /1000;  Testing Loss: 0.043770 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 824 /1000;  Training Loss: 0.033686 ; Training Acc: 47.750\n",
      "Iteration: 824 /1000;  Testing Loss: 0.042326 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 825 /1000;  Training Loss: 0.032830 ; Training Acc: 50.098\n",
      "Iteration: 825 /1000;  Testing Loss: 0.042457 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 826 /1000;  Training Loss: 0.033557 ; Training Acc: 49.511\n",
      "Iteration: 826 /1000;  Testing Loss: 0.045625 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 827 /1000;  Training Loss: 0.034646 ; Training Acc: 47.162\n",
      "Iteration: 827 /1000;  Testing Loss: 0.042893 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 828 /1000;  Training Loss: 0.033221 ; Training Acc: 48.728\n",
      "Iteration: 828 /1000;  Testing Loss: 0.042978 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 829 /1000;  Training Loss: 0.032992 ; Training Acc: 51.663\n",
      "Iteration: 829 /1000;  Testing Loss: 0.042492 ; Testing Acc: 55.639\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 830 /1000;  Training Loss: 0.033163 ; Training Acc: 50.685\n",
      "Iteration: 830 /1000;  Testing Loss: 0.043302 ; Testing Acc: 57.895\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 831 /1000;  Training Loss: 0.033668 ; Training Acc: 50.294\n",
      "Iteration: 831 /1000;  Testing Loss: 0.042619 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 832 /1000;  Training Loss: 0.034661 ; Training Acc: 44.031\n",
      "Iteration: 832 /1000;  Testing Loss: 0.041851 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 833 /1000;  Training Loss: 0.034129 ; Training Acc: 46.967\n",
      "Iteration: 833 /1000;  Testing Loss: 0.046557 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 834 /1000;  Training Loss: 0.033798 ; Training Acc: 48.337\n",
      "Iteration: 834 /1000;  Testing Loss: 0.042380 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 835 /1000;  Training Loss: 0.032874 ; Training Acc: 48.141\n",
      "Iteration: 835 /1000;  Testing Loss: 0.042835 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 836 /1000;  Training Loss: 0.036800 ; Training Acc: 41.292\n",
      "Iteration: 836 /1000;  Testing Loss: 0.044010 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 837 /1000;  Training Loss: 0.034953 ; Training Acc: 43.249\n",
      "Iteration: 837 /1000;  Testing Loss: 0.041849 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 838 /1000;  Training Loss: 0.033617 ; Training Acc: 47.750\n",
      "Iteration: 838 /1000;  Testing Loss: 0.042449 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 839 /1000;  Training Loss: 0.034401 ; Training Acc: 44.814\n",
      "Iteration: 839 /1000;  Testing Loss: 0.049854 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 840 /1000;  Training Loss: 0.034682 ; Training Acc: 47.750\n",
      "Iteration: 840 /1000;  Testing Loss: 0.041913 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 841 /1000;  Training Loss: 0.033974 ; Training Acc: 47.945\n",
      "Iteration: 841 /1000;  Testing Loss: 0.042997 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 842 /1000;  Training Loss: 0.032882 ; Training Acc: 49.511\n",
      "Iteration: 842 /1000;  Testing Loss: 0.042406 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 843 /1000;  Training Loss: 0.032795 ; Training Acc: 50.098\n",
      "Iteration: 843 /1000;  Testing Loss: 0.043740 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 844 /1000;  Training Loss: 0.033016 ; Training Acc: 51.663\n",
      "Iteration: 844 /1000;  Testing Loss: 0.042586 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 845 /1000;  Training Loss: 0.032830 ; Training Acc: 49.902\n",
      "Iteration: 845 /1000;  Testing Loss: 0.043252 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 846 /1000;  Training Loss: 0.034804 ; Training Acc: 46.184\n",
      "Iteration: 846 /1000;  Testing Loss: 0.043692 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 847 /1000;  Training Loss: 0.032973 ; Training Acc: 49.902\n",
      "Iteration: 847 /1000;  Testing Loss: 0.042397 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 848 /1000;  Training Loss: 0.033126 ; Training Acc: 48.924\n",
      "Iteration: 848 /1000;  Testing Loss: 0.043562 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 849 /1000;  Training Loss: 0.033397 ; Training Acc: 48.141\n",
      "Iteration: 849 /1000;  Testing Loss: 0.042295 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 850 /1000;  Training Loss: 0.033718 ; Training Acc: 49.902\n",
      "Iteration: 850 /1000;  Testing Loss: 0.043418 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 851 /1000;  Training Loss: 0.033127 ; Training Acc: 52.642\n",
      "Iteration: 851 /1000;  Testing Loss: 0.046183 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 852 /1000;  Training Loss: 0.035067 ; Training Acc: 43.836\n",
      "Iteration: 852 /1000;  Testing Loss: 0.044119 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 853 /1000;  Training Loss: 0.033578 ; Training Acc: 48.532\n",
      "Iteration: 853 /1000;  Testing Loss: 0.045442 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 854 /1000;  Training Loss: 0.033541 ; Training Acc: 46.967\n",
      "Iteration: 854 /1000;  Testing Loss: 0.043744 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 855 /1000;  Training Loss: 0.033620 ; Training Acc: 48.141\n",
      "Iteration: 855 /1000;  Testing Loss: 0.043151 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 856 /1000;  Training Loss: 0.032712 ; Training Acc: 48.532\n",
      "Iteration: 856 /1000;  Testing Loss: 0.042646 ; Testing Acc: 55.639\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 857 /1000;  Training Loss: 0.032839 ; Training Acc: 48.924\n",
      "Iteration: 857 /1000;  Testing Loss: 0.041959 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 858 /1000;  Training Loss: 0.032894 ; Training Acc: 49.511\n",
      "Iteration: 858 /1000;  Testing Loss: 0.041902 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 859 /1000;  Training Loss: 0.032463 ; Training Acc: 50.489\n",
      "Iteration: 859 /1000;  Testing Loss: 0.042434 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 860 /1000;  Training Loss: 0.033592 ; Training Acc: 45.793\n",
      "Iteration: 860 /1000;  Testing Loss: 0.043531 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 861 /1000;  Training Loss: 0.032664 ; Training Acc: 49.706\n",
      "Iteration: 861 /1000;  Testing Loss: 0.041869 ; Testing Acc: 55.639\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 862 /1000;  Training Loss: 0.033181 ; Training Acc: 48.924\n",
      "Iteration: 862 /1000;  Testing Loss: 0.042530 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 863 /1000;  Training Loss: 0.033164 ; Training Acc: 48.141\n",
      "Iteration: 863 /1000;  Testing Loss: 0.042294 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 864 /1000;  Training Loss: 0.032750 ; Training Acc: 50.098\n",
      "Iteration: 864 /1000;  Testing Loss: 0.041505 ; Testing Acc: 55.639\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 865 /1000;  Training Loss: 0.032940 ; Training Acc: 49.511\n",
      "Iteration: 865 /1000;  Testing Loss: 0.041816 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 866 /1000;  Training Loss: 0.032671 ; Training Acc: 48.532\n",
      "Iteration: 866 /1000;  Testing Loss: 0.043079 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 867 /1000;  Training Loss: 0.034008 ; Training Acc: 47.750\n",
      "Iteration: 867 /1000;  Testing Loss: 0.042385 ; Testing Acc: 57.143\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 868 /1000;  Training Loss: 0.032857 ; Training Acc: 48.532\n",
      "Iteration: 868 /1000;  Testing Loss: 0.041538 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 869 /1000;  Training Loss: 0.032664 ; Training Acc: 48.924\n",
      "Iteration: 869 /1000;  Testing Loss: 0.043233 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 870 /1000;  Training Loss: 0.034012 ; Training Acc: 49.315\n",
      "Iteration: 870 /1000;  Testing Loss: 0.041792 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 871 /1000;  Training Loss: 0.032710 ; Training Acc: 48.728\n",
      "Iteration: 871 /1000;  Testing Loss: 0.041622 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 872 /1000;  Training Loss: 0.033777 ; Training Acc: 47.945\n",
      "Iteration: 872 /1000;  Testing Loss: 0.043160 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 873 /1000;  Training Loss: 0.033020 ; Training Acc: 48.728\n",
      "Iteration: 873 /1000;  Testing Loss: 0.043853 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 874 /1000;  Training Loss: 0.032982 ; Training Acc: 48.924\n",
      "Iteration: 874 /1000;  Testing Loss: 0.045401 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 875 /1000;  Training Loss: 0.034025 ; Training Acc: 43.640\n",
      "Iteration: 875 /1000;  Testing Loss: 0.050439 ; Testing Acc: 36.090\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 876 /1000;  Training Loss: 0.034886 ; Training Acc: 42.074\n",
      "Iteration: 876 /1000;  Testing Loss: 0.041807 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 877 /1000;  Training Loss: 0.033617 ; Training Acc: 48.141\n",
      "Iteration: 877 /1000;  Testing Loss: 0.042409 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 878 /1000;  Training Loss: 0.034665 ; Training Acc: 44.618\n",
      "Iteration: 878 /1000;  Testing Loss: 0.043774 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 879 /1000;  Training Loss: 0.033774 ; Training Acc: 45.010\n",
      "Iteration: 879 /1000;  Testing Loss: 0.042695 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 880 /1000;  Training Loss: 0.032858 ; Training Acc: 49.902\n",
      "Iteration: 880 /1000;  Testing Loss: 0.041978 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 881 /1000;  Training Loss: 0.032891 ; Training Acc: 49.511\n",
      "Iteration: 881 /1000;  Testing Loss: 0.045017 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 882 /1000;  Training Loss: 0.035967 ; Training Acc: 43.053\n",
      "Iteration: 882 /1000;  Testing Loss: 0.043827 ; Testing Acc: 38.346\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 883 /1000;  Training Loss: 0.037169 ; Training Acc: 40.900\n",
      "Iteration: 883 /1000;  Testing Loss: 0.043905 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 884 /1000;  Training Loss: 0.033482 ; Training Acc: 47.945\n",
      "Iteration: 884 /1000;  Testing Loss: 0.041443 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 885 /1000;  Training Loss: 0.032850 ; Training Acc: 49.119\n",
      "Iteration: 885 /1000;  Testing Loss: 0.041659 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 886 /1000;  Training Loss: 0.033838 ; Training Acc: 46.184\n",
      "Iteration: 886 /1000;  Testing Loss: 0.041884 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 887 /1000;  Training Loss: 0.032711 ; Training Acc: 50.294\n",
      "Iteration: 887 /1000;  Testing Loss: 0.042397 ; Testing Acc: 56.391\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 888 /1000;  Training Loss: 0.034525 ; Training Acc: 44.618\n",
      "Iteration: 888 /1000;  Testing Loss: 0.044546 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 889 /1000;  Training Loss: 0.035247 ; Training Acc: 40.509\n",
      "Iteration: 889 /1000;  Testing Loss: 0.045880 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 890 /1000;  Training Loss: 0.033192 ; Training Acc: 47.554\n",
      "Iteration: 890 /1000;  Testing Loss: 0.042143 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 891 /1000;  Training Loss: 0.032402 ; Training Acc: 49.706\n",
      "Iteration: 891 /1000;  Testing Loss: 0.041839 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 892 /1000;  Training Loss: 0.034083 ; Training Acc: 47.945\n",
      "Iteration: 892 /1000;  Testing Loss: 0.042637 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 893 /1000;  Training Loss: 0.035119 ; Training Acc: 42.270\n",
      "Iteration: 893 /1000;  Testing Loss: 0.041204 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 894 /1000;  Training Loss: 0.032886 ; Training Acc: 50.294\n",
      "Iteration: 894 /1000;  Testing Loss: 0.042022 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 895 /1000;  Training Loss: 0.032439 ; Training Acc: 48.924\n",
      "Iteration: 895 /1000;  Testing Loss: 0.044528 ; Testing Acc: 42.857\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 896 /1000;  Training Loss: 0.032572 ; Training Acc: 49.902\n",
      "Iteration: 896 /1000;  Testing Loss: 0.042109 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 897 /1000;  Training Loss: 0.032354 ; Training Acc: 50.294\n",
      "Iteration: 897 /1000;  Testing Loss: 0.041978 ; Testing Acc: 54.887\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 898 /1000;  Training Loss: 0.032412 ; Training Acc: 50.881\n",
      "Iteration: 898 /1000;  Testing Loss: 0.042548 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 899 /1000;  Training Loss: 0.032195 ; Training Acc: 51.663\n",
      "Iteration: 899 /1000;  Testing Loss: 0.042165 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 900 /1000;  Training Loss: 0.032190 ; Training Acc: 51.663\n",
      "Iteration: 900 /1000;  Testing Loss: 0.041853 ; Testing Acc: 54.887\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 901 /1000;  Training Loss: 0.032744 ; Training Acc: 50.098\n",
      "Iteration: 901 /1000;  Testing Loss: 0.042813 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 902 /1000;  Training Loss: 0.032485 ; Training Acc: 49.902\n",
      "Iteration: 902 /1000;  Testing Loss: 0.043800 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 903 /1000;  Training Loss: 0.033891 ; Training Acc: 46.967\n",
      "Iteration: 903 /1000;  Testing Loss: 0.043029 ; Testing Acc: 44.361\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 904 /1000;  Training Loss: 0.032387 ; Training Acc: 49.119\n",
      "Iteration: 904 /1000;  Testing Loss: 0.041865 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 905 /1000;  Training Loss: 0.032532 ; Training Acc: 50.098\n",
      "Iteration: 905 /1000;  Testing Loss: 0.042209 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 906 /1000;  Training Loss: 0.034027 ; Training Acc: 45.988\n",
      "Iteration: 906 /1000;  Testing Loss: 0.041527 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 907 /1000;  Training Loss: 0.032944 ; Training Acc: 49.706\n",
      "Iteration: 907 /1000;  Testing Loss: 0.042162 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 908 /1000;  Training Loss: 0.032329 ; Training Acc: 50.685\n",
      "Iteration: 908 /1000;  Testing Loss: 0.041913 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 909 /1000;  Training Loss: 0.032155 ; Training Acc: 51.272\n",
      "Iteration: 909 /1000;  Testing Loss: 0.042002 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 910 /1000;  Training Loss: 0.032993 ; Training Acc: 47.162\n",
      "Iteration: 910 /1000;  Testing Loss: 0.041105 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 911 /1000;  Training Loss: 0.032522 ; Training Acc: 49.119\n",
      "Iteration: 911 /1000;  Testing Loss: 0.041499 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 912 /1000;  Training Loss: 0.032115 ; Training Acc: 51.663\n",
      "Iteration: 912 /1000;  Testing Loss: 0.042152 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 913 /1000;  Training Loss: 0.032155 ; Training Acc: 49.315\n",
      "Iteration: 913 /1000;  Testing Loss: 0.041501 ; Testing Acc: 54.887\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 914 /1000;  Training Loss: 0.032109 ; Training Acc: 49.706\n",
      "Iteration: 914 /1000;  Testing Loss: 0.041736 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 915 /1000;  Training Loss: 0.032602 ; Training Acc: 51.272\n",
      "Iteration: 915 /1000;  Testing Loss: 0.042330 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 916 /1000;  Training Loss: 0.033630 ; Training Acc: 47.750\n",
      "Iteration: 916 /1000;  Testing Loss: 0.044852 ; Testing Acc: 41.353\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 917 /1000;  Training Loss: 0.032475 ; Training Acc: 48.532\n",
      "Iteration: 917 /1000;  Testing Loss: 0.041155 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 918 /1000;  Training Loss: 0.032691 ; Training Acc: 48.924\n",
      "Iteration: 918 /1000;  Testing Loss: 0.041247 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 919 /1000;  Training Loss: 0.032080 ; Training Acc: 51.076\n",
      "Iteration: 919 /1000;  Testing Loss: 0.041994 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 920 /1000;  Training Loss: 0.033172 ; Training Acc: 46.184\n",
      "Iteration: 920 /1000;  Testing Loss: 0.047423 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 921 /1000;  Training Loss: 0.034243 ; Training Acc: 45.988\n",
      "Iteration: 921 /1000;  Testing Loss: 0.042925 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 922 /1000;  Training Loss: 0.032681 ; Training Acc: 49.315\n",
      "Iteration: 922 /1000;  Testing Loss: 0.041471 ; Testing Acc: 58.647\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 923 /1000;  Training Loss: 0.032942 ; Training Acc: 48.924\n",
      "Iteration: 923 /1000;  Testing Loss: 0.043163 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 924 /1000;  Training Loss: 0.033275 ; Training Acc: 47.945\n",
      "Iteration: 924 /1000;  Testing Loss: 0.041110 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 925 /1000;  Training Loss: 0.032803 ; Training Acc: 47.358\n",
      "Iteration: 925 /1000;  Testing Loss: 0.042013 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 926 /1000;  Training Loss: 0.033067 ; Training Acc: 47.358\n",
      "Iteration: 926 /1000;  Testing Loss: 0.046542 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 927 /1000;  Training Loss: 0.033767 ; Training Acc: 46.967\n",
      "Iteration: 927 /1000;  Testing Loss: 0.044477 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 928 /1000;  Training Loss: 0.033637 ; Training Acc: 47.750\n",
      "Iteration: 928 /1000;  Testing Loss: 0.041298 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 929 /1000;  Training Loss: 0.032414 ; Training Acc: 48.141\n",
      "Iteration: 929 /1000;  Testing Loss: 0.042004 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 930 /1000;  Training Loss: 0.032647 ; Training Acc: 50.489\n",
      "Iteration: 930 /1000;  Testing Loss: 0.041775 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 931 /1000;  Training Loss: 0.031983 ; Training Acc: 52.250\n",
      "Iteration: 931 /1000;  Testing Loss: 0.041371 ; Testing Acc: 55.639\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 932 /1000;  Training Loss: 0.032412 ; Training Acc: 49.315\n",
      "Iteration: 932 /1000;  Testing Loss: 0.041935 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 933 /1000;  Training Loss: 0.032646 ; Training Acc: 51.076\n",
      "Iteration: 933 /1000;  Testing Loss: 0.042231 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 934 /1000;  Training Loss: 0.032728 ; Training Acc: 48.532\n",
      "Iteration: 934 /1000;  Testing Loss: 0.044524 ; Testing Acc: 42.105\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 935 /1000;  Training Loss: 0.033175 ; Training Acc: 48.532\n",
      "Iteration: 935 /1000;  Testing Loss: 0.044206 ; Testing Acc: 43.609\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 936 /1000;  Training Loss: 0.032483 ; Training Acc: 50.098\n",
      "Iteration: 936 /1000;  Testing Loss: 0.041484 ; Testing Acc: 55.639\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 937 /1000;  Training Loss: 0.032786 ; Training Acc: 47.945\n",
      "Iteration: 937 /1000;  Testing Loss: 0.043774 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 938 /1000;  Training Loss: 0.032503 ; Training Acc: 49.706\n",
      "Iteration: 938 /1000;  Testing Loss: 0.042424 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 939 /1000;  Training Loss: 0.032660 ; Training Acc: 50.098\n",
      "Iteration: 939 /1000;  Testing Loss: 0.041636 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 940 /1000;  Training Loss: 0.031816 ; Training Acc: 51.663\n",
      "Iteration: 940 /1000;  Testing Loss: 0.042046 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 941 /1000;  Training Loss: 0.032166 ; Training Acc: 49.511\n",
      "Iteration: 941 /1000;  Testing Loss: 0.042187 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 942 /1000;  Training Loss: 0.033584 ; Training Acc: 47.162\n",
      "Iteration: 942 /1000;  Testing Loss: 0.041311 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 943 /1000;  Training Loss: 0.031762 ; Training Acc: 51.076\n",
      "Iteration: 943 /1000;  Testing Loss: 0.042976 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 944 /1000;  Training Loss: 0.032135 ; Training Acc: 47.750\n",
      "Iteration: 944 /1000;  Testing Loss: 0.042062 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 945 /1000;  Training Loss: 0.032755 ; Training Acc: 49.902\n",
      "Iteration: 945 /1000;  Testing Loss: 0.041396 ; Testing Acc: 57.143\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 946 /1000;  Training Loss: 0.032964 ; Training Acc: 48.924\n",
      "Iteration: 946 /1000;  Testing Loss: 0.046041 ; Testing Acc: 40.602\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 947 /1000;  Training Loss: 0.036450 ; Training Acc: 42.270\n",
      "Iteration: 947 /1000;  Testing Loss: 0.043990 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 948 /1000;  Training Loss: 0.032464 ; Training Acc: 47.162\n",
      "Iteration: 948 /1000;  Testing Loss: 0.040726 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 949 /1000;  Training Loss: 0.033660 ; Training Acc: 47.162\n",
      "Iteration: 949 /1000;  Testing Loss: 0.042821 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 950 /1000;  Training Loss: 0.032967 ; Training Acc: 47.162\n",
      "Iteration: 950 /1000;  Testing Loss: 0.041140 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 951 /1000;  Training Loss: 0.033547 ; Training Acc: 48.337\n",
      "Iteration: 951 /1000;  Testing Loss: 0.040900 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 952 /1000;  Training Loss: 0.032277 ; Training Acc: 51.859\n",
      "Iteration: 952 /1000;  Testing Loss: 0.041507 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 953 /1000;  Training Loss: 0.032250 ; Training Acc: 48.924\n",
      "Iteration: 953 /1000;  Testing Loss: 0.041782 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 954 /1000;  Training Loss: 0.032626 ; Training Acc: 50.294\n",
      "Iteration: 954 /1000;  Testing Loss: 0.041909 ; Testing Acc: 54.887\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 955 /1000;  Training Loss: 0.035594 ; Training Acc: 44.031\n",
      "Iteration: 955 /1000;  Testing Loss: 0.048793 ; Testing Acc: 33.835\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 956 /1000;  Training Loss: 0.033441 ; Training Acc: 46.380\n",
      "Iteration: 956 /1000;  Testing Loss: 0.042738 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 957 /1000;  Training Loss: 0.032531 ; Training Acc: 49.511\n",
      "Iteration: 957 /1000;  Testing Loss: 0.041135 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 958 /1000;  Training Loss: 0.032724 ; Training Acc: 49.511\n",
      "Iteration: 958 /1000;  Testing Loss: 0.044797 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 959 /1000;  Training Loss: 0.034136 ; Training Acc: 46.771\n",
      "Iteration: 959 /1000;  Testing Loss: 0.042918 ; Testing Acc: 45.113\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 960 /1000;  Training Loss: 0.032717 ; Training Acc: 48.532\n",
      "Iteration: 960 /1000;  Testing Loss: 0.044659 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 961 /1000;  Training Loss: 0.033440 ; Training Acc: 45.401\n",
      "Iteration: 961 /1000;  Testing Loss: 0.041057 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 962 /1000;  Training Loss: 0.031957 ; Training Acc: 49.119\n",
      "Iteration: 962 /1000;  Testing Loss: 0.042202 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 963 /1000;  Training Loss: 0.033933 ; Training Acc: 48.141\n",
      "Iteration: 963 /1000;  Testing Loss: 0.041532 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 964 /1000;  Training Loss: 0.032710 ; Training Acc: 48.141\n",
      "Iteration: 964 /1000;  Testing Loss: 0.041632 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 965 /1000;  Training Loss: 0.032187 ; Training Acc: 49.315\n",
      "Iteration: 965 /1000;  Testing Loss: 0.048670 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 966 /1000;  Training Loss: 0.033649 ; Training Acc: 46.575\n",
      "Iteration: 966 /1000;  Testing Loss: 0.040857 ; Testing Acc: 55.639\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 967 /1000;  Training Loss: 0.031930 ; Training Acc: 49.315\n",
      "Iteration: 967 /1000;  Testing Loss: 0.040824 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 968 /1000;  Training Loss: 0.031675 ; Training Acc: 50.489\n",
      "Iteration: 968 /1000;  Testing Loss: 0.041045 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 969 /1000;  Training Loss: 0.032086 ; Training Acc: 49.315\n",
      "Iteration: 969 /1000;  Testing Loss: 0.041537 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 970 /1000;  Training Loss: 0.032106 ; Training Acc: 47.554\n",
      "Iteration: 970 /1000;  Testing Loss: 0.042387 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 971 /1000;  Training Loss: 0.031911 ; Training Acc: 50.881\n",
      "Iteration: 971 /1000;  Testing Loss: 0.041878 ; Testing Acc: 50.376\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 972 /1000;  Training Loss: 0.034941 ; Training Acc: 44.227\n",
      "Iteration: 972 /1000;  Testing Loss: 0.044451 ; Testing Acc: 47.368\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 973 /1000;  Training Loss: 0.033057 ; Training Acc: 48.337\n",
      "Iteration: 973 /1000;  Testing Loss: 0.040852 ; Testing Acc: 54.887\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 974 /1000;  Training Loss: 0.033581 ; Training Acc: 45.401\n",
      "Iteration: 974 /1000;  Testing Loss: 0.041031 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 975 /1000;  Training Loss: 0.031774 ; Training Acc: 50.685\n",
      "Iteration: 975 /1000;  Testing Loss: 0.041388 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 976 /1000;  Training Loss: 0.031656 ; Training Acc: 51.076\n",
      "Iteration: 976 /1000;  Testing Loss: 0.041324 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 977 /1000;  Training Loss: 0.031818 ; Training Acc: 49.511\n",
      "Iteration: 977 /1000;  Testing Loss: 0.041768 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 978 /1000;  Training Loss: 0.031676 ; Training Acc: 51.859\n",
      "Iteration: 978 /1000;  Testing Loss: 0.041075 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 979 /1000;  Training Loss: 0.031656 ; Training Acc: 51.076\n",
      "Iteration: 979 /1000;  Testing Loss: 0.043107 ; Testing Acc: 45.865\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 980 /1000;  Training Loss: 0.031690 ; Training Acc: 50.294\n",
      "Iteration: 980 /1000;  Testing Loss: 0.043182 ; Testing Acc: 48.872\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 981 /1000;  Training Loss: 0.032492 ; Training Acc: 50.098\n",
      "Iteration: 981 /1000;  Testing Loss: 0.041681 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 982 /1000;  Training Loss: 0.032631 ; Training Acc: 48.532\n",
      "Iteration: 982 /1000;  Testing Loss: 0.040626 ; Testing Acc: 57.895\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 983 /1000;  Training Loss: 0.031499 ; Training Acc: 52.055\n",
      "Iteration: 983 /1000;  Testing Loss: 0.040976 ; Testing Acc: 55.639\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 984 /1000;  Training Loss: 0.031974 ; Training Acc: 50.881\n",
      "Iteration: 984 /1000;  Testing Loss: 0.042534 ; Testing Acc: 51.880\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 985 /1000;  Training Loss: 0.033412 ; Training Acc: 47.358\n",
      "Iteration: 985 /1000;  Testing Loss: 0.048279 ; Testing Acc: 37.594\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 986 /1000;  Training Loss: 0.036761 ; Training Acc: 38.943\n",
      "Iteration: 986 /1000;  Testing Loss: 0.041056 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 987 /1000;  Training Loss: 0.033555 ; Training Acc: 46.380\n",
      "Iteration: 987 /1000;  Testing Loss: 0.042773 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 988 /1000;  Training Loss: 0.032070 ; Training Acc: 50.294\n",
      "Iteration: 988 /1000;  Testing Loss: 0.041082 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 989 /1000;  Training Loss: 0.031784 ; Training Acc: 49.315\n",
      "Iteration: 989 /1000;  Testing Loss: 0.041010 ; Testing Acc: 56.391\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 990 /1000;  Training Loss: 0.033405 ; Training Acc: 49.119\n",
      "Iteration: 990 /1000;  Testing Loss: 0.040881 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 991 /1000;  Training Loss: 0.033319 ; Training Acc: 48.728\n",
      "Iteration: 991 /1000;  Testing Loss: 0.040651 ; Testing Acc: 54.135\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 992 /1000;  Training Loss: 0.031925 ; Training Acc: 48.924\n",
      "Iteration: 992 /1000;  Testing Loss: 0.041182 ; Testing Acc: 52.632\n",
      "Time consumed: 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 993 /1000;  Training Loss: 0.032447 ; Training Acc: 47.358\n",
      "Iteration: 993 /1000;  Testing Loss: 0.047634 ; Testing Acc: 39.098\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 994 /1000;  Training Loss: 0.032309 ; Training Acc: 48.728\n",
      "Iteration: 994 /1000;  Testing Loss: 0.040912 ; Testing Acc: 51.128\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 995 /1000;  Training Loss: 0.031595 ; Training Acc: 48.728\n",
      "Iteration: 995 /1000;  Testing Loss: 0.040621 ; Testing Acc: 49.624\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 996 /1000;  Training Loss: 0.031802 ; Training Acc: 51.272\n",
      "Iteration: 996 /1000;  Testing Loss: 0.043783 ; Testing Acc: 46.617\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 997 /1000;  Training Loss: 0.031496 ; Training Acc: 50.294\n",
      "Iteration: 997 /1000;  Testing Loss: 0.041105 ; Testing Acc: 53.383\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 998 /1000;  Training Loss: 0.031778 ; Training Acc: 48.924\n",
      "Iteration: 998 /1000;  Testing Loss: 0.044099 ; Testing Acc: 48.120\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 999 /1000;  Training Loss: 0.031727 ; Training Acc: 52.250\n",
      "Iteration: 999 /1000;  Testing Loss: 0.041043 ; Testing Acc: 55.639\n",
      "Time consumed: 0m 1s\n",
      "Iteration: 1000 /1000;  Training Loss: 0.031955 ; Training Acc: 49.706\n",
      "Iteration: 1000 /1000;  Testing Loss: 0.041599 ; Testing Acc: 55.639\n",
      "Time consumed: 0m 1s\n",
      "Training completed in 8m 59s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1000\n",
    "bSize = 32 # Batch size\n",
    "L = 32 # Number of time steps\n",
    "\n",
    "bCount = len(trainShuffList)//bSize # Number of batches in train set\n",
    "lastBatch = len(trainShuffList)%bSize # Number of samples in last batch of train set\n",
    "\n",
    "test_bCount = len(testList)//bSize # Number of batches in test set\n",
    "test_lastBatch = len(testList)%bSize # Number of samples in last batch of test set\n",
    "\n",
    "# Lists for saving train/test loss and accuracy\n",
    "trainLoss = []\n",
    "trainAcc = []\n",
    "testLoss = []\n",
    "testAcc = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epochNum in range(epochs):\n",
    "    # Shuffling train data for each epoch\n",
    "    trainList = list(zip(trainShuffList, labelShuffList))\n",
    "    shuffle(trainList)\n",
    "    trainShuffList, labelShuffList = zip(*trainList)\n",
    "    \n",
    "    trainRunLoss = 0.0\n",
    "    testRunLoss = 0.0\n",
    "    trainRunCorr = 0\n",
    "    testRunCorr = 0\n",
    "    \n",
    "    epochStart = time.time()\n",
    "    \n",
    "    ## Train\n",
    "    # Load data tensors batchwise     \n",
    "    idx = 0    \n",
    "    for bNum in range(bCount):\n",
    "        first = True\n",
    "        # Loading one batch\n",
    "        for dNum in range(idx,idx+bSize):\n",
    "            if first:\n",
    "                loadData = torch.load(trainPath+trainShuffList[dNum])\n",
    "                sz = loadData.size(0)\n",
    "                idx1 = torch.from_numpy(np.arange(0,(sz//L)*L,sz//L))\n",
    "                batchData = torch.index_select(loadData,dim=0,index=idx1).unsqueeze(0)\n",
    "                batchLabel = torch.Tensor([labelShuffList[dNum]]).long()                          \n",
    "                first = False                \n",
    "            else:\n",
    "                loadData = torch.load(trainPath+trainShuffList[dNum])\n",
    "                sz = loadData.size(0)\n",
    "                idx1 = torch.from_numpy(np.arange(0,(sz//L)*L,sz//L))\n",
    "                tempData = torch.index_select(loadData,dim=0,index=idx1).unsqueeze(0)\n",
    "                batchData = torch.cat((batchData,tempData), dim=0)\n",
    "                batchLabel = torch.cat((batchLabel,torch.Tensor([labelShuffList[dNum]]).long()),dim=0)            \n",
    "        \n",
    "        # Train the network on current batch\n",
    "        net, tr_loss, tr_corr = train(net, batchData, batchLabel, optimizer, criterion)\n",
    "        trainRunLoss += tr_loss\n",
    "        trainRunCorr += tr_corr\n",
    "        idx += bSize\n",
    "        \n",
    "    # Loading last batch\n",
    "    if lastBatch != 0:        \n",
    "        first = True\n",
    "        for dNum in range(idx,idx+lastBatch):\n",
    "            if first:\n",
    "                loadData = torch.load(trainPath+trainShuffList[dNum])\n",
    "                sz = loadData.size(0)\n",
    "                idx1 = torch.from_numpy(np.arange(0,(sz//L)*L,sz//L))\n",
    "                batchData = torch.index_select(loadData,dim=0,index=idx1).unsqueeze(0)\n",
    "                batchLabel = torch.Tensor([labelShuffList[dNum]]).long()\n",
    "                first = False                \n",
    "            else:\n",
    "                loadData = torch.load(trainPath+trainShuffList[dNum])\n",
    "                sz = loadData.size(0)\n",
    "                idx1 = torch.from_numpy(np.arange(0,(sz//L)*L,sz//L))\n",
    "                tempData = torch.index_select(loadData,dim=0,index=idx1).unsqueeze(0)\n",
    "                batchData = torch.cat((batchData,tempData), dim=0)\n",
    "                batchLabel = torch.cat((batchLabel,torch.Tensor([labelShuffList[dNum]]).long()),dim=0)          \n",
    "        \n",
    "        # Training network on last batch\n",
    "        net, tr_loss, tr_corr = train(net, batchData, batchLabel, optimizer, criterion)\n",
    "        trainRunLoss += tr_loss\n",
    "        trainRunCorr += tr_corr\n",
    "    \n",
    "    # Average training loss and accuracy for each epoch\n",
    "    avgTrainLoss = trainRunLoss/float(len(trainShuffList))\n",
    "    trainLoss.append(avgTrainLoss)\n",
    "    avgTrainAcc = float(trainRunCorr)/float(len(trainShuffList))\n",
    "    trainAcc.append(avgTrainAcc)\n",
    "    \n",
    "    ## Test\n",
    "    # Load data tensors batchwise     \n",
    "    idx = 0    \n",
    "    for bNum in range(test_bCount):\n",
    "        first = True\n",
    "        # Loading one batch\n",
    "        for dNum in range(idx,idx+bSize): \n",
    "            if first:\n",
    "                loadData = torch.load(testPath+testList[dNum])\n",
    "                sz = loadData.size(0)\n",
    "                idx1 = torch.from_numpy(np.arange(0,(sz//L)*L,sz//L))\n",
    "                batchData = torch.index_select(loadData,dim=0,index=idx1).unsqueeze(0)\n",
    "                batchLabel = torch.Tensor([testLabelList[dNum]]).long()\n",
    "                first = False                \n",
    "            else:\n",
    "                loadData = torch.load(testPath+testList[dNum])\n",
    "                sz = loadData.size(0)\n",
    "                idx1 = torch.from_numpy(np.arange(0,(sz//L)*L,sz//L))\n",
    "                tempData = torch.index_select(loadData,dim=0,index=idx1).unsqueeze(0)\n",
    "                batchData = torch.cat((batchData,tempData), dim=0)\n",
    "                batchLabel = torch.cat((batchLabel,torch.Tensor([testLabelList[dNum]]).long()),dim=0)            \n",
    "        \n",
    "        # Test the network on current batch\n",
    "        ts_loss, ts_corr = test(net, batchData, batchLabel, criterion)\n",
    "        testRunLoss += ts_loss\n",
    "        testRunCorr += ts_corr\n",
    "        idx += bSize\n",
    "     \n",
    "    # Loading last batch    \n",
    "    if test_lastBatch != 0:        \n",
    "        first = True\n",
    "        for dNum in range(idx,idx+test_lastBatch):\n",
    "            if first:\n",
    "                loadData = torch.load(testPath+testList[dNum])\n",
    "                sz = loadData.size(0)\n",
    "                idx1 = torch.from_numpy(np.arange(0,(sz//L)*L,sz//L))\n",
    "                batchData = torch.index_select(loadData,dim=0,index=idx1).unsqueeze(0)               \n",
    "                batchLabel = torch.Tensor([testLabelList[dNum]]).long()\n",
    "                first = False                \n",
    "            else:\n",
    "                loadData = torch.load(testPath+testList[dNum])\n",
    "                sz = loadData.size(0)\n",
    "                idx1 = torch.from_numpy(np.arange(0,(sz//L)*L,sz//L))\n",
    "                tempData = torch.index_select(loadData,dim=0,index=idx1).unsqueeze(0)\n",
    "                batchData = torch.cat((batchData,tempData), dim=0)\n",
    "                batchLabel = torch.cat((batchLabel,torch.Tensor([testLabelList[dNum]]).long()),dim=0)          \n",
    "        \n",
    "        # Test network on last batch\n",
    "        ts_loss, ts_corr = test(net, batchData, batchLabel, criterion)\n",
    "        testRunLoss += ts_loss\n",
    "        testRunCorr += tr_corr\n",
    "        \n",
    "    # Average testing loss and accuracy for each epoch\n",
    "    avgTestLoss = testRunLoss/float(len(testList))\n",
    "    testLoss.append(avgTestLoss)\n",
    "    avgTestAcc = float(testRunCorr)/float(len(testList))\n",
    "    testAcc.append(avgTestAcc)   \n",
    "\n",
    "    \n",
    "    # Plotting training loss vs Epochs\n",
    "    fig1 = plt.figure(1)        \n",
    "    plt.plot(range(epochNum+1),trainLoss,'r-',label='train')  \n",
    "    plt.plot(range(epochNum+1),testLoss,'g-',label='test') \n",
    "    if epochNum==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')   \n",
    "    # Plotting testing accuracy vs Epochs\n",
    "    fig2 = plt.figure(2)        \n",
    "    plt.plot(range(epochNum+1),trainAcc,'r-',label='train')    \n",
    "    plt.plot(range(epochNum+1),testAcc,'g-',label='test')        \n",
    "    if epochNum==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "    \n",
    "    epochEnd = time.time()-epochStart\n",
    "    print('Iteration: {:.0f} /{:.0f};  Training Loss: {:.6f} ; Training Acc: {:.3f}'\\\n",
    "          .format(epochNum + 1,epochs, avgTrainLoss, avgTrainAcc*100))\n",
    "    print('Iteration: {:.0f} /{:.0f};  Testing Loss: {:.6f} ; Testing Acc: {:.3f}'\\\n",
    "          .format(epochNum + 1,epochs, avgTestLoss, avgTestAcc*100))\n",
    "    \n",
    "    print('Time consumed: {:.0f}m {:.0f}s'.format(epochEnd//60,epochEnd%60))\n",
    "end = time.time()-start\n",
    "print('Training completed in {:.0f}m {:.0f}s'.format(end//60,end%60))      \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'LSTM_ucf101_1000adam_1e-4_b32.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(testList) // bSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
