{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 22: Cost Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "from skimage.measure import compare_ssim as ssim #Structural similarity index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "BatchSize = 100\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./MNIST', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BatchSize,\n",
    "                                          shuffle=True, num_workers=4) # Creating dataloader\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./MNIST', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BatchSize,\n",
    "                                         shuffle=False, num_workers=4) # Creating dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Losses\n",
    "## Define the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 400),\n",
    "            nn.Tanh())\n",
    "        self.decoder = nn.Sequential(          \n",
    "            nn.Linear(400, 28*28),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net1 = autoencoder()\n",
    "net2 = autoencoder()\n",
    "\n",
    "if use_gpu:\n",
    "    net1 = net1.cuda()\n",
    "    net2 = net2.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(model,optimizer,criterion,datainput,label):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(datainput)\n",
    "    loss = criterion(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "learning_rate = 1\n",
    "\n",
    "optimizer1 = optim.Adam(net1.parameters(), lr=1e-4)\n",
    "optimizer2 = optim.Adam(net2.parameters(), lr=1e-4)\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "criterion2 = nn.L1Loss()\n",
    "\n",
    "Plotssim1 = []\n",
    "Plotssim2 = []\n",
    "plotLoss1 = []\n",
    "plotLoss2 = []\n",
    "\n",
    "testImage = testloader.dataset[0][0]\n",
    "if use_gpu:\n",
    "    testinputs = Variable(testImage.view(-1, 28*28)).cuda()    \n",
    "else:\n",
    "    testinputs = Variable(testImage.view(-1, 28*28)) \n",
    "\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "    running_loss1 = 0.0\n",
    "    running_loss2 = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.view(-1, 28*28)).cuda()           \n",
    "        else:\n",
    "            inputs = Variable(inputs.view(-1, 28*28))               \n",
    "      \n",
    "        trainLoss1  = Train(net1,optimizer1,criterion1,inputs,inputs)\n",
    "        trainLoss2 = Train(net2,optimizer2,criterion2,inputs,inputs)    \n",
    "        \n",
    "        running_loss1 += trainLoss1\n",
    "        running_loss2 += trainLoss2\n",
    "    plotLoss1.append(running_loss1/(i+1))\n",
    "    plotLoss2.append(running_loss2/(i+1))       \n",
    "\n",
    "      \n",
    "    outputs = net1(testinputs)    \n",
    "    ssim1 = ssim(outputs.data.view(28,28).cpu().numpy(),testinputs.data.view(28,28).cpu().numpy())\n",
    "    \n",
    "    outputs = net2(testinputs)\n",
    "    ssim2 = ssim(outputs.data.view(28,28).cpu().numpy(),testinputs.data.view(28,28).cpu().numpy())\n",
    "\n",
    "    Plotssim1.append(float(ssim1))\n",
    "    Plotssim2.append(float(ssim2))\n",
    "    \n",
    "    print('At Epoch '+str(epoch+1))\n",
    "    print('With MSELoss: Loss = {:.6f}, SSIM Index = {:.5f} '.format(running_loss1/(i+1),float(ssim1)))\n",
    "    print('With L1Loss: Loss = {:.6f}, SSIM Index = {:.5f} '.format(running_loss2/(i+1),float(ssim2)))\n",
    "\n",
    "fig = plt.figure()        \n",
    "plt.plot(range(epoch+1),plotLoss1,'r-',label='Mean Square Error')\n",
    "plt.plot(range(epoch+1),plotLoss2,'g-',label='L1 Loss')   \n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Loss')  \n",
    "\n",
    "fig = plt.figure()         \n",
    "plt.plot(range(epoch+1),Plotssim1,'r-',label='SSIM Index (MSE)')\n",
    "plt.plot(range(epoch+1),Plotssim2,'g-',label='SSIM Index (L1)')      \n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Testing SSIM') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Loss\n",
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.Layer1 = nn.Sequential(\n",
    "            nn.Linear(28*28, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 256),\n",
    "            nn.ReLU())\n",
    "        self.Layer2 = nn.Sequential(\n",
    "            nn.Linear(256, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.Layer1(x)\n",
    "        x = self.Layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = NeuralNet()\n",
    "net2 = NeuralNet()\n",
    "net3 = NeuralNet()\n",
    "\n",
    "if use_gpu:\n",
    "    net1 = net1.cuda()\n",
    "    net2 = net2.cuda()\n",
    "    net3 = net3.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(model,optimizer,criterion,datainput,label,lossType):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(datainput)\n",
    "    if lossType == 'NLL':\n",
    "        loss = criterion(F.log_softmax(output), label)\n",
    "    else:\n",
    "        loss = criterion(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "learning_rate = 0.1\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.NLLLoss()\n",
    "criterion3 = nn.MultiMarginLoss()\n",
    "\n",
    "optimizer1 = optim.Adam(net1.parameters(), lr=1e-4)\n",
    "optimizer2 = optim.Adam(net2.parameters(), lr=1e-4)\n",
    "optimizer3 = optim.Adam(net3.parameters(), lr=1e-4)\n",
    "\n",
    "Plotacc1 = []\n",
    "Plotacc2 = []\n",
    "Plotacc3 = []\n",
    "\n",
    "plotLoss1 = []\n",
    "plotLoss2 = []\n",
    "plotLoss3 = []\n",
    "\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "\n",
    "    correct1 = 0\n",
    "    correct2 = 0\n",
    "    correct3 = 0\n",
    "    runningLoss1 = 0\n",
    "    runningLoss2 = 0\n",
    "    runningLoss3 = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.view(-1, 28*28)).cuda(), Variable(labels).cuda()\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs.view(-1, 28*28)), Variable(labels)         \n",
    "        trainLoss1 = Train(net1,optimizer1,criterion1,inputs,labels,lossType='CE')\n",
    "        trainLoss2 = Train(net2,optimizer2,criterion2,inputs,labels,lossType='NLL')   \n",
    "        trainLoss3 = Train(net3,optimizer3,criterion3,inputs,labels,lossType='MM')    \n",
    "\n",
    "        runningLoss1 += trainLoss1\n",
    "        runningLoss2 += trainLoss2\n",
    "        runningLoss3 += trainLoss3\n",
    "   \n",
    "    runningLoss1 = runningLoss1/(i+1)\n",
    "    runningLoss2 = runningLoss2/(i+1)\n",
    "    runningLoss3 = runningLoss3/(i+1)\n",
    "          \n",
    "   \n",
    "    plotLoss1.append(runningLoss1)\n",
    "    plotLoss2.append(runningLoss2)\n",
    "    plotLoss3.append(runningLoss3)\n",
    "    \n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.view(-1, 28*28)).cuda(), labels.cuda()\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs.view(-1, 28*28)), labels\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        outputs = net1(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct1 += (predicted == labels).sum()\n",
    "        \n",
    "        outputs = net2(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct2 += (predicted == labels).sum()\n",
    "        \n",
    "        outputs = net3(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct3 += (predicted == labels).sum()\n",
    "\n",
    "    Plotacc1.append(correct1/float(total))\n",
    "    Plotacc2.append(correct2/float(total))\n",
    "    Plotacc3.append(correct3/float(total))\n",
    "    \n",
    "    print('At Epoch '+str(epoch+1))\n",
    "    print('With CrossEntropyLoss: Loss = {:.6f} , Acc = {:.4f}'.format(runningLoss1,correct1/float(total)))\n",
    "    print('With NegativeLogLikelihoodLoss: Loss = {:.6f} , Acc = {:.4f}'.format(runningLoss2,correct2/float(total)))\n",
    "    print('With MultiMarginLoss: Loss = {:.6f} , Acc = {:.4f}\\n'.format(runningLoss3,correct3/float(total)))\n",
    "    \n",
    "fig = plt.figure()        \n",
    "plt.plot(range(epoch+1),plotLoss1,'r-',label='Cross Entropy Loss')\n",
    "plt.plot(range(epoch+1),plotLoss2,'g-',label='Negative Log Likelihood Loss')   \n",
    "plt.plot(range(epoch+1),plotLoss3,'b-',label='Multi Margin Loss')  \n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Loss')  \n",
    "    \n",
    "fig = plt.figure()        \n",
    "plt.plot(range(epoch+1),Plotacc1,'r-',label='Cross Entropy Loss')\n",
    "plt.plot(range(epoch+1),Plotacc2,'g-',label='Negative Log Likelihood Loss')   \n",
    "plt.plot(range(epoch+1),Plotacc3,'b-',label='Multi Margin Loss')  \n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Testing Accuracy')  \n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
