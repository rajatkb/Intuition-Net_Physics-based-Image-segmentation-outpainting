{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 54: Adversarial Autoencoder for Synthetic Sample Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from IPython import display\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset \n",
    "dataset = dsets.MNIST(root='./data', train=True, transform=transforms.ToTensor(),  download=True)\n",
    "testset = dsets.MNIST(root='./data', train=False, transform=transforms.ToTensor(),  download=True)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=testset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(x):\n",
    "    return x.data.cpu().numpy()\n",
    "\n",
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x) \n",
    "\n",
    "def to_cuda(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "class Q_net(nn.Module):  \n",
    "    def __init__(self,X_dim,N,z_dim):\n",
    "        super(Q_net, self).__init__()\n",
    "        self.lin1 = nn.Linear(X_dim, N)\n",
    "        self.lin2 = nn.Linear(N, N)\n",
    "        self.lin3gauss = nn.Linear(N, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        xgauss = self.lin3gauss(x)\n",
    "        return xgauss\n",
    "\n",
    "# Decoder\n",
    "class P_net(nn.Module):  \n",
    "    def __init__(self,X_dim,N,z_dim):\n",
    "        super(P_net, self).__init__()\n",
    "        self.lin1 = nn.Linear(z_dim, N)\n",
    "        self.lin2 = nn.Linear(N, N)\n",
    "        self.lin3 = nn.Linear(N, X_dim)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.25, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "# Discriminator\n",
    "class D_net_gauss(nn.Module):  \n",
    "    def __init__(self,N,z_dim):\n",
    "        super(D_net_gauss, self).__init__()\n",
    "        self.lin1 = nn.Linear(z_dim, N)\n",
    "        self.lin2 = nn.Linear(N, N)\n",
    "        self.lin3 = nn.Linear(N, 1)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.2, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.2, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        return F.sigmoid(self.lin3(x))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_red_dims = 2\n",
    "Q = to_cuda(Q_net(784,1000,z_red_dims))\n",
    "P = to_cuda(P_net(784,1000,z_red_dims))\n",
    "D_gauss = to_cuda(D_net_gauss(500,z_red_dims))\n",
    "\n",
    "\n",
    "# Set learning rates\n",
    "gen_lr = 0.0001\n",
    "reg_lr = 0.00005\n",
    "\n",
    "#encode/decode optimizers\n",
    "optim_P = optim.Adam(P.parameters(), lr=gen_lr)\n",
    "optim_Q_enc = optim.Adam(Q.parameters(), lr=gen_lr)\n",
    "#regularizing optimizers\n",
    "optim_Q_gen = optim.Adam(Q.parameters(), lr=reg_lr)\n",
    "optim_D = optim.Adam(D_gauss.parameters(), lr=reg_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 100\n",
    "\n",
    "test_noise = torch.Tensor(num_test_samples,z_red_dims)\n",
    "p = [-1,1,-1,1]\n",
    "q = [-1,1,1,-1]\n",
    "for loop in range(4):\n",
    "    \n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            test_noise[25*loop+i*5+j] = torch.Tensor([(i+1)*0.4*p[loop], (j+1)*0.4*q[loop]])\n",
    "\n",
    "\n",
    "test_noise = to_var(test_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure for plotting\n",
    "size_figure_grid = int(math.sqrt(num_test_samples))\n",
    "fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(6, 6))\n",
    "for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
    "    ax[i,j].get_xaxis().set_visible(False)\n",
    "    ax[i,j].get_yaxis().set_visible(False)\n",
    "    \n",
    "    \n",
    "data_iter = iter(data_loader)\n",
    "iter_per_epoch = len(data_loader)\n",
    "total_step = 5000\n",
    "\n",
    "# Start training\n",
    "for step in range(total_step):\n",
    "\n",
    "    # Reset the data_iter\n",
    "    if (step+1) % iter_per_epoch == 0:\n",
    "        data_iter = iter(data_loader)\n",
    "\n",
    "    # Fetch the images and labels and convert them to variables\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = to_var(images.view(images.size(0), -1)), to_var(labels)\n",
    "\n",
    "    #reconstruction loss\n",
    "    P.zero_grad()\n",
    "    Q.zero_grad()\n",
    "    D_gauss.zero_grad()\n",
    "\n",
    "    z_sample = Q(images)   #encode to z\n",
    "    X_sample = P(z_sample) #decode to X reconstruction\n",
    "    recon_loss = F.binary_cross_entropy(X_sample,images)\n",
    "\n",
    "    recon_loss.backward()\n",
    "    optim_P.step()\n",
    "    optim_Q_enc.step()\n",
    "\n",
    "    # Discriminator\n",
    "    ## true prior is random normal (randn)\n",
    "    ## this is constraining the Z-projection to be normal!\n",
    "    Q.eval()\n",
    "    z_real_gauss = to_var(torch.randn(images.size()[0], z_red_dims))\n",
    "    D_real_gauss = D_gauss(z_real_gauss)\n",
    "\n",
    "    z_fake_gauss = Q(images)\n",
    "    D_fake_gauss = D_gauss(z_fake_gauss)\n",
    "\n",
    "    D_loss = -torch.mean(torch.log(D_real_gauss) + torch.log(1 - D_fake_gauss))\n",
    "\n",
    "    D_loss.backward()\n",
    "    optim_D.step()\n",
    "\n",
    "    # Generator\n",
    "    Q.train()\n",
    "    z_fake_gauss = Q(images)\n",
    "    D_fake_gauss = D_gauss(z_fake_gauss)\n",
    "    \n",
    "    G_loss = -torch.mean(torch.log(D_fake_gauss))\n",
    "\n",
    "    G_loss.backward()\n",
    "    optim_Q_gen.step()   \n",
    "    \n",
    "    P.eval()\n",
    "    test_images = P(test_noise)\n",
    "    P.train()\n",
    "            \n",
    "    for k in range(num_test_samples):\n",
    "        i = k//10\n",
    "        j = k%10\n",
    "        ax[i,j].cla()\n",
    "        ax[i,j].imshow(to_np(test_images[k,:]).reshape(28, 28), cmap='Greys')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
