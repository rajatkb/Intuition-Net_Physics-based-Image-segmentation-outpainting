{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5: Classification with Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import PIL\n",
    "from skimage.feature import local_binary_pattern, greycomatrix, greycoprops\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading saved features from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved features\n",
    "with open(\"trainFeats.pckl\", \"rb\") as f:\n",
    "    trainFeats = pickle.load(f)\n",
    "with open(\"trainLabel.pckl\", \"rb\") as f:\n",
    "    trainLabel = pickle.load(f)\n",
    "    \n",
    "with open(\"testFeats.pckl\", \"rb\") as f:\n",
    "    testFeats = pickle.load(f)\n",
    "with open(\"testLabel.pckl\", \"rb\") as f:\n",
    "    testLabel = pickle.load(f)\n",
    "    \n",
    "print('Finished load saved feature matrices from the disk!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the perceptron\n",
    "class perceptron(nn.Module):\n",
    "    def __init__(self,n_channels): #n_channels => length of feature vector\n",
    "        super(perceptron, self).__init__()\n",
    "        self.L = nn.Linear(n_channels,10) #Mapping from input to output\n",
    "    def forward(self,x): #x => Input\n",
    "        x = self.L(x) #Feed-forward  \n",
    "        x = F.softmax(x) #Softmax non-linearity\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 1-hot label vectors\n",
    "trainLabel2 = np.zeros((50000,10))\n",
    "testLabel2 = np.zeros((10000,10))\n",
    "for d1 in range(trainLabel.shape[0]):\n",
    "    trainLabel2[d1,trainLabel[d1]] = 1\n",
    "for d2 in range(testLabel.shape[0]):\n",
    "    testLabel2[d2,testLabel[d2]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pytorch dataset from the feature matices\n",
    "trainDataset = TensorDataset(torch.from_numpy(trainFeats), torch.from_numpy(trainLabel2))\n",
    "testDataset = TensorDataset(torch.from_numpy(testFeats), torch.from_numpy(testLabel2))\n",
    "# Creating dataloader\n",
    "trainLoader = DataLoader(trainDataset, batch_size=64, shuffle=True,num_workers=4, pin_memory=True)\n",
    "testLoader = DataLoader(testDataset, batch_size=64, shuffle=True,num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking availability of GPU\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining function for training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definining the training routine\n",
    "def train_model(model,criterion,num_epochs,learning_rate):\n",
    "        start = time.time()\n",
    "        train_loss = [] #List for saving the loss per epoch    \n",
    "        train_acc = [] #List for saving the accuracy per epoch  \n",
    "        tempLabels = [] #List for saving shuffled labels as fed into the network\n",
    "        for epoch in range(num_epochs):\n",
    "            epochStartTime = time.time()\n",
    "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "\n",
    "            running_loss = 0.0           \n",
    "            # Loading data in batches\n",
    "            batch = 0\n",
    "            for data in trainLoader:\n",
    "                inputs,labels = data\n",
    "                # Wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.float().cuda()), \\\n",
    "                        Variable(labels.float().cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs.float()), Variable(labels.float())    \n",
    "                # Initializing model gradients to zero\n",
    "                model.zero_grad() \n",
    "                # Data feed-forward through the network\n",
    "                outputs = model(inputs)\n",
    "                # Predicted class is the one with maximum probability\n",
    "                _, preds = outputs.data.max(1)                 \n",
    "                # Finding the MSE\n",
    "                loss = criterion(outputs, labels)\n",
    "                # Accumulating the loss for each batch\n",
    "                running_loss += loss.data[0]             \n",
    "    \n",
    "                # Backpropaging the error\n",
    "                if batch == 0:\n",
    "                    totalLoss = loss\n",
    "                    totalPreds = preds                    \n",
    "                    tempLabels = labels.data.cpu()\n",
    "                    batch += 1                    \n",
    "                else:\n",
    "                    totalLoss += loss \n",
    "                    totalPreds = torch.cat((totalPreds,preds),0)                 \n",
    "                    tempLabels = torch.cat((tempLabels,labels.data.cpu()),0)\n",
    "                    batch += 1\n",
    "                    \n",
    "            totalLoss = totalLoss/batch\n",
    "            totalLoss.backward()\n",
    "            \n",
    "            # Updating the model parameters\n",
    "            for f in model.parameters():\n",
    "                f.data.sub_(f.grad.data * learning_rate) \n",
    "                                    \n",
    "            epoch_loss = running_loss/50000  #Total loss for one epoch\n",
    "            train_loss.append(epoch_loss) #Saving the loss over epochs for plotting the graph\n",
    "            \n",
    "            # Accuracy per epoch\n",
    "            tempLabels = tempLabels.numpy()\n",
    "            _,totalLabels = np.where(tempLabels==1)                        \n",
    "            epoch_acc = np.sum(np.equal(totalPreds.cpu().numpy(),np.array(totalLabels)))/50000.0      \n",
    "            train_acc.append(epoch_acc) #Saving the accuracy over epochs for plotting the graph\n",
    "            \n",
    "            epochTimeEnd = time.time()-epochStartTime\n",
    "            print('Average epoch loss: {:.6f}'.format(epoch_loss))\n",
    "            print('Average epoch accuracy: {:.6f}'.format(epoch_acc))\n",
    "            print('-' * 25)\n",
    "            # Plotting Loss vs Epochs\n",
    "            fig1 = plt.figure(1)        \n",
    "            plt.plot(range(epoch+1),train_loss,'r--',label='train')        \n",
    "            if epoch==0:\n",
    "                plt.legend(loc='upper left')\n",
    "                plt.xlabel('Epochs')\n",
    "                plt.ylabel('Loss')\n",
    "            fig1.savefig('lossPlot.png')\n",
    "             # Plotting Accuracy vs Epochs\n",
    "            fig2 = plt.figure(2)        \n",
    "            plt.plot(range(epoch+1),train_acc,'g--',label='train')        \n",
    "            if epoch==0:\n",
    "                plt.legend(loc='upper left')\n",
    "                plt.xlabel('Epochs')\n",
    "                plt.ylabel('Accuracy')\n",
    "            fig2.savefig('accPlot.png')\n",
    "\n",
    "        time_elapsed = time.time() - start\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "featLength = 2+5+2\n",
    "model = perceptron(featLength)\n",
    "if use_gpu:\n",
    "    model = model.cuda() # Initilaizing the model\n",
    "criterion = nn.MSELoss() \n",
    "model = train_model(model,criterion,num_epochs=100,learning_rate=1) # Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation of trained perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding testing accuracy\n",
    "test_running_corr = 0\n",
    "# Loading data in batches\n",
    "batches = 0\n",
    "tempLabels = []\n",
    "for tsData in testLoader:\n",
    "    inputs,labels = tsData\n",
    "    # Wrap them in Variable\n",
    "    if use_gpu:\n",
    "        inputs, labels = Variable(inputs.float().cuda()), \\\n",
    "            Variable(labels.float().cuda())\n",
    "    else:\n",
    "        inputs, labels = Variable(inputs), Variable(labels)        \n",
    "    # Feedforward train data batch through model\n",
    "    output = model(inputs) \n",
    "    # Predicted class is the one with maximum probability\n",
    "    _,preds = output.data.max(1)    \n",
    "    if batches==0:\n",
    "        totalPreds = preds\n",
    "        tempLabels = labels.data.cpu()\n",
    "        batches = 1\n",
    "    else:\n",
    "        totalPreds = torch.cat((totalPreds,preds),0)\n",
    "        tempLabels = torch.cat((tempLabels,labels.data.cpu()),0) \n",
    "# Converting 1-hot vector labels to interget labels\n",
    "tempLabels = tempLabels.numpy()\n",
    "compLabels = np.zeros(10000)\n",
    "for i in range(10000):    \n",
    "    compLabels[i] = np.where(tempLabels[i,:]==1)[0][0]\n",
    "# Finding total number of correct predictions\n",
    "ts_corr = np.sum(np.equal(totalPreds.cpu().numpy(),compLabels))\n",
    "# Calculating accuracy\n",
    "ts_acc = ts_corr/10000.0\n",
    "print('Accuracy on test set = '+str(ts_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
