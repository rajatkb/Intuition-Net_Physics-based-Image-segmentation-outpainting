{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 32: Convolutional Autoencoder for Representation Learning\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data:\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "BatchSize = 2000\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./CIFAR10', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BatchSize,\n",
    "                                          shuffle=True, num_workers=4) # Creating dataloader\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./CIFAR10', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BatchSize,\n",
    "                                         shuffle=False, num_workers=4) # Creating dataloader\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Autoencoder:\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.conv_encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1))\n",
    "        \n",
    "        self.fc_encoder = nn.Sequential(\n",
    "            nn.Linear(128*4*4,1024),\n",
    "            nn.LeakyReLU(0.1))\n",
    "        \n",
    "        self.fc_decoder = nn.Sequential(\n",
    "            nn.Linear(1024,128*4*4),\n",
    "            nn.LeakyReLU(0.1))\n",
    "        \n",
    "        self.conv_decoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "            nn.Conv2d(in_channels=64, out_channels=3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_encoder(x)\n",
    "        x = x.view(-1, 128*4*4)\n",
    "        x = self.fc_encoder(x)\n",
    "        x = self.fc_decoder(x)\n",
    "        x = x.view(-1, 128,4,4)\n",
    "        x = self.conv_decoder(x)\n",
    "        return x\n",
    "net = autoencoder()\n",
    "if use_gpu:\n",
    "    net = net.cuda()\n",
    "print(net)\n",
    "init_weights = copy.deepcopy(net.conv_encoder[0].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Autoencoder:\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "trainLoss = []\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        # wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs).cuda()\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "\n",
    "        optimizer.zero_grad()  # zeroes the gradient buffers of all parameters\n",
    "        outputs = net(inputs) # forward \n",
    "        loss = criterion(outputs, inputs) # calculate loss\n",
    "        loss.backward() #  backpropagate the loss\n",
    "        \n",
    "        optimizer.step()\n",
    "        runningLoss += loss.data[0]\n",
    "    trainLoss.append((runningLoss/(60000/BatchSize)))\n",
    "    epochEnd = time.time()-epochStart\n",
    "    print('Iteration: {:.0f} /{:.0f}  ;  Training Loss: {:.6f} ; Time consumed: {:.0f}m {:.0f}s '\\\n",
    "          .format(epoch + 1,iterations,runningLoss/(60000/BatchSize),epochEnd//60,epochEnd%60))   \n",
    "print('Finished Training')\n",
    "\n",
    "fig = plt.figure()        \n",
    "plt.plot(range(epoch+1),trainLoss,'g-',label='Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training loss') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights Visualization:\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img, strlabel):\n",
    "    npimg = img.numpy()\n",
    "    npimg = np.abs(npimg)\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    fig_size[0] = 10\n",
    "    fig_size[1] = 10\n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "    plt.figure()\n",
    "    plt.title(strlabel)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trained_weights = copy.deepcopy(net.conv_encoder[0].weight.data)\n",
    "d_weights = init_weights - trained_weights \n",
    "\n",
    "if use_gpu:\n",
    "    init_weights = init_weights.view(64,3,3,3).cpu()\n",
    "    trained_weights = trained_weights.view(64,3,3,3).cpu()\n",
    "    d_weights = d_weights.view(64,3,3,3).cpu()\n",
    "else:\n",
    "    init_weights = init_weights.view(64,3,3,3)\n",
    "    trained_weights = trained_weights.view(64,3,3,3)\n",
    "    d_weights = d_weights.view(64,3,3,3)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(init_weights,nrow=8,normalize=True),'Initial Weights')\n",
    "imshow(torchvision.utils.make_grid(trained_weights,nrow=8,normalize=True),'Trained Weights')\n",
    "imshow(torchvision.utils.make_grid(d_weights,nrow=8,normalize=True), 'Weight update')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the autoencoder for classification:\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv = net.conv_encoder\n",
    "        self.fc1 = net.fc_encoder\n",
    "        self.fc2 = nn.Sequential(nn.Linear(1024, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 128*4*4)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "net = Model()\n",
    "print(net)\n",
    "if use_gpu:\n",
    "    net = net.cuda()\n",
    "else:\n",
    "    net = net\n",
    "\n",
    "# Copying initial weights  for visualization\n",
    "cll_weights = copy.deepcopy(net.conv[0].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Classifier:\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "trainLoss = []\n",
    "testacc = []\n",
    "\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()  # zeroes the gradient buffers of all parameters\n",
    "        outputs = net(inputs) # forward \n",
    "        loss = criterion(outputs, labels) # calculate loss\n",
    "        loss.backward() #  backpropagate the loss\n",
    "        optimizer.step()\n",
    "        \n",
    "        runningLoss += loss.data[0]\n",
    "        correct = 0\n",
    "        total = 0\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs).cuda(), labels.cuda()\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), labels\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    trainLoss.append((runningLoss/(60000/BatchSize)))\n",
    "    testacc.append(100 * correct /float(total))\n",
    "    epochEnd = time.time()-epochStart\n",
    "    print('Iteration: {:.0f} /{:.0f}  ;  Training Loss: {:.6f} ; Testing Acc: {:.3f} ; Time consumed: {:.0f}m {:.0f}s '\\\n",
    "          .format(epoch + 1,iterations,runningLoss/(60000/BatchSize),100 * correct /float(total),epochEnd//60,epochEnd%60))\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "fig = plt.figure()        \n",
    "plt.plot(range(epoch+1),trainLoss,'g-',label='Train Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training loss') \n",
    "\n",
    "fig = plt.figure()        \n",
    "plt.plot(range(epoch+1),testacc,'r-',label='Test Acc')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Test Accuracy') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder Weights Visualization:\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cll_weights_ft = copy.deepcopy(net.conv[0].weight.data)\n",
    "d_weights = cll_weights-cll_weights_ft \n",
    "\n",
    "if use_gpu:\n",
    "    cll_weights = cll_weights.view(64,3,3,3).cpu()\n",
    "    cll_weights_ft = cll_weights_ft.view(64,3,3,3).cpu()\n",
    "    d_weights = d_weights.view(64,3,3,3).cpu()\n",
    "else:\n",
    "    cll_weights = cll_weights.view((64,3,3,3))\n",
    "    cll_weights_ft = cll_weights_ft.view((64,3,3,3))\n",
    "    d_weights = d_weights.view((64,3,3,3))\n",
    "\n",
    "imshow(torchvision.utils.make_grid(cll_weights,nrow=8,normalize=True),'Trained Weights')\n",
    "imshow(torchvision.utils.make_grid(cll_weights_ft,nrow=8,normalize=True),'Finetuned Weights')\n",
    "imshow(torchvision.utils.make_grid(d_weights,nrow=8,normalize=True), 'Weight update')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of different Classes:\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    if use_gpu:\n",
    "        outputs = net(Variable(images.cuda()))\n",
    "        _, predicted = torch.max(outputs.data.cpu(), 1)\n",
    "    else:\n",
    "        outputs = net(Variable(images))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(BatchSize):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %f %%' % (\n",
    "        classes[i], 100 * class_correct[i] / float(class_total[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
