{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 55: Adversarial Autoencoder for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from IPython import display\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset \n",
    "dataset = dsets.MNIST(root='./data', train=True, transform=transforms.ToTensor(),  download=True)\n",
    "testset = dsets.MNIST(root='./data', train=False, transform=transforms.ToTensor(),  download=True)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=testset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(x):\n",
    "    return x.data.cpu().numpy()\n",
    "\n",
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x) \n",
    "\n",
    "def to_cuda(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "class Q_net(nn.Module):  \n",
    "    def __init__(self,X_dim,N,z_dim):\n",
    "        super(Q_net, self).__init__()\n",
    "        self.lin1 = nn.Linear(X_dim, N)\n",
    "        self.lin2 = nn.Linear(N, N)\n",
    "        self.lin3gauss = nn.Linear(N, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin3gauss(x)\n",
    "        return x\n",
    "\n",
    "# Decoder\n",
    "class P_net(nn.Module):  \n",
    "    def __init__(self,X_dim,N,z_dim):\n",
    "        super(P_net, self).__init__()\n",
    "        self.lin1 = nn.Linear(z_dim, N)\n",
    "        self.lin2 = nn.Linear(N, N)\n",
    "        self.lin3 = nn.Linear(N, X_dim)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.25, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "# Discriminator\n",
    "class D_net_gauss(nn.Module):  \n",
    "    def __init__(self,N,z_dim):\n",
    "        super(D_net_gauss, self).__init__()\n",
    "        self.lin1 = nn.Linear(z_dim, N)\n",
    "        self.lin2 = nn.Linear(N, N)\n",
    "        self.lin3 = nn.Linear(N, 1)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.2, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.2, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        return F.sigmoid(self.lin3(x))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_red_dims = 100\n",
    "Q = to_cuda(Q_net(784,1000,z_red_dims))\n",
    "P = to_cuda(P_net(784,1000,z_red_dims))\n",
    "D_gauss = to_cuda(D_net_gauss(500,z_red_dims))\n",
    "\n",
    "\n",
    "# Set learning rates\n",
    "gen_lr = 0.0001\n",
    "reg_lr = 0.00005\n",
    "\n",
    "#encode/decode optimizers\n",
    "optim_P = optim.Adam(P.parameters(), lr=gen_lr)\n",
    "optim_Q_enc = optim.Adam(Q.parameters(), lr=gen_lr)\n",
    "#regularizing optimizers\n",
    "optim_Q_gen = optim.Adam(Q.parameters(), lr=reg_lr)\n",
    "optim_D = optim.Adam(D_gauss.parameters(), lr=reg_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 100\n",
    "\n",
    "test_noise = torch.randn(num_test_samples,z_red_dims)\n",
    "test_noise = to_var(test_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure for plotting\n",
    "size_figure_grid = int(math.sqrt(num_test_samples))\n",
    "fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(6, 6))\n",
    "for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
    "    ax[i,j].get_xaxis().set_visible(False)\n",
    "    ax[i,j].get_yaxis().set_visible(False)\n",
    "    \n",
    "    \n",
    "data_iter = iter(data_loader)\n",
    "iter_per_epoch = len(data_loader)\n",
    "total_step = 5000\n",
    "\n",
    "# Start training\n",
    "for step in range(total_step):\n",
    "\n",
    "    # Reset the data_iter\n",
    "    if (step+1) % iter_per_epoch == 0:\n",
    "        data_iter = iter(data_loader)\n",
    "\n",
    "    # Fetch the images and labels and convert them to variables\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = to_var(images.view(images.size(0), -1)), to_var(labels)\n",
    "\n",
    "    #reconstruction loss\n",
    "    P.zero_grad()\n",
    "    Q.zero_grad()\n",
    "    D_gauss.zero_grad()\n",
    "\n",
    "    z_sample = Q(images)   #encode to z\n",
    "    X_sample = P(z_sample) #decode to X reconstruction\n",
    "    recon_loss = F.binary_cross_entropy(X_sample,images)\n",
    "\n",
    "    recon_loss.backward()\n",
    "    optim_P.step()\n",
    "    optim_Q_enc.step()\n",
    "\n",
    "    # Discriminator\n",
    "    ## true prior is random normal (randn)\n",
    "    ## this is constraining the Z-projection to be normal!\n",
    "    Q.eval()\n",
    "    z_real_gauss = to_var(torch.randn(images.size()[0], z_red_dims))\n",
    "    D_real_gauss = D_gauss(z_real_gauss)\n",
    "\n",
    "    z_fake_gauss = Q(images)\n",
    "    D_fake_gauss = D_gauss(z_fake_gauss)\n",
    "\n",
    "    D_loss = -torch.mean(torch.log(D_real_gauss) + torch.log(1 - D_fake_gauss))\n",
    "\n",
    "    D_loss.backward()\n",
    "    optim_D.step()\n",
    "\n",
    "    # Generator\n",
    "    Q.train()\n",
    "    z_fake_gauss = Q(images)\n",
    "    D_fake_gauss = D_gauss(z_fake_gauss)\n",
    "    \n",
    "    G_loss = -torch.mean(torch.log(D_fake_gauss))\n",
    "\n",
    "    G_loss.backward()\n",
    "    optim_Q_gen.step()   \n",
    "    \n",
    "    P.eval()\n",
    "    test_images = P(test_noise)\n",
    "    P.train()\n",
    "            \n",
    "    for k in range(num_test_samples):\n",
    "        i = k//10\n",
    "        j = k%10\n",
    "        ax[i,j].cla()\n",
    "        ax[i,j].imshow(to_np(test_images[k,:]).reshape(28, 28), cmap='Greys')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "class Classifier(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.l1 = Q\n",
    "        self.l2 = nn.Linear(100,10)\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = to_cuda(Classifier())\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "\n",
    "    runningLoss = 0.0\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = to_var(inputs.view(inputs.size(0), -1)), to_var(labels)\n",
    "        \n",
    "        net.train()\n",
    "        optimizer.zero_grad()  # zeroes the gradient buffers of all parameters\n",
    "        outputs = net(inputs) # forward \n",
    "        loss = criterion(outputs, labels) # calculate loss\n",
    "        loss.backward() #  backpropagate the loss\n",
    "        optimizer.step()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "    for data in test_loader:\n",
    "        net.eval()\n",
    "        inputs, labels = data\n",
    "        inputs, labels = to_var(inputs.view(inputs.size(0), -1)), to_var(labels)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.data).sum()\n",
    "    print('At Iteration : %d / %d  ;Test Accuracy : %f'%(epoch + 1,iterations,100 * correct /float(total)))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
