{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# %matplotlib inline\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras import metrics\n",
    "from keras.applications import *\n",
    "from keras.preprocessing import image\n",
    "from keras.activations import *\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighwayDriving_Process:\n",
    "    \n",
    "    def imread(self , name):\n",
    "        return cv2.cvtColor(cv2.imread(name) , cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    def image2class(self , image):\n",
    "        img = np.zeros((image.shape[0],image.shape[1]))\n",
    "        for i,t in enumerate(self.color_list):\n",
    "            img[np.all(image == t[0] , axis = -1)] = i\n",
    "        return img\n",
    "\n",
    "    def class2onehot(self , classm):\n",
    "        return (np.arange(self.nb_classes) == classm[...,None]).astype(np.int8)\n",
    "\n",
    "    def class2image(self , classm):\n",
    "        img = np.zeros((classm.shape[0],classm.shape[1],3))\n",
    "        for i,t in enumerate(self.color_list):\n",
    "            img[classm == i] = np.array(t[0])\n",
    "        return img.astype(np.uint8)\n",
    "\n",
    "    def image_file(self , name):\n",
    "        return self.images_dir+'/'+name\n",
    "\n",
    "    def label_file(self , name):\n",
    "        n , _ , _ , s3 = name.split(self.split_char)\n",
    "        return self.labels_dir+'/'+self.split_char.join([n,self.label_suffix ,s3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self ,images_dir , labels_dir , classes = None):\n",
    "\n",
    "        '''\n",
    "        Original Video sampling by cameras was at 30 Hz\n",
    "        i.e 30 frames per second\n",
    "        This then turned into a 1Hz sampling for 1 frame\n",
    "        per second. The sampling is done for getting rid of \n",
    "        reptitive frames\n",
    "\n",
    "        for our experiment we create these kind of data set \n",
    "        organisation\n",
    "\n",
    "        1. frame => label (training segmentation network)\n",
    "        2. frame => future label (training sgemententation with optical flow)\n",
    "                    i.e capture future intuition\n",
    "                    Try with 1second , Try with 2second , Try with 3 second\n",
    "        3. frame_seq => frame_seq_label (training segmentation sequence model)\n",
    "        4. frame_seq => future_frame_seq_label (shifted by two or three frames)\n",
    "        \n",
    "        using all these the frame vision field can be limited\n",
    "        '''\n",
    "\n",
    "        self.color_list =   [           ([255, 255, 255]         ,  'Undefined'), ## The position is their class so void stays at 0\n",
    "                                        ([0, 255, 255]     ,  'Sky'),\n",
    "                                        ([128,128,128]     ,  'Road'),\n",
    "                                        ([255,255,0]      ,  'Lane'),\n",
    "                                        ([255,0,0]     ,  'Fence'),\n",
    "                                        ([128, 0, 128]       ,  'Construction'),\n",
    "                                        ([255, 0, 128]      ,  'Traffic sign'),\n",
    "                                        ([0, 0, 128]      ,  'Car'),\n",
    "                                        ([0,128,128]    ,  'Truck'),\n",
    "                                        ([0,128,0]   ,  'vegetation'),\n",
    "                                        \n",
    "                                    ]\n",
    "\n",
    "        if classes is not None:\n",
    "            assert(isinstance(classes,list) ) ,\"log:give a list of classes, check dataset or code\"\n",
    "            color_list = [self.color_list[0]]\n",
    "            for t in self.color_list[1:]:\n",
    "                if t[1] in classes:\n",
    "                    color_list.append(t)\n",
    "            self.color_list = color_list\n",
    "\n",
    "        self.nb_classes  = len(self.color_list)   \n",
    "        print(\"log: after filtering there are \",self.nb_classes,\" classes for training\")                          \n",
    "\n",
    "        self.label_suffix = 'ColorLabel' ## dataset specific\n",
    "        self.split_char = '_' ## dataset specific\n",
    "        image_name_list = os.listdir(images_dir)\n",
    "        image_name_list.sort()\n",
    "        labels_name_list = os.listdir(labels_dir)\n",
    "        \n",
    "        \n",
    "\n",
    "        image_sequence_dict = {}\n",
    "\n",
    "        for name in image_name_list:\n",
    "#             print(name)\n",
    "            n , s1 , s2 , s3 = name.split(self.split_char)\n",
    "            image_sequence_dict.setdefault(n , [])\n",
    "            image_sequence_dict[n].append(self.split_char.join([s1,s2,s3]))\n",
    "          \n",
    "\n",
    "        self.images_dir = images_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.image_name_list = image_name_list\n",
    "        self.labels_name_list = labels_name_list\n",
    "        self.image_sequence_dict = image_sequence_dict\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def frame2label_val_datagen(self , size = None  , normalise = True):\n",
    "        '''\n",
    "            Using this makes sense when validation is True\n",
    "        '''\n",
    "        val_images = self.image_name_list[int(len(self.image_name_list)*0.9):]\n",
    "        random.shuffle(val_images)\n",
    "        batch_size = len(val_images)\n",
    "        itr = len(val_images) // batch_size \n",
    "        for i in range(itr+1):\n",
    "            IMAGES = []\n",
    "            LABELS = []\n",
    "            beg = i*batch_size\n",
    "            end = (i*batch_size + batch_size) if (i*batch_size + batch_size) < len(val_images) else -1\n",
    "            for img_file in val_images[beg:end]:\n",
    "                image = self.imread(self.image_file(img_file))\n",
    "                label = self.image2class(self.imread(self.label_file(img_file)))\n",
    "                \n",
    "                if size != None:\n",
    "                    assert( len(size) == 2) , \"log: give (y , x) format size\"\n",
    "                    image = cv2.resize(image , size , interpolation = cv2.INTER_NEAREST)\n",
    "                    label = cv2.resize(label , size , interpolation = cv2.INTER_NEAREST)    \n",
    "                label = self.class2onehot(label)\n",
    "                IMAGES.append(image)\n",
    "                LABELS.append(label)\n",
    "            if len(IMAGES) == 0 or len(LABELS) == 0:\n",
    "                continue\n",
    "            IMAGES = np.array(IMAGES)\n",
    "            LABELS = np.array(LABELS)\n",
    "            if normalise:\n",
    "                IMAGES = IMAGES / 255\n",
    "            yield np.array(IMAGES),np.array(LABELS)        \n",
    "\n",
    "\n",
    "    def frame2label_train_datagen(self ,size = None  ,  batch_size = 16 , validation = True , normalise = True):\n",
    "        \n",
    "        train_images = self.image_name_list\n",
    "        \n",
    "        if validation == True:\n",
    "            train_images = self.image_name_list[:int(len(self.image_name_list)*0.9)]\n",
    "\n",
    "        random.shuffle(train_images)\n",
    "        itr = len(train_images) // batch_size \n",
    "        for i in range(itr+1):\n",
    "            IMAGES = []\n",
    "            LABELS = []\n",
    "            beg = i*batch_size\n",
    "            end = (i*batch_size + batch_size) if (i*batch_size + batch_size) < len(train_images) else -1\n",
    "            for img_file in train_images[beg:end]:\n",
    "                image = self.imread(self.image_file(img_file))\n",
    "                label = self.image2class(self.imread(self.label_file(img_file)))\n",
    "                \n",
    "                if size != None:\n",
    "                    assert( len(size) == 2) , \"log: give (y , x) format size\"\n",
    "                    image = cv2.resize(image , size , interpolation = cv2.INTER_NEAREST)\n",
    "                    label = cv2.resize(label , size , interpolation = cv2.INTER_NEAREST)    \n",
    "                label = self.class2onehot(label)\n",
    "                IMAGES.append(image)\n",
    "                LABELS.append(label)\n",
    "            IMAGES = np.array(IMAGES)\n",
    "            LABELS = np.array(LABELS)\n",
    "            if normalise:\n",
    "                IMAGES = IMAGES / 255\n",
    "\n",
    "            yield np.array(IMAGES),np.array(LABELS)\n",
    "\n",
    "    def jaccard_index(y_pred , y):\n",
    "        intersection = np.logical_and(y, y_pred)\n",
    "        union = np.logical_or(y, y_pred)\n",
    "        iou_score = np.sum(intersection) / np.sum(union)\n",
    "        return iou_score\n",
    "\n",
    "\n",
    "    def get_class_weights(self , c=1.02):\n",
    "        _ , labels = next(self.frame2label_train_datagen(size = (256 , 256)  ,  batch_size = len(self.image_name_list) , \n",
    "                    validation = False , normalise = False))\n",
    "        labels = np.argmax(labels , axis = -1)\n",
    "        print(labels.shape)\n",
    "        all_labels = labels.flatten()\n",
    "        each_class = np.bincount(all_labels, minlength=self.nb_classes)\n",
    "        prospensity_score = each_class / len(all_labels)\n",
    "        class_weights = 1 / (np.log(c + prospensity_score))\n",
    "        return class_weights\n",
    "        \n",
    "    \n",
    "\n",
    "    def frameSequence_train_datagen(self , size = None , batch_size = 16, time_steps = 4 , skip = 4, normalise = True , log=False):\n",
    "        assert(time_steps >= 2) , 'log: give more than or equal to two time steps'\n",
    "        assert(skip >= 1), 'log: give time skip >= 1'\n",
    "      \n",
    "        for sequence in self.image_sequence_dict.keys():\n",
    "            if log:\n",
    "                print(\"log: sequence started:\",sequence)\n",
    "            train_images = self.image_sequence_dict[sequence]\n",
    "            assert(len(train_images) <= batch_size+time_steps*skip), \"log: batch_size + time_steps*skip exceeds max sequence length of video\"\n",
    "\n",
    "            IMAGES = []\n",
    "            LABELS_FUTURE = []\n",
    "            train_batch = train_images\n",
    "\n",
    "\n",
    "            images_numpy = []\n",
    "            labels_numpy = []\n",
    "            for img_file in train_batch:\n",
    "                if size != None:\n",
    "                    images_numpy.append(\n",
    "                      cv2.resize(self.imread(\n",
    "                          self.image_file(\n",
    "                              self.split_char.join([sequence,img_file]))) \n",
    "                                 ,size , interpolation = cv2.INTER_NEAREST))\n",
    "                    labels_numpy.append(self.class2onehot(\n",
    "                      cv2.resize(self.image2class(\n",
    "                        self.imread(self.label_file(\n",
    "                           self.split_char.join([sequence,img_file]))))\n",
    "                                 , size , interpolation = cv2.INTER_NEAREST)))\n",
    "                else:\n",
    "                    images_numpy.append(self.imread(\n",
    "                          self.image_file(\n",
    "                              self.split_char.join([sequence,img_file]))))\n",
    "                    labels_numpy.append(self.class2onehot(self.image2class(\n",
    "                      self.imread(self.label_file(\n",
    "                          self.split_char.join([sequence,img_file]))))))\n",
    "\n",
    "            itr = (len(train_batch) - time_steps*skip)\n",
    "            for j in range(itr):\n",
    "                frames =[]\n",
    "                labels = []\n",
    "                for k in range(time_steps):\n",
    "                    frames.append( images_numpy[j+k*skip] )\n",
    "                    labels.append( labels_numpy[j+(k+1)*skip])\n",
    "                IMAGES.append(frames)\n",
    "                LABELS_FUTURE.append(labels)\n",
    "\n",
    "\n",
    "                if (j+1)%batch_size == 0 or (j+1) == itr:\n",
    "                    IMAGES = np.array(IMAGES)\n",
    "                    LABELS_FUTURE = np.array(LABELS_FUTURE)\n",
    "                    if normalise:\n",
    "                        IMAGES = IMAGES / 255\n",
    "                    x = IMAGES\n",
    "                    y = LABELS_FUTURE\n",
    "                    IMAGES = []\n",
    "                    LABELS_FUTURE = []\n",
    "                    yield x , y\n",
    "                  \n",
    "                  \n",
    "\n",
    "\n",
    "    def frame2futurelabel_train_datagen(self , size=None , batch_size = 16, time_step = 3 , normalise = True):\n",
    "        assert(batch_size > time_step) ,'log: batch size must be greater than time step'\n",
    "        batch_size = batch_size+time_step\n",
    "        \n",
    "        for sequence in self.image_sequence_dict.keys():\n",
    "            train_images = self.image_sequence_dict[sequence]\n",
    "            itr = len(train_images) // batch_size\n",
    "            for i in range(itr+1):\n",
    "                IMAGES = []\n",
    "                IMAGES_FUTURE = []\n",
    "                LABELS_FUTURE = []\n",
    "                beg = i*batch_size\n",
    "                end = (i*batch_size + batch_size) if (i*batch_size + batch_size) < len(train_images) else -1\n",
    "                train_batch = train_images[beg:end ]\n",
    "                for i in range(len(train_batch) - time_step):\n",
    "                    frame1 = self.image_file(self.split_char.join([sequence,train_batch[i]]))\n",
    "                    frame2 = self.image_file(self.split_char.join([sequence,train_batch[i+time_step]]))\n",
    "                    label2 = self.label_file(self.split_char.join([sequence,train_batch[i+time_step]]))\n",
    "                    frame1_image = self.imread(frame1)\n",
    "                    frame2_image = self.imread(frame2)\n",
    "                    label2_classim = self.image2class(self.imread(label2))\n",
    "                    if size != None:\n",
    "                        assert( len(size) == 2) , \"log: give (y , x) format size\"\n",
    "                        frame1_image = cv2.resize(frame1_image , size , interpolation = cv2.INTER_NEAREST)\n",
    "                        frame2_image = cv2.resize(frame2_image , size , interpolation = cv2.INTER_NEAREST)\n",
    "                        label2_classim = cv2.resize(label2_classim , size , interpolation = cv2.INTER_NEAREST)\n",
    "                    label2_onehote = self.class2onehot(label2_classim)\n",
    "                    IMAGES.append(frame1_image)\n",
    "                    IMAGES_FUTURE.append(frame2_image)\n",
    "                    LABELS_FUTURE.append(label2_onehote)\n",
    "                if(len(IMAGES) == 0):\n",
    "                    continue\n",
    "                IMAGES = np.array(IMAGES)\n",
    "                IMAGES_FUTURE = np.array(IMAGES_FUTURE)\n",
    "                LABELS_FUTURE = np.array(LABELS_FUTURE)\n",
    "\n",
    "                if normalise:\n",
    "                    IMAGES_FUTURE = IMAGES_FUTURE / 255\n",
    "                    IMAGES = IMAGES / 255\n",
    "\n",
    "\n",
    "                yield IMAGES , IMAGES_FUTURE , LABELS_FUTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log: after filtering there are  10  classes for training\n"
     ]
    }
   ],
   "source": [
    "data_path = \"highway/HighwayDataset/images\"\n",
    "labels_path = \"highway/HighwayDataset/label\"\n",
    "\n",
    "proc = HighwayDriving_Process(data_path , labels_path , classes = None)\n",
    "\n",
    "nb_classes = proc.nb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 4, 256, 256,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c1_conv1 (TimeDistributed)      (None, 4, 256, 256,  896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "c1_conv1_bn (TimeDistributed)   (None, 4, 256, 256,  128         c1_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c1_conv1_relu (TimeDistributed) (None, 4, 256, 256,  0           c1_conv1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "c1_conv2 (TimeDistributed)      (None, 4, 256, 256,  9248        c1_conv1_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c1_conv2_bn (TimeDistributed)   (None, 4, 256, 256,  128         c1_conv2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c1_conv2_relu (TimeDistributed) (None, 4, 256, 256,  0           c1_conv2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "seqc1_1 (ConvLSTM2D)            (None, 4, 256, 256,  73856       c1_conv2_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "seqc1_2 (ConvLSTM2D)            (None, 4, 256, 256,  73856       seqc1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mp1 (TimeDistributed)           (None, 4, 128, 128,  0           seqc1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "c2_conv1 (TimeDistributed)      (None, 4, 128, 128,  18496       mp1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "c2_conv1_bn (TimeDistributed)   (None, 4, 128, 128,  256         c2_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c2_conv1_relu (TimeDistributed) (None, 4, 128, 128,  0           c2_conv1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "c2_conv2 (TimeDistributed)      (None, 4, 128, 128,  36928       c2_conv1_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c2_conv2_bn (TimeDistributed)   (None, 4, 128, 128,  256         c2_conv2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c2_conv2_relu (TimeDistributed) (None, 4, 128, 128,  0           c2_conv2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "seqc2_1 (ConvLSTM2D)            (None, 4, 128, 128,  110720      c2_conv2_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "seqc2_2 (ConvLSTM2D)            (None, 4, 128, 128,  73856       seqc2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mp2 (TimeDistributed)           (None, 4, 64, 64, 32 0           seqc2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "c3_conv1 (TimeDistributed)      (None, 4, 64, 64, 12 36992       mp2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "c3_conv1_bn (TimeDistributed)   (None, 4, 64, 64, 12 512         c3_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c3_conv1_relu (TimeDistributed) (None, 4, 64, 64, 12 0           c3_conv1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "c3_conv2 (TimeDistributed)      (None, 4, 64, 64, 12 147584      c3_conv1_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c3_conv2_bn (TimeDistributed)   (None, 4, 64, 64, 12 512         c3_conv2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c3_conv2_relu (TimeDistributed) (None, 4, 64, 64, 12 0           c3_conv2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "seqc3_1 (ConvLSTM2D)            (None, 4, 64, 64, 32 184448      c3_conv2_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "seqc3_2 (ConvLSTM2D)            (None, 4, 64, 64, 32 73856       seqc3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mp3 (TimeDistributed)           (None, 4, 32, 32, 32 0           seqc3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "c4_conv1 (TimeDistributed)      (None, 4, 32, 32, 25 73984       mp3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "c4_conv1_bn (TimeDistributed)   (None, 4, 32, 32, 25 1024        c4_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c4_conv1_relu (TimeDistributed) (None, 4, 32, 32, 25 0           c4_conv1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "c4_conv2 (TimeDistributed)      (None, 4, 32, 32, 25 590080      c4_conv1_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c4_conv2_bn (TimeDistributed)   (None, 4, 32, 32, 25 1024        c4_conv2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c4_conv2_relu (TimeDistributed) (None, 4, 32, 32, 25 0           c4_conv2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "seqc4_1 (ConvLSTM2D)            (None, 4, 32, 32, 32 331904      c4_conv2_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "seqc4_2 (ConvLSTM2D)            (None, 4, 32, 32, 32 73856       seqc4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mp4 (TimeDistributed)           (None, 4, 16, 16, 32 0           seqc4_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "c5_conv1 (TimeDistributed)      (None, 4, 16, 16, 51 147968      mp4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "c5_conv1_bn (TimeDistributed)   (None, 4, 16, 16, 51 2048        c5_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c5_conv1_relu (TimeDistributed) (None, 4, 16, 16, 51 0           c5_conv1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "c5_conv2 (TimeDistributed)      (None, 4, 16, 16, 51 2359808     c5_conv1_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c5_conv2_bn (TimeDistributed)   (None, 4, 16, 16, 51 2048        c5_conv2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c5_conv2_relu (TimeDistributed) (None, 4, 16, 16, 51 0           c5_conv2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "seq_1 (ConvLSTM2D)              (None, 4, 16, 16, 32 626816      c5_conv2_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "seq_2 (ConvLSTM2D)              (None, 4, 16, 16, 32 73856       seq_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up1 (TimeDistributed)           (None, 4, 32, 32, 25 73984       seq_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 4, 32, 32, 28 0           up1[0][0]                        \n",
      "                                                                 seqc4_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "c6_conv1 (TimeDistributed)      (None, 4, 32, 32, 25 663808      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c6_conv1_bn (TimeDistributed)   (None, 4, 32, 32, 25 1024        c6_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c6_conv1_relu (TimeDistributed) (None, 4, 32, 32, 25 0           c6_conv1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "c6_conv2 (TimeDistributed)      (None, 4, 32, 32, 25 590080      c6_conv1_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c6_conv2_bn (TimeDistributed)   (None, 4, 32, 32, 25 1024        c6_conv2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c6_conv2_relu (TimeDistributed) (None, 4, 32, 32, 25 0           c6_conv2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up2 (TimeDistributed)           (None, 4, 64, 64, 12 295040      c6_conv2_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 4, 64, 64, 16 0           up2[0][0]                        \n",
      "                                                                 seqc3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "c7_conv1 (TimeDistributed)      (None, 4, 64, 64, 12 184448      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c7_conv1_bn (TimeDistributed)   (None, 4, 64, 64, 12 512         c7_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c7_conv1_relu (TimeDistributed) (None, 4, 64, 64, 12 0           c7_conv1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "c7_conv2 (TimeDistributed)      (None, 4, 64, 64, 12 147584      c7_conv1_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c7_conv2_bn (TimeDistributed)   (None, 4, 64, 64, 12 512         c7_conv2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c7_conv2_relu (TimeDistributed) (None, 4, 64, 64, 12 0           c7_conv2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up3 (TimeDistributed)           (None, 4, 128, 128,  73792       c7_conv2_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 4, 128, 128,  0           up3[0][0]                        \n",
      "                                                                 seqc2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "c8_conv1 (TimeDistributed)      (None, 4, 128, 128,  55360       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c8_conv1_bn (TimeDistributed)   (None, 4, 128, 128,  256         c8_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c8_conv1_relu (TimeDistributed) (None, 4, 128, 128,  0           c8_conv1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "c8_conv2 (TimeDistributed)      (None, 4, 128, 128,  36928       c8_conv1_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c8_conv2_bn (TimeDistributed)   (None, 4, 128, 128,  256         c8_conv2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c8_conv2_relu (TimeDistributed) (None, 4, 128, 128,  0           c8_conv2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up4 (TimeDistributed)           (None, 4, 256, 256,  18464       c8_conv2_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 4, 256, 256,  0           up4[0][0]                        \n",
      "                                                                 seqc1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "c9_conv1 (TimeDistributed)      (None, 4, 256, 256,  18464       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c9_conv1_bn (TimeDistributed)   (None, 4, 256, 256,  128         c9_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c9_conv1_relu (TimeDistributed) (None, 4, 256, 256,  0           c9_conv1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "c9_conv2 (TimeDistributed)      (None, 4, 256, 256,  9248        c9_conv1_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c9_conv2_bn (TimeDistributed)   (None, 4, 256, 256,  128         c9_conv2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c9_conv2_relu (TimeDistributed) (None, 4, 256, 256,  0           c9_conv2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output (TimeDistributed)        (None, 4, 256, 256,  330         c9_conv2_relu[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 7,298,314\n",
      "Trainable params: 7,292,426\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class Sequenced_Unet:\n",
    "  \n",
    "    def jaccard_distance(self , y_true, y_pred, smooth=100):\n",
    "        intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "        sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "        jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "        return (1 - jac) * smooth\n",
    "  \n",
    "    def conv2d(self , x, n_filters=64 , kernel_size = 3, batchnorm = True  , name = None):\n",
    "\n",
    "        x = TimeDistributed(Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\n",
    "                 kernel_initializer = 'glorot_uniform', padding = 'same', activation=None ) , name = name)(x)\n",
    "        if batchnorm:\n",
    "            x = TimeDistributed(BatchNormalization() , name = name+'_bn')(x)\n",
    "        x = TimeDistributed(Activation('relu') , name = name+'_relu')(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def conv2d_block(self , x , n_filters=64 , kernel_size = 3, batchnorm = True , name = None):\n",
    "        x = self.conv2d(x , n_filters , kernel_size , batchnorm  , name= name+\"_conv1\")\n",
    "        x = self.conv2d(x , n_filters , kernel_size , batchnorm  , name= name+\"_conv2\")\n",
    "        return x\n",
    "      \n",
    "    def convlstm2d_block(self , x , filters = 64 , kernel_size = 3 , name = None , return_sequence = True):\n",
    "        x = ConvLSTM2D(filters = n_filters , kernel_size = kernel_size , strides = 1 , padding = 'same' , return_sequences = True , name = name+\"_1\")(x)\n",
    "        x = ConvLSTM2D(filters = n_filters , kernel_size = kernel_size , strides = 1 , padding = 'same' , return_sequences = return_sequence , name = name+\"_2\")(x)\n",
    "        return x\n",
    "  \n",
    "    def __init__(self ,nb_classes , size = (512 , 512 , 3) , n_filters = 16 , time_step = 4, batchnorm = True):\n",
    "    \n",
    "        self.size = size\n",
    "        self.nb_class = nb_classes\n",
    "\n",
    "        inp = Input(shape = (time_step,)+size)\n",
    "\n",
    "\n",
    "        c1 = self.conv2d_block(inp, n_filters * 1, kernel_size = 3, batchnorm = batchnorm , name = 'c1')\n",
    "        seqc1 = self.convlstm2d_block(c1 , filters = n_filters * 1 , kernel_size = 3 , name = 'seqc1')\n",
    "        p1 = TimeDistributed(MaxPooling2D((2, 2)) , name='mp1')(seqc1)\n",
    "\n",
    "\n",
    "        c2 = self.conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm , name=\"c2\")\n",
    "        seqc2 = self.convlstm2d_block(c2 , filters = n_filters * 2 , kernel_size = 3 , name = 'seqc2')\n",
    "        p2 = TimeDistributed(MaxPooling2D((2, 2)) , name='mp2')(seqc2)\n",
    "\n",
    "        c3 = self.conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm , name = \"c3\")\n",
    "        seqc3 = self.convlstm2d_block(c3 , filters = n_filters * 4 , kernel_size = 3 , name = 'seqc3')\n",
    "        p3 = TimeDistributed(MaxPooling2D((2, 2)), name='mp3')(seqc3)\n",
    "\n",
    "        c4 = self.conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm , name = \"c4\")\n",
    "        seqc4 = self.convlstm2d_block(c4 , filters = n_filters * 8 , kernel_size = 3 , name = 'seqc4')\n",
    "        p4 = TimeDistributed(MaxPooling2D((2, 2)), name='mp4')(seqc4)\n",
    "\n",
    "        c5 = self.conv2d_block(p4, n_filters * 16, kernel_size = 3, batchnorm = batchnorm , name = \"c5\")\n",
    "\n",
    "        seq = self.convlstm2d_block(c5 , filters = n_filters * 16 , kernel_size = 3 , name = 'seq')  ## Remember since we are intending to recreate the frames we are intending it to be an identity function i.e use (1,1) filters\n",
    "\n",
    "\n",
    "        u6 = TimeDistributed(Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same') , name = \"up1\")(seq)\n",
    "        u6 = Concatenate(axis = -1)([u6, seqc4])\n",
    "        c6 = self.conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm , name = \"c6\")\n",
    "\n",
    "        u7 = TimeDistributed(Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')  , name = \"up2\")(c6)\n",
    "        u7 = Concatenate(axis = -1)([u7, seqc3])\n",
    "        c7 = self.conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm , name = \"c7\")\n",
    "\n",
    "        u8 = TimeDistributed(Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same') , name = \"up3\")(c7)\n",
    "        u8 = Concatenate(axis = -1)([u8, seqc2])\n",
    "        c8 = self.conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm , name = \"c8\")\n",
    "\n",
    "        u9 = TimeDistributed(Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same' ) , name = \"up4\")(c8)\n",
    "        u9 = Concatenate(axis = -1)([u9, seqc1])\n",
    "        c9 = self.conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm , name = \"c9\")\n",
    "\n",
    "        out = TimeDistributed(Conv2D(filters = nb_classes, kernel_size = 1 ,kernel_initializer = 'glorot_uniform', padding = 'same' , activation='softmax') , name='output')(c9)\n",
    "\n",
    "        u_model = Model(inputs = inp , outputs = out)\n",
    "\n",
    "        model = Model(inputs = inp , outputs = out , name='u_net_segmentation')\n",
    "        self.model = model\n",
    "\n",
    "        model.summary()\n",
    "    \n",
    "      \n",
    "    def train(self , epochs = 30 ,lr = 1e-4 ,  batch_size = 16 , mem_rate = 10 , time_steps = 4 , skip = 4, dataset = None  , \n",
    "            pretrained = False , class_weights = None , model_name=\"time_model.h5\"):\n",
    "        assert (dataset is not None),'log: give a dataset class with generator function for validation and training'\n",
    "        \n",
    "        if pretrained:\n",
    "            self.model.load_weights(model_name)\n",
    "      \n",
    "        self.model.compile(optimizer = Adam(lr = lr), loss = 'categorical_crossentropy', metrics = [self.jaccard_distance])\n",
    "        \n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            print(\"Epoch :\", i)\n",
    "            print(\"Training .....\")\n",
    "            for x , y in dataset.frameSequence_train_datagen(size=self.size[:-1] , \n",
    "                                                           batch_size= batch_size*mem_rate , time_steps = time_steps , skip = skip , normalise = True):\n",
    "                x[:, :, :, 0:28, :] = 0\n",
    "                x[:, :, :, 228:256, :] = 0\n",
    "                \n",
    "                hist = self.model.fit(x = x , y = y , batch_size=batch_size , epochs = 1 , verbose = 1 , class_weight = class_weights)\n",
    "                train_losses.append(hist.history['loss'][0])\n",
    "            self.model.save_weights(\"saved_models/future_segmentation_generate/\" + model_name + \"_e\" + str(i))\n",
    "          \n",
    "            x , y = next(dataset.frameSequence_train_datagen(size = self.size[:-1] ,batch_size = 4 , time_steps = 4 , skip = 4 , normalise = True))\n",
    "            index = random.randint(0,x.shape[0])\n",
    "            p = self.model.predict(np.array([x[index]]))            \n",
    "          \n",
    "\n",
    "            plt.figure(figsize = (time_steps*time_steps,time_steps*time_steps))\n",
    "            for i in range(time_steps):\n",
    "                plt.subplot(3,time_steps,i+1)\n",
    "                plt.imshow(x[index][i])\n",
    "                plt.title(\"frame \"+str(i+1))\n",
    "                plt.subplot(3,time_steps,i+time_steps+1)\n",
    "                plt.imshow(dataset.class2image(np.argmax(y[index][i] , axis = -1)))\n",
    "                plt.title(\"label \"+str(i+1))\n",
    "                plt.subplot(3,time_steps,i+2*time_steps+1)\n",
    "                plt.imshow(dataset.class2image(np.argmax(p[0][i] , axis = -1)))\n",
    "                plt.title(\"label predicted \"+str(i+1))\n",
    "            \n",
    "            \n",
    "            plt.show()\n",
    "            plt.figure(figsize = (10,10))\n",
    "            plt.plot(train_losses)\n",
    "            plt.show()\n",
    "            \n",
    "        pickle_out = open(\"saved_models/future_segmentation_generate/history_future_segmentation_generate_e30.pickle\",\"wb\")\n",
    "        pickle.dump(train_losses, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "        \n",
    "    \n",
    "size = (256 , 256  , 3)\n",
    "n_filters = 32\n",
    "time_step = 4\n",
    "skip = 4\n",
    "nb_classes\n",
    "net = Sequenced_Unet(nb_classes, size , n_filters = n_filters , time_step = time_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "Training .....\n",
      "44/44 [==============================] - 27s 621ms/step - loss: 2.2634 - jaccard_distance: 1.7245\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 27s 623ms/step - loss: 2.4690 - jaccard_distance: 1.7771\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 27s 623ms/step - loss: 2.2685 - jaccard_distance: 1.7308\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 27s 623ms/step - loss: 2.0464 - jaccard_distance: 1.6768\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 27s 622ms/step - loss: 1.9899 - jaccard_distance: 1.6481\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 27s 622ms/step - loss: 1.7655 - jaccard_distance: 1.5651\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 27s 622ms/step - loss: 2.0158 - jaccard_distance: 1.6463\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 27s 620ms/step - loss: 1.6347 - jaccard_distance: 1.5143\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 27s 622ms/step - loss: 1.8677 - jaccard_distance: 1.5609\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 27s 622ms/step - loss: 1.8251 - jaccard_distance: 1.5553\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 27s 621ms/step - loss: 1.6578 - jaccard_distance: 1.5071\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 27s 621ms/step - loss: 1.4652 - jaccard_distance: 1.4249\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 27s 622ms/step - loss: 2.1950 - jaccard_distance: 1.6248\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 27s 622ms/step - loss: 1.7163 - jaccard_distance: 1.5016\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 27s 621ms/step - loss: 1.5050 - jaccard_distance: 1.4180\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 4\n",
    "lr = 1e-4\n",
    "net.train(epochs=epochs , lr = 1e-4 , dataset = proc , batch_size = batch_size , time_steps = time_step , skip = skip\n",
    "             , pretrained = False , mem_rate = 11 , class_weights = None , model_name = \"time_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(\n",
    "        filepath=os.path.join('saved_models', 'future_segmentation_generate', 'future_segmentation_generate' + \\\n",
    "            '.{epoch:03d}-{loss:.3f}.hdf5'),\n",
    "        verbose=1,\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True)\n",
    "\n",
    "proc = HighwayDriving_Process(data_path, labels_path, classes = None)\n",
    "datagen = proc.frameSequence_train_datagen(size = (256, 256))\n",
    "\n",
    "history = u_model.fit_generator(generator = datagen, steps_per_epoch = 60, epochs = 5, verbose = 1, workers = 4, shuffle = False, callbacks = [checkpointer], initial_epoch = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "proc = HighwayDriving_Process(data_path, labels_path, classes = None)\n",
    "\n",
    "for data in proc.frameSequence_train_datagen(size = (256, 256)):\n",
    "    x, y = data\n",
    "    print(str(x.shape) + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
